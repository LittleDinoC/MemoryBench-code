{
    "title": "Exploring Ordinality in Text Classification: A Comparative Study of Explicit and Implicit Techniques",
    "abstract": "Ordinal Classification (OC) is a widely encountered challenge in Natural Language Processing (NLP), with applications in various domains such as sentiment analysis, rating prediction, and more. Previous approaches to tackle OC have primarily focused on modifying existing or creating novel loss functions that explicitly account for the ordinal nature of labels.\nHowever, with the advent of Pretrained Language Models (PLMs), it became possible to tackle ordinality through the implicit semantics of the labels as well.\nThis paper provides a comprehensive theoretical and empirical examination of both these approaches.\nFurthermore, we also offer strategic recommendations regarding the most effective approach to adopt based on specific settings.",
    "sections": [
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Explicit approach: Loss-functions and Analysis",
            "text": "Let  be  independent and identically distributed datapoints containing the input features  and their corresponding labels ; where  where  is the number of classes. The output of the classifier is denoted by  which is a probability distribution over the  classes.\nLet  be the one hot encoding of .\nThe classifier is trained by optimizing the parameters  such that  reaches a minimum. In the rest of the paper, for ease of mathematical exposition, we omit the indexing with respect to , i.e. remove the  and , wherever it is evident from the loss expression.\nIn the next subsection, we give a few desirable theoretical properties of the loss function  in the context of OC and then follow it up by discussing some of the widely used loss functions."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Desirable Properties of Losses in OC",
            "text": "Proper Scoring Rule (PSR): A loss is said to be a PSR (Gneiting and Raftery, 2007  ###reference_b13###; Merkle and Steyvers, 2013  ###reference_b23###) if it takes the lowest value when the predicted class probabilities match the ground truth which is a one-hot encoded -dimensional vector.\nBeing PSR ensures that the loss indeed tries to optimize the classifier to predict the ground truth without injecting any bias in the predicted outputs. Further, PSR losses also help to produce well calibrated probabilities (Lakshminarayanan et al., 2017  ###reference_b20###).\nConvexity (Cx): Convexity of  with respect to  is a desirable property of the loss as it is an essential requirement for several convex formulations of Neural Networks (NNs) Kawaguchi et al. (2019  ###reference_b17###); Du et al. (2019  ###reference_b11###); Pilanci and Ergen (2020  ###reference_b25###); Wojtowytsch (2023  ###reference_b34###). Further, if both  and  (classifier function) are convex with respect to  (as in the case of logistic regression or support vector machines), then it is guaranteed that the local minima indeed coincides with the global minima.\nSeveral widely used losses such CE, MAE, MSE, etc. are both PSRs and Convex. Next, we look at two desirable characteristics of the output probabilities from the classifier in the context of OC.\nUnimodality (UM): If the output probabilities have single mode, i.e.  is not satisfied for any , then we say the classifier satisfies the UM condition (Beckham and Pal, 2017  ###reference_b1###; Yamasaki, 2022  ###reference_b35###; Iannario and Piccolo, 2011  ###reference_b14###). An illustration is given in Figure 1  ###reference_###.\nOrdinality (Ord): In the context of OC, we require the loss  to explicitly penalize the mis-classifications more which are farther away from each other compared to the ones which are closer. The goal is to enforce a meaningful ordering among the labels unlike nominal classifcation where categories lack a specific order. We will see later that different loss functions enforce ordinality to a varying degree.\nIn the next subsection, we discuss some of the widely used loss functions in the context of OC in NLP."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Widely used Loss Functions in OC",
            "text": "Cross-Entropy (CE): CE is given by\nThe above expression boils down to . Oftentimes CE is discredited for not being able to factor in ordering as its expression does not take into account the probabilities corresponding to the non-groundtruth classes.\nOrdinal Log Loss (OLL) (Castagnos et al., 2022  ###reference_b6###): OLL is given by\nHere  is a hyperparameter. This can be seen as a complementary of CE where the missclassification is explicitly penalized in proportion to its degree by the term\n. Both CE and OLL belong to PSR family as both these losses are zero when the output probabilities coincide with the ground truth one-hot encoding.\nSOFT labels (SOFT) Díaz and Marathe (2019  ###reference_b12###): In this approach, first the ground truth -dimensional onehot encoded is modified to  ‘soft’ labels as follows.\nThen CE loss can be computed using these soft ground labels as truth probabilities.\nClearly, introducing softlabels makes this approach not fall in the PSR family as the ground-truth onehot encoding vector does not minimize the loss anymore.\nEarth Mover Distance (EMD) Rubner et al. (2000  ###reference_b28###) : EMD or Wasserstein loss is defined\nHere CDF refers to the cumulative distribution function. While EMD is a PSR, it does not impose a strong penalty in the tails (as compared to OLL) because CDFs are monotonic with range in  and hence the difference between the CDFs will be small in the tails.\nUnimodal Losses: da Costa et al. 2008  ###reference_b7### and Beckham and Pal 2017  ###reference_b1### introduce a parametric way to force unimodality in the predicted probability scores by first computing a scalar function  and using this scalar as the parameter of a Binomial distribution with parameters , the Probability Mass Function (PMF) is computed which forms the final predicted probabilities.\nNote that the computing a single scalar  (as opposed a vector of embeddings as done in other methods) severely hampers the learning; thus the guarantee of unimodality comes at the cost of degradation in performance. To address this, Yamasaki (2022  ###reference_b35###) proposes a more-flexible unimodal OC framework by imposing shape-based constraints on the output probabilities; the V-Shaped Stereotyped Logit (VS-SL) method has shown to be the state-of-the-art for UM in their work and hence, we use it as a baseline in our experiments.\nWe also include two more loss function variants, namely COnsistent RAnk Logits (CORAL) Cao et al. (2020  ###reference_b5###) and Weighted Kappa Loss (WKL) de la Torre et al. (2017  ###reference_b9###), and benchmark their effectiveness in terms of accuracy and ordinality.\nTo benchmark the performance of the above loss functions, we run experiments on\nthree\nbenchmark multi-class text classification datasets, each with its distinct task: Hypothesis entails Premise task - SNLI Bowman et al. (2015  ###reference_b2###), Reviews Classification task - Amazon Reviews (AR) Keung et al. (2020  ###reference_b18###),\nand Sentiment Analysis task - SST-5 Socher et al. (2013  ###reference_b30###). We report weighted-F1 scores and MAE, MSE, Off-by-1 (OB1) accuracy to measure both classification and ordinal performance respectively. In the interest of space, we present the details of datasets and metrics in Appendix B  ###reference_### and C  ###reference_###.\nWe observe that in general CE performs best in terms of nominal metrics (like weighted-F1) and OLL performs best in terms of ordinal metrics on an average. However, there seems to be a trade-off between nominal and ordinal performance i.e. the improvement in ordinal metrics comes at the expense of nominal metrics. However, given that all these metrics are also from the PSR family, and in some sense are not independent of each other as a perfect classifier would improve both these metrics simultaneously.\nThis intuition prompted us to experiment with a weighted combination of CE and OLL, which we have named Multitask Log Loss (MLL), hypothesizing that it would inherit the best attributes of both methods.\nMulti-task log loss function (MLL): MLL is given by\nHere,  is a hyperparameter. MLL satisfies both convexity and PSR conditions. Further, while OLL and MLL are not theoretically guaranteed to be UM, but empirically have been found to be satisfying UM condition for 80-90% test datapoints which we show later in Figure 4  ###reference_###. A summary of the properties satisfied by different loss-based approaches is given in Table 1  ###reference_###, with discussions in Appendix E  ###reference_### and F  ###reference_###. Note that while it’s theoretically possible to consider weighted combinations involving other loss functions, we only considered CE and OLL here because OLL has already been shown to outperform other losses in terms of ordinal metrics (Castagnos et al., 2022  ###reference_b6###) and we aimed to improve its performance in term of nominal metrics as well, by adding with the CE term.\nWe perform all explicit approach based experiments using BERT-base (refer Appendix D  ###reference_###). Following Castagnos et al. (2022  ###reference_b6###) we also train a smaller version - TinyBERT Jiao et al. (2020  ###reference_b15###), as the performance of different loss functions\nis better contrasted when the size of the base model is small, which is usually the case in online settings where we cannot deploy larger models.\nThe detailed results are given in Table 3  ###reference_### and Appendix A  ###reference_###."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Implicit approach: Entailment-style Encoder Models",
            "text": "Wang et al. (2021  ###reference_b32###) proposed reformulating vanilla classification into an entailment-style task to enhance the few-shot capabilities of PLMs. Here, the model learns to predict whether the input text and the label entail each other or not (similar to Natural Language Inference (NLI) setting), leveraging the inherent semantic relationship between the label and input text. We adopt a similar approach for our task and explore it through the lens of ordinality, which has not been studied in prior works.\nWe assume the existence of a classifier, based on Pretrained Language Model (PLM), called .\nLet  be the collection of textual labels.\nThe training dataset can be divided based on the labels into , which consists of subsets . Each subset contains the available training data  for label . The corresponding test data is represented by .\nDuring the training phase in , the following entailment-style data augmentation technique is employed:\nFor each data point  with a ground truth label of ,  samples () are generated and augmented as follows:\nHere,  is an indicator function that yields 1 if  else 0. The ‘+’ operator denotes concatenation operation (refer §D  ###reference_###), and  is a pre-defined template (specific to the downstream task) describing the label in natural language. For example, in sentiment classification task  can be described as: indicates positive sentiment. See Figure 2  ###reference_### for example.\nEssentially, for each data point,  negative samples and 1 positive sample are created. Finally the problem reduces to the following NLI task - Does  entail  or not?\nOnce these  augmented examples are generated, the parameters  are finetuned for a binary classification task, where  serves as the input and  acts as the ground truth.\nDuring the inference phase, for a datapoint  the predicted label  is obtained using:\nDuring inference for ,  is computed following Eq. 6  ###reference_### and softmax() is applied on the predicted logits before taking argmax so that all the class probabilities sum up to 1. As the model leverages the natural language meanings of the labels during training, we argue it is inherently capable of learning to predict labels that are ordinally consistent. For instance, the model learns to comprehend that the label very negative sentiment is closer in semantic space to negative sentiment than to very positive sentiment. This understanding prevents the model from deviating significantly from the actual ground truth. In contrast, in the case of vanilla CE, these labels are treated solely as numbers, disregarding their inter-semantic relations. We again use BERT-base here as base model for performing experiments. The exact label verbalisers used for all datasets are mentioned in Appendix 8  ###reference_###."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Implicit approach: Generative Models",
            "text": "Decoder-based text generative models have seen notable advancements in recent years, facilitating the production of coherent and contextually relevant text. The development of models like the GPT series Radford et al. (2018a  ###reference_b26###, b  ###reference_b27###); Brown et al. (2020  ###reference_b4###) has led to state-of-the-art results in text generation and summarization benchmarks.\nOne of the primary objectives of this paper is to investigate whether these models demonstrate ordinal behavior by accurately capturing the inherent order or ranking of elements in the generated text.\nFormally, in the context of OC, for a given a textual input  which comprises the following words  and its corresponding ground truth label , we append the input and label as .\nNext, the parameters  of generative model are finetuned s.t.\nDuring inference for  input , the generative model predicts the word  from the vocabulary  which maximizes the conditional probability:\nFurther, it is possible that the predicted label may not be in the set of ground truth labels i.e. for an  input  the label  where  is the set of  distinct labels (see Appendix 9  ###reference_###). This is the notorious hallucination problem associated with generative models.\nTo mitigate this issue during inference, we compare the conditional log-probabilities of each the  labels\n, given the text segment . The class corresponding to the highest probability is proposed as the generated label. That is, given that  represents the learned parameters of LM, the label selection during inference will be s.t.\nHere  are the words in input  and  are the labels in the set .\nFor fair comparison with other explicit and implicit approaches, we use GPT2-small as our base model for experiments to maintain similar number of model parameters (with BERT-base). Similar to the entailment approach (§3  ###reference_###), we also experiment with informative and un-informative verbalisers here.\nMotivated by recent advancements and the accessibility of open-source Large Language Models (LLMs), and to demonstrate the true potential of the generative approach, we also experiment with Llama-7B Touvron et al. (2023  ###reference_b31###), a decoder-based LLM with 7 billion parameters. Pre-trained on trillions of tokens using publicly available data, it achieves state-of-the-art performance, surpassing its larger predecessors like GPT-3 (175B) on the majority of benchmarks.\nNote that our approach is different from GPT2ForSquenceClassification111https://tinyurl.com/am93sjdw  ###reference_tinyurl.com/am93sjdw### where the last embedding of the last token is used for classification, which is similar to encoder-model (like BERT) style classification. Instead we train it for a language modelling task\nto generate within a fixed set of tokens i.e. the set of labels."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "This paper presents an unified analysis of explicit and implicit strategies for addressing OC. It is the first study to thoroughly examine and compare these approaches from both theoretical and empirical standpoints. Our analysis (summarized in Table 5  ###reference_###) reveals that MLL demonstrates balanced performance across ordinal and nominal metrics, unlike existing explicit losses. However, in few-shot scenarios, ENT is preferred for its ability to achieve optimal performance with fewer examples, leveraging label semantics. Furthermore, we highlight the importance of providing informative verbalisers in low-data settings, resulting in reduced variance and improved outcomes. However, the distinction between strategies becomes less clear with increasing data. In full-data scenarios, fine-tuning Llama-7B-Adapter surpasses previous approaches due to its substantial model size. Interestingly, even with such a large base model, the impact of adding informative verbalisers remains apparent, indicating its recognition of label order.\nWe hope that our work will serve as a benchmark encompassing multitude of approaches, providing a foundation for future efforts to address OC in NLP."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "In this study,\nwe don’t consider the effect of calibration techniques on the explicit approaches (Kull et al., 2019  ###reference_b19###), as the techniques employed are largely identical to those used in nominal classification, offering no distinct or novel methodologies specifically for OC tasks.\nAlso for implicit approaches, a more deeper analysis is required on how implicit methods like LLMs & PLMs implicitly capture ordinality. It’s not always analogous to how humans use task instructions as shown in Webson and Pavlick (2022  ###reference_b33###). Furthermore, in this study we limit ourselves to only finetuning-based OC approaches. However, it would also be interesting to explore OC through the lens of in-context learning (ICL) for generative approaches. Also for the generative approach, we make the assumption that the label word will not break further into multiple tokens by re-mapping original labels to simpler words (see Appendix 9  ###reference_###). This avoids having to account for multiple token probabilities when taking the argmax. Without this some sort of normalization would be required across the entire generation length to compare different outputs. We leave these discussions for future work. Even though we notice that LLMs such as Llama-7B outperform all the other models in full data settings, there are certain challenges in terms of compute resources and inference time. Additionally, finetuning Llama-7B is susceptible to hallucinations in low-data settings Zhao et al. (2021  ###reference_b37###), which is why we don’t report LLM results for the few-shot case."
        }
    ]
}