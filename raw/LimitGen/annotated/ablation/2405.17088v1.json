{
    "title": "Phase Transitions in the Output Distribution of Large Language Models",
    "abstract": "In a physical system, changing parameters such as temperature can induce a phase transition: an abrupt change from one state of matter to another. Analogous phenomena have recently been observed in large language models. Typically, the task of identifying phase transitions requires human analysis and some prior understanding of the system to narrow down which low-dimensional properties to monitor and analyze. Statistical methods for the automated detection of phase transitions from data have recently been proposed within the physics community. These methods are largely system agnostic and, as shown here, can be adapted to study the behavior of large language models. In particular, we quantify distributional changes in the generated output via statistical distances, which can be efficiently estimated with access to the probability distribution over next-tokens. This versatile approach is capable of discovering new phases of behavior and unexplored transitions – an ability that is particularly exciting in light of the rapid development of language models and their emergent capabilities.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Colloquially, the term phase transition refers to a change among the basic phases of matter. For example, in response to changes in external conditions such as temperature or pressure, water can transition to a solid, liquid, or gaseous state. More broadly, in physics a phase transition refers to an abrupt change in the macroscopic behavior of a large-scale system of interacting constituents [1  ###reference_b1###, 2  ###reference_b2###]. Notable examples include transitions in the magnetic properties of materials [3  ###reference_b3###], transitions from a normal conducting state to a superconductor [4  ###reference_b4###], transitions in the entanglement properties of quantum circuit [5  ###reference_b5###], or the collective motion of active matter such as a flock of birds [6  ###reference_b6###].\nIn the context of artificial intelligence, “phase transition”-like phenomena have also been observed in the learning behavior of neural networks (NNs) [1  ###reference_b1###, 7  ###reference_b7###, 8  ###reference_b8###, 9  ###reference_b9###, 10  ###reference_b10###, 11  ###reference_b11###, 12  ###reference_b12###, 13  ###reference_b13###, 14  ###reference_b14###, 15  ###reference_b15###, 16  ###reference_b16###]. For example, during training, AlphaZero [17  ###reference_b17###] underwent periods of rapid knowledge acquisition in which increasingly sophisticated chess openings were favored by the engine [9  ###reference_b9###]. Large language models (LLMs) have been observed to make sudden improvements in their inductive abilities during training which is related to the formation of special circuitry (so-called induction heads) [18  ###reference_b18###]. Similar abrupt improvements in specific capabilities, often referred to as breakthroughs, have been observed for a variety of different models and tasks [19  ###reference_b19###, 20  ###reference_b20###, 21  ###reference_b21###, 22  ###reference_b22###, 23  ###reference_b23###, 24  ###reference_b24###, 12  ###reference_b12###, 25  ###reference_b25###, 26  ###reference_b26###, 10  ###reference_b10###, 27  ###reference_b27###]. Moreover, phenomena such as double descent [28  ###reference_b28###, 29  ###reference_b29###] or grokking [30  ###reference_b30###, 31  ###reference_b31###, 32  ###reference_b32###, 33  ###reference_b33###, 34  ###reference_b34###, 35  ###reference_b35###] are also reminiscent of phase transitions in physics.\nThe detection of phase transitions111In the following, we adopt a more general definition of a phase transition as a sudden shift in the qualitative behavior of a system as a function of a control parameter [1  ###reference_b1###, 10  ###reference_b10###, 36  ###reference_b36###]. in deep learning systems may improve our understanding and eventually enable better model training. For example, an in-depth analysis of the grokking transition [30  ###reference_b30###, 37  ###reference_b37###] led to a way for accelerating generalization [32  ###reference_b32###]. Moreover, it has been shown that models are highly sensitive to perturbations, such as data corruptions, at critical points [38  ###reference_b38###, 36  ###reference_b36###]. Being able to predict the behavior of models is also crucial for ensuring safe model deployment [19  ###reference_b19###] as well as for projecting the performance of future model versions and optimally allocating resources for their training [39  ###reference_b39###].\nThe characterization of phase transitions in physics is difficult because the state of the systems to be studied typically lives in a very high-dimensional space and is probabilistic in nature, meaning that for given values of the tuning parameters we can find the system in various states. Physicists solve this problem by finding a suitable set of a few low-dimensional quantities, called order parameters [2  ###reference_b2###], which capture the essence of each phase of the system. For example, even though water is a highly complex system, we can detect the liquid-gas transition by looking at the density which shows a sudden jump at the boiling point and, in this case, serves as an order parameter. However, finding such a suitable set of order parameters is “considered an art” [2  ###reference_b2###], as it requires a great deal of human intuition as well as prior understanding.\nFaced with the task of characterizing phase transitions in learning systems based on large NNs, similar issues are encountered. NNs contain an enormous amount of trainable parameters and their state space, as characterized by their neural activations, is huge. This problem is exacerbated in generative models such as LLMs where also the output space is large, i.e., the high dimensionality cannot be foregone by treating the inside of the NN as a black box and focusing solely on its output characteristics. Understanding LLMs from first principles has been notoriously hard [40  ###reference_b40###]. Theories capturing their microscopic and macroscopic behavior, for instance based on mechanistic interpretability [41  ###reference_b41###, 18  ###reference_b18###, 42  ###reference_b42###, 34  ###reference_b34###, 43  ###reference_b43###] or neural scaling laws [44  ###reference_b44###, 45  ###reference_b45###, 39  ###reference_b39###, 46  ###reference_b46###, 47  ###reference_b47###, 48  ###reference_b48###, 49  ###reference_b49###, 27  ###reference_b27###], are still nascent. In particular, the definition of appropriate low-dimensional quantities that facilitate the detection of transitions has been done manually, for example through the extraction of appropriate circuitry [50  ###reference_b50###, 51  ###reference_b51###, 43  ###reference_b43###]. Due to this human-in-the-loop, transitions can be easily missed [43  ###reference_b43###] or spuriously induced [52  ###reference_b52###].\nIn physics, these problems have been tackled using statistical methods for the detection of phase transitions from data, which requires minimal prior system knowledge and human input [53  ###reference_b53###, 54  ###reference_b54###, 55  ###reference_b55###, 56  ###reference_b56###, 57  ###reference_b57###, 58  ###reference_b58###, 59  ###reference_b59###, 60  ###reference_b60###, 61  ###reference_b61###, 62  ###reference_b62###, 63  ###reference_b63###, 64  ###reference_b64###, 65  ###reference_b65###, 66  ###reference_b66###, 67  ###reference_b67###, 68  ###reference_b68###, 69  ###reference_b69###, 70  ###reference_b70###, 71  ###reference_b71###, 72  ###reference_b72###, 73  ###reference_b73###, 74  ###reference_b74###, 75  ###reference_b75###]. Inspired by this body of work, we here adapt such an approach for the automated detection of phase transitions in LLMs. The method is based on measuring changes in the distribution of the text output of LLMs via generic statistical distances belonging to the family of -divergences, making it a versatile all-purpose tool for objectively and automatically mapping out phase diagrams of generative models. Such an approach has the potential to characterize unexplored phase transitions and potentially discover new phases of behaviors. This is crucial in light of the rapid development of LLMs [76  ###reference_b76###, 77  ###reference_b77###, 78  ###reference_b78###] and their emergent capabilities [19  ###reference_b19###, 20  ###reference_b20###, 21  ###reference_b21###, 22  ###reference_b22###, 23  ###reference_b23###, 24  ###reference_b24###, 79  ###reference_b79###, 18  ###reference_b18###, 80  ###reference_b80###, 21  ###reference_b21###, 25  ###reference_b25###, 26  ###reference_b26###, 10  ###reference_b10###].\nAs a demonstration, we characterize transitions occurring as a function of three different control parameters in Pythia [81  ###reference_b81###], Mistral (7B) [82  ###reference_b82###], and Llama3 (8B) [83  ###reference_b83###] language models: an integer occurring in the input prompt, the temperature hyperparameter for text generation, and the model’s training epoch.\nWe find that\nthe instruction-tuned Llama and Mistral models seem to have the capability to order integers whereas all considered base models do not.\nchanges in integer tokenization can be visible in the text output as sharp transitions.\nthree distinct phases of behavior as a function of an LLM’s temperature can be mapped out: a deterministic “frozen” phase near zero temperature, an intermediate “coherent” phase, and a “disordered” phase at high temperatures.\nan LLM’s “heat capacity” with respect to the temperature can be negative, i.e., the LLM’s mean energy can decrease as its temperature is increased.\nrapid changes in the distribution of weights during training can coincide with transitions in the text output that are present across many prompts.\ndifferent prompts result in different transition times during training, suggesting that distinct type of behavior can be learned rapidly at distinct times in training."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "Pythia [81  ###reference_b81###] is suite of 16 LLMs released in 2023 that were trained on public data in the same reproducible manner ranging from 70 million (M) to 12 billion (B) parameters in size. We consider every second model, i.e. the models with 70M, 410M, 1.4B, and 6.9B parameters. From the Mistral family, we consider the base model Mistral-7B-v0.1 with 7.3B parameters and the corresponding fine-tuned Mistral-7B-Instruct model [82  ###reference_b82###] released in 2023. Llama 3 [83  ###reference_b83###] from Meta AI was released in 2024. We consider both the Llama-3 8B parameter base model and NVIDIA’s chat-tuned Llama3-ChatQA-1.5-8B [107  ###reference_b107###]. For the chat model we use accordingly formatted inputs."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Quantifying Dissimilarity between Distributions",
            "text": "In this work, we view phase transitions as rapid changes in the probability distribution governing the state of the system as the control parameter is varied. That is, values of the parameter at which the distribution changes strongly are considered critical points where phase transitions occur. While it is possible to generalize our approach to distributions conditioned on multiple control parameters, for simplicity we consider the one-dimensional scenario in the following. We quantify the rate of change using -divergences, as they have particularly nice properties, such as satisfying the data processing inequality. Given a convex function with , the corresponding -divergence is a statistical distance defined as Prominent examples of -divergences include the Kullback-Leibler (KL) divergence, the Jensen-Shannon (JS) divergence, which corresponds to a symmetrized and smoothened version of the KL divergence, as well as the total variation (TV) distance. Ideally, we would also like the statistical distance we choose to be symmetric. This condition is only satisfied by the TV distance and the JS divergence among the examples above. Hence, in this work, we will focus on the TV distance corresponding to , as well as the JS divergence corresponding to , where is the KL divergence. The TV distance and the JS divergence have also had tremendous success in detecting phase transitions in physical systems without prior system knowledge under the name of “learning-by-confusion.” Note that both the TV distance and the JS divergence form lower bounds to the KL divergence and other -divergence, such as the divergence. In this sense, detecting a large dissimilarity in terms of the TV distance or the JS divergence also signals a large dissimilarity in other measures."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Detecting Phase Transitions",
            "text": "Having defined appropriate notions of distance between probability distributions, we now describe their use to detect phase transitions: Consider a sampled set of control parameter values, forming a uniform one-dimensional grid. For each point lying halfway in between grid points, we assess whether it is a critical point by computing a dissimilarity score between the distributions underlying the segments to the left and to the right of it. Denoting the cardinality of the segment as \\( n \\), we can write these probabilities as \\( P(n) \\) for each segment. Critical points where phase transitions occur can then be identified as local maxima in this score.\n\nFor simplicity, we proceed with segments of equal length for the rest of this article, and define the length \\( l \\) as the number of parameter values to the left or right of the point that characterize the segment. We are free to adjust it according to the problem, as \\( l \\) sets a natural length scale on which changes in the distributions are assessed. Examples will be discussed in Sec. 3. In particular, for small values and neighboring parameter points separated by \\( \\epsilon \\), \\( D_\\epsilon(f || g) \\rightarrow I_F \\), where \\( I_F \\) is the Fisher information. That is, local changes in a distribution as measured by any -divergence reduce to the Fisher information in the limit.\n\nHaving the Fisher information as a limiting case is a desirable property: It is a well-known, generic statistical measure for quantifying how sensitive probability distributions are to changes in their parameters and its behavior is well-understood when used to detect phase transitions in physical systems."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "\nApplication to Language Models and Numerical Implementation",
            "text": "In the case of language models,  is the sampled text and  is any variable that influences the sampling probability. Because of the autoregressive structure of language models, we can efficiently sample text  for a given prompt and evaluate its probability . Thus, we can obtain an unbiased estimate  of  by replacing expected values with sample means where samples correspond to text generated with language models conditioned on different parameter settings , see Appendix A  ###reference_### for details on implementation.\n\nFor numerical stability and efficient sampling, we express our dissimilarity measures as parameterized by a function  acting on the probability  for  to stem from segment . Specifically, we consider\n\nThese -dissimilarities and the -divergences [Eq. (1  ###reference_###)] defined above correspond to each other in the following sense: any -dissimilarity  can be rewritten in the form of an -divergence  with\n\nsee Appendix B  ###reference_### for the derivation and further discussion. In particular, for the choice ,  corresponds to the JS divergence [Eq. (3  ###reference_###)]. For ,  corresponds to the TV distance [Eq. (2  ###reference_###)].\n\nA natural choice for  is any linear function in . In particular, setting  results in a dissimilarity measure that quantifies the ability of an optimal classifier to tell whether a sample  has been drawn in the left or right sector. This measure is 0 if the two distributions are completely indistinguishable and 1 if the two distributions are perfectly distinguishable. Moreover,  has the property of being bounded between 1 and -1, where the edge values are attained for the certain predictions 0 and 1, and the value 0 corresponds to uncertain predictions at 0.5. This results in a low variance and favorable convergence properties for , which we will refer to as linear dissimilarity in what follows. This quantity is a valid -divergence and reduces to the Fisher information in lowest non-vanishing order444In fact, any -dissimilarity with  and a twice-differentiable -function can be shown to be proportional to the Fisher information in lowest order., as shown in Appendix B  ###reference_###."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "Utilized Large Language Models",
            "text": "In this work, we study transitions in models of the Pythia, Mistral, and Llama family. Pythia is a suite of 16 LLMs released in 2023 that were trained on public data in the same reproducible manner ranging from 70 million (M) to 12 billion (B) parameters in size. We consider every second model, i.e. the models with 70M, 410M, 1.4B, and 6.9B parameters. From the Mistral family, we consider the base model Mistral-7B-v0.1 with 7.3B parameters and the corresponding fine-tuned Mistral-7B-Instruct model released in 2023. Llama 3 from Meta AI was released in 2024. We consider both the Llama-3 8B parameter base model and NVIDIA’s chat-tuned Llama3-ChatQA-1.5-8B. For the chat model we use accordingly formatted inputs."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Results",
            "text": "In the following, we will explore all three fundamental ways in which a parameter may influence the output distribution of a language model: As a hyperparameter controlling how a trained language model is applied, we vary the temperature in Sec. 3.2  ###reference_###. As a training hyperparameter of the language model, we vary the number of training epochs in Sec. 3.3  ###reference_###."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Related Works",
            "text": "Before concluding, let us discuss how our method relates to other approaches for studying transitions in LLMs.\nGeneric performance-based analysis. Many previous works found transitions in LLM behavior by locating sharp changes in generic performance measures, such as sudden drops in training loss [18  ###reference_b18###, 36  ###reference_b36###]. While this may capture transitions in the overall behavior, such an approach cannot resolve transitions in specific LLM behavior. In particular, it may miss algorithmic transitions where the same performance is reached but by different means [43  ###reference_b43###].\nPrompt-specific success metrics. Other works have found transitions by looking at success metrics tailored toward specific prompts [20  ###reference_b20###, 21  ###reference_b21###, 22  ###reference_b22###, 23  ###reference_b23###, 24  ###reference_b24###, 25  ###reference_b25###, 113  ###reference_b113###]. Recalling the example studied in Sec. 3.1  ###reference_###, this would correspond to assigning a score of 1 if the LLM provided the correct answer to the question  and 0 otherwise. Similarly, one could compute such a score in a temporal analysis (Sec. 3.3  ###reference_###) or for detecting transitions as a function of another hyperparameter (Sec. 3.2  ###reference_###). A downside of this approach is that it is restricted to prompts that allow for a clear score to be assigned. In particular, choosing an appropriate scoring function may require lots of human engineering. Moreover, discontinuous metrics can artificially induce transitions where the underlying behavior varies smoothly [52  ###reference_b52###]. Similarly, they may miss transitions where the same performance is reached but by different means [43  ###reference_b43###].\nMeasures based on model internals. The aforementioned approaches are based on the model output. Many works have also detected transitions based on changes in the internal structure of models, such as its trainable parameters [115  ###reference_b115###, 36  ###reference_b36###] (similar to the weight-based analysis we have performed in Sec. 3.3  ###reference_###). However, access to model internals may not always be available. Moreover, the design of measures that capture specific transitions in behavior requires lots of human input [50  ###reference_b50###, 51  ###reference_b51###, 43  ###reference_b43###], e.g., using insights from the field of mechanistic interpretability."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion and Outlook",
            "text": "We have proposed a method for automating the detection of phase transitions in LLMs, and demonstrated that it successfully reveals a variety of transitions. Leveraging access to the LLMs’ next-token probability distributions, the proposed dissimilarity measures can efficiently quantify distribution shifts without fine-tuning or adaption to the specific scenario at hand. Because the method is solely based on analyzing a model’s output distribution and access to the model weights is not required, it enables black-box interpretability studies.\nThe proposed method is not only applicable to language models, but can be straightforwardly adapted to any generative model with an explicit, tractable density [116  ###reference_b116###, 73  ###reference_b73###]. If one can draw samples from the output distribution but does not have explicit access to the underlying probabilities, then the dissimilarity measures can still be approximated using NN-based classifiers [117  ###reference_b117###, 75  ###reference_b75###] tailored toward the particular data type, such as natural language.\nFuture large-scale investigations are needed to fully understand how the uncovered transitions depend on variables such as the specific prompt, the number of generated output tokens, or the selected model. In particular, due to computational resource constraints, the size of the studied language models has been limited.\nOur method has the potential to enhance the development of future AI systems due to an improved understanding of their behavior. The dual-use nature of such systems carries inherent risks, which requires one to proceed with caution and implement mechanisms to ensure they are used safely and ethically."
        }
    ]
}