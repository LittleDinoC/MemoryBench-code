{
    "title": "Adapting Abstract Meaning Representation Parsing to the Clinical Narrative – the SPRING THYME parser",
    "abstract": "This paper is dedicated to the design and evaluation of the first AMR parser tailored for clinical notes. Our objective was to facilitate the precise transformation of the clinical notes into structured AMR expressions, thereby enhancing the interpretability and usability of clinical text data at scale. Leveraging the colon cancer dataset from the Temporal Histories of Your Medical Events (THYME) corpus, we adapted a state-of-the-art AMR parser utilizing continuous training. Our approach incorporates data augmentation techniques to enhance the accuracy of AMR structure predictions. Notably, through this learning strategy, our parser achieved an impressive F1 score of 88% on the THYME corpus’s colon cancer dataset. Moreover, our research delved into the efficacy of data required for domain adaptation within the realm of clinical notes, presenting domain adaptation data requirements for AMR parsing. This exploration not only underscores the parser’s robust performance but also highlights its potential in facilitating a deeper understanding of clinical narratives through structured semantic representations.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Abstract Meaning Representation Banarescu et al. (2013  ###reference_b4###)(AMR)is a highly adaptable and expressive framework designed to capture the semantics of natural language expressions. Automatic AMR parsing is a natural language processing (NLP) method that translates natural language inputs into formal AMR expressions – representations which have proven to be useful across a wide range of downstream applications Kapanipathi et al. (2021  ###reference_b20###); Liu et al. (2015  ###reference_b28###); Liao et al. (2018  ###reference_b27###); Li and Flanigan (2022  ###reference_b25###); Bonial et al. (2020  ###reference_b7###); Bai et al. (2021  ###reference_b1###) including those in the biomedical domain Garg et al. (2016  ###reference_b16###); Rao et al. (2017  ###reference_b32###).\nFormally, AMR expressions take the form of labeled, rooted, directed, and acyclic graphs, , where  represents the set of AMR nodes, which can be of type predicate, abstract concept and attributes;  represents the possible semantic relations between nodes such as prototypical agent and patient denoted by arg0 and arg1. The AMR graph structure underpinned by Neo-Davidsonian semantics can then effectively encapsulate the abstract concepts, relationships, and entities present in individual sentences or utterances.\nFrom a practical standpoint, AMR expressions encompass the semantic content typically addressed by individual representation schemes such as semantic role labeling Palmer et al. (2005  ###reference_b31###), named entities Wang et al. (2022  ###reference_b38###), and coreference chains Joshi et al. (2020  ###reference_b19###), thereby unifying these diverse aspects of meaning into a single comprehensive representation. Figure 1 illustrates an AMR expression selected from the clinical domain.\n###figure_1### As Figure 1  ###reference_### demonstrates, concepts including events, entities and properties are captured as nodes in the graph, while the relations among the concepts are captured by labeled edges connecting the nodes. Events are represented using PropBank frames Palmer et al. (2005  ###reference_b31###), and the semantic relations of both entities and events to these predicates are specified either by a frame’s numbered argument or one of the relations from AMR’s role inventory. For example, the see-09 predicate represents the event of “visit/consultation by a medical professional.” In this case, the agent of the seeing event is “Dr. Chandler Bing”, represented by see-09’s ARG0 relation, and the semantic role of patient for the event is “she” indicated by the ARG1 semantic relation. AMR graphs also specify the temporal information in a formal way. In the above example, the time of the seeing event is specified by two temporal modifier subgraphs. It is a conjunction of “after now” and “within this week” which makes “later this week” a concrete time range.\nAMR parsers based on pretrained large language models and sequence-to-sequence (encoder-decoder) architectures have demonstrated impressive accuracy when trained and evaluated on standard datasets. The use of AMR parsers has contributed to improved performance across a range of NLP tasks including question answering Fu et al. (2021  ###reference_b15###), information retrieval Liao et al. (2018  ###reference_b27###), knowledge-graph construction Ribeiro et al. (2022  ###reference_b33###), and text generation Bai et al. (2022  ###reference_b2###).\nThese successes have sparked growing interest in employing AMR in domains that diverge from the existing training data, such as human-robot interaction tasks, educational applications involving classroom discourse analysis, and diverse biomedical use cases. Unfortunately, as language form and meaning deviate from the general language captured in generic training data, parsing performance shows a rapid decline. This decline stems from disparities in vocabulary, syntax, and overall discourse structure. Addressing these challenges necessitates dedicated human expert annotation efforts to create domain-specific AMR resources. However, such endeavors can be costly and time-consuming. Hence, the preference lies in maximizing the utilization of existing data and parsers and adapting them to new domains, rather than building entirely new systems from scratch.\nThe contributions of this paper include:\nWe adapted the high-performance SPRING parser Bevilacqua et al. (2021  ###reference_b5###) to the clinical domain, specifically leveraging the Temporal Histories of Your Medical Events (THYME) corpus Wright-Bettner et al. (2020  ###reference_b39###), and achieved state-of-the-art performance in AMR parsing within this context..\nWe demonstrated that by tailoring an existing general domain English neural AMR parser with a relatively modest amount of gold-standard in-domain data, we could attain significantly high accuracy.\nWe showcased data augmentation techniques that effectively enhance the parser’s robustness across different domains."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Data",
            "text": "Supervised training data for AMR parsers consists of pairs of linguistic expressions along with their associated human annotated gold-standard AMR expressions. The current standard dataset for AMR development is AMR 3.0 Knight et al. (2020  ###reference_b22###) available from the Linguistic Data Consortium as LDC2020T02. This general domain dataset is the basis for our baseline efforts prior to domain adaptation. AMR 3.0 consists of over 59k English expressions from a variety of broadcast conversations, newswire, weblogs, web discussion forums, fiction and web text. To facilitate evaluation and model comparison, AMR 3.0 is divided into standard training, development and test splits consisting of 55,635, 1,722, and 1,898 expressions respectively.\nTo adapt AMR to the clinical narrative, we developed 8,327 in-domain AMRs (separate paper with detailed description under review) on a subset of the THYME colon cancer corpus Styler et al. (2014  ###reference_b36###); Wright-Bettner et al. (2020  ###reference_b39###). The colon cancer part of the THYME corpus consists of 594 de-identified physicians’ notes for 198 patients with colon cancer. Each patient is represented by one pathology note and two clinical notes. The corpus has undergone several prior annotation efforts, including temporal and coreference annotation Styler et al. (2014  ###reference_b36###); Wright-Bettner et al. (2019  ###reference_b40###, 2020  ###reference_b39###) and entity tagging as defined by the Unified Medical Language System (UMLS Bodenreider (2004  ###reference_b6###)).\nAs part of our AMR annotation process, we adopted seven clinical-domain named entity (NE) types (anatomical-site, clinical-attribute, devices, disease-disorder, medications-drugs, sign-symptom) from the UMLS project and relied heavily on the UMLS in classifying many AMR concepts.\nLike other genre-specific AMR tasks Bonial et al. (2019  ###reference_b8###); Bonn et al. (2020  ###reference_b9###), we found it necessary to modify the standard AMR annotation approach to support meaningful annotation of domain-unique linguistic phenomena. Two phenomena are pervasive in the clinical narrative. First, physician notes frequently drop eventive mentions when they are inferable by human readers. For example, “Declines tetanus” does not mean the patient declined having tetanus; they declined a tetanus immunization. We expanded AMR’s guidelines to permit explicit rendering of certain implicit concepts like the immunization:\nSecond, like other specialized domains, clinical texts are rife with semantically dense noun phrases (NPs) Grön et al. (2018  ###reference_b17###). In AMR, NPs must be treated in one of two ways: Either all components are extracted and related (white marble = marble that is white), or they are analyzed as single units of meaning, i.e., NEs (White House). However, semantic compositionality exists on a spectrum Nakov (2013  ###reference_b30###), and many specialized NPs in particular strain the adequacy of a binary approach. This can be seen even in simple clinical NPs: One annotator might decide “blood pressure” is a single, cohesive unit of meaning and annotate it as an NE, while another might decide “pressure” is an extractable property of “blood”. To address this, we implemented a two-pass strategy: In the first pass, for NPs that fell under one of the clinical NE types mentioned above, an experienced annotator made these compositionality judgments and added each unique phrase to a searchable, phrasal NE Dictionary along with an AMR fragment that “defined” the compositionality for each phrase. Annotators then referenced the Dictionary when building the AMR graphs in the second pass. This approach supported consistency and speed of annotation.\nFinally, the THYME corpus contains frequent repetition of many other multiword expressions and phrases. For extremely formulaic phrases, such as those found in Vital Signs sections (Height = 167.60 cm, e.g.), we implemented a template-filling script that deterministically produced the AMRs, again saving significant manual annotation time. Of the 8,327 AMRs, 1,640 were produced by this script; the rest were created manually. The final 8,327 THYME-AMR data are split into training, development and test sets randomly with 4,955, 1,641 and 1,731 sentence-AMR pairs, respectively. All of the model training is conducted on the training set of the AMR 3.0 and THYME AMR corpora. We show the Inter Annotator Agreement between three annotators on 107 THYME-AMRs in Table 1  ###reference_###"
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methods",
            "text": "We treat the AMR parsing task as a supervised machine learning problem and train a parameterized model to map natural language expressions to their corresponding AMR graphs. Various model architectures and training methods and paradigms have been employed over the years Flanigan et al. (2014  ###reference_b13###); Foland and Martin (2017  ###reference_b14###); Lyu and Titov (2018  ###reference_b29###); Cai and Lam (2019  ###reference_b10###); Zhang et al. (2019  ###reference_b42###); Wang et al. (2015  ###reference_b37###); Ballesteros and Al-Onaizan (2017  ###reference_b3###); Fernandez Astudillo et al. (2020  ###reference_b12###); Hoang et al. (2021  ###reference_b18###), resulting in a continuous improvement in the state of the art on the general domain AMR dataset(i.e. AMR 2.0 and 3.0 corpus (LDC2020T2)). However, these improvements are highly dependent on the availability of significant amounts of annotated training data hampering the development of parsers for specific genres and languages other than English. Our approach here is to leverage an existing high-performance parser and adapt it to the clinical domain using the modest amount of domain-specific training data described in the last section.\nMeanwhile, the great advances of the pre-trained foundational models has introduced a new modeling paradigm in the field of NLP as well as to structure-prediction problems such as AMR parsing. In particular, the sequence-to-sequence modeling, originally developed for machine translation, has proven a highly effective approach for AMR parsing Bevilacqua et al. (2021  ###reference_b5###); Konstas et al. (2017  ###reference_b23###); Xu et al. (2020  ###reference_b41###). In this approach, two neural network components are involved: an encoder, which takes the natural language sentence as input and maps it to a continuous manifold as a sequence of high-dimensional vectors, and a decoder, which takes the embedded sentence representation vectors and maps them to the output embedding space, corresponding to the target sequence tokens.\nHere we make use of the SPRING parser Bevilacqua et al. (2021  ###reference_b5###), one of the state-of-the-art AMR parsers on AMR 3.0 evaluation. The underlying pre-trained language model is BART-large Lewis et al. (2020  ###reference_b24###), a transformer-based language model that has been trained using a set of denoising pre-training objectives, such as a masked language modeling objective and a document reconstruction objective, on general domain unlabeled English text. The neural network architecture relies on the self-attention and cross-attention mechanism to learn patterns from natural language texts. This pre-trained model is then fine-tuned on the AMR 3.0 training data to map English inputs to linearized AMR graphs, which consist of a sequence of AMR tokens. We show the linearization correspondence of an AMR graph to its sequence of AMR tokens in Figure 2  ###reference_###.\n###figure_2### A critical aspect of using sequence-to-sequence models for structured prediction tasks, like parsing, is transforming the task itself. In AMR parsing, the AMR graph is converted into a sequence of tokens through a linearization algorithm. Note that the vocabulary of the decoder differs from that of the encoder model, as the target sequence consists of AMR-specific tokens such as the relations arg0 and arg1, and predicates like test-01. During fine-tuning, we utilize the vocabulary derived from the AMR 3.0 corpus, which ensures consistency and accuracy in the parsing process. The parsing problem is then to convert an input text sequence into a valid sequence of AMR tokens that can be deterministically transformed into a directed AMR graph. The overall SPRING approach is depicted in Figure 3  ###reference_###.\n###figure_3### Given a high-performing SPRING model, we adapt it to the THYME domain by fine-tuning on the THYME-AMR training set (4,955 expressions). Here, fine-tuning involves continuous gradient-based updates to the original model parameters with a small learning rate () with batch size to be 20, we keep the maximum sequence length to be 1024.."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Evaluation",
            "text": "The standard metric to evaluate AMR parsing performance is SMATCH, which decomposes an AMR graph into triples that capture the edge list representation of a graph structure. For instance, the AMR for the sentence “He had never undergone a screening colonoscopy.” can be decomposed into its edge list representation as AMR1 and edge list 1 as follows:\nWe conjured another slightly altered AMR2 with the he node replaced with a she node, indicating a potential mistake in the parser generated AMR. In the above decomposition of AMR graphs, instance() represents the nodes in the graph while the rest are the edges. Given the edge lists for a hypothetical parse and its corresponding gold-standard parse, the SMATCH metric produces precision (p), recall (r), and F1-measure scores as follows:\nA complication in computing these scores is that we need to know which of the proposed AMR nodes in the parse are supposed to correspond to which ones in the correct set. In other words, the graphs need to be matched before they can be scored. This issue originates from the encoding of AMR nodes with variables, through which different instantiations of a concept can be encoded. The standard SMATCH scorer Cai and Knight (2013  ###reference_b11###) employs a greedy heuristic method to provide the required alignment to avoid computing a computationally expensive optimal alignment.\nFinally, AMR representations are an amalgamation of semantic representations including predicate-argument relations, named entities, and coreference components. The SMATCH score represents an average over these component categories, obscuring the model performance over the various categories of information in AMR expressions, thus making it difficult to assess the usability of the results in downstream applications. To address this, a more fine-grained analysis tool111https://github.com/mdtux89/amr-evaluation  ###reference_### provides precision, recall and F1 measures across the various component AMR tasks. We will discuss the fine-grained categories in section 4.3  ###reference_###."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "We present the domain adaption training experiments in this section to show the characteristics of the text from THYME corpus when it comes to AMR parser development. Recent advancements in AI have significantly impacted art generation, enabling the creation of unique and sophisticated artworks. Techniques such as Generative Adversarial Networks (GANs) and neural style transfer have revolutionized digital art by allowing machines to learn and replicate distinctive styles and patterns."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Domain Adaptation",
            "text": "Table 2  ###reference_### provides the results of our primary domain adaptation experiments. The first column presents the evaluation results of the off-the-shelf SPRING AMR parser trained solely with the AMR 3.0 training data. The 83.0 SMATCH score for the SPRING parser reaches near state-of-the-art performance on the AMR 3.0 test set, whereas, the performance on the THYME-AMR test set is significantly lower at 51.7 SMATCH. The second column shows the results of the same parser fine-tuned using the THYME-AMR training data. Here, we see that the fine-tuned parser achieves excellent results on the THYME-AMR corpus test set with a 35.3 point absolute improvement over the original model. \n\nArtificial intelligence has made significant strides in the generation of art, with models such as DALL-E and Midjourney demonstrating the ability to create intricate and imaginative visual content. These AI systems leverage deep learning techniques, including GANs and transformers, to produce artwork that often rivals human creativity, transforming the landscape of digital art."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Avoiding Forgetting",
            "text": "Catastrophic forgetting is a frequently observed problem when fine-tuning large pre-trained models on domain specific data Li and Hoiem (2018  ###reference_b26###); Riemer et al. (2019  ###reference_b34###); Scialom et al. (2022  ###reference_b35###). While fitting the model’s parameters to the new domain, there is often a significant loss in terms of the model’s performance on its original domain. To assess the robustness and potential forgetting of general domain AMR knowledge, we evaluated the THYME-AMR fine-tuned parser on the AMR 3.0. The results showed a decrease in performance from 83.8 to 77.0, indicating significant forgetting of the general domain AMR. Based on this observation, we deployed a joint training approach to mitigate this forgetting phenomenon. In this experiment, we fine-tuned the parser on a mixture sampled from both the AMR 3.0 and THYME-AMR data. Considering the differing sizes of the two corpora, we sampled them in a 12-to-1 ratio between THYME-AMR and AMR 3.0 sources. As can be seen from Table 2  ###reference_###, this modest infusion of general domain data allowed the parser to attain high performance on the THYME-AMR test set while also largely maintaining its performance on the AMR 3.0 test set. This observation underscores the effectiveness of domain-specific annotation in improving semantic parsing in a joint fashion. This means that the understanding of semantics improves collectively rather than independently, thanks to domain-specific data. As more representative data are collected, we expect further improvements in the parser’s performance, making it even more adept at comprehending the semantics in the given domain.\n\nIn recent years, AI has become instrumental in generating art, with advancements in models like GANs and transformer networks. Works by Elgammal et al. (2017) and Yang et al. (2022) illustrate AI's ability to produce innovative and aesthetically compelling pieces. By leveraging neural creativity, these systems challenge traditional concepts of artistry."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Fine-Grained Performance",
            "text": "Artificial Intelligence has notably transformed art generation by employing neural networks such as Generative Adversarial Networks (GANs) and transformers, enabling the creation of artworks that mimic human creativity. These models have achieved remarkable results in generating imaginative and stylistically diverse pieces, which continue to blur the lines between machine-generated and human art."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Data Requirements for Successful Adaptation",
            "text": "Manual annotation of AMR data is time consuming and expensive. At the current time, the standard AMR 3.0 still consists of only 60k sentences, nearly 10 years after the initial data release. The results shown in Table 2 raise the question of how much data is actually required to attain high levels of parser accuracy through adaptation. To address this question, we conducted a series of experiments training models with progressively larger snapshots of the available training data. Specifically, we gradually augmented the training set size for each model by random sampling without replacement from the training data (resulting in training sets of size 500, 1,000, 2,000, 3,000, 4,000 and 4,955). The results in Figure 4 illustrate the parser’s performance across these training sets. As can be seen, performance rapidly rises from the non-adapted baseline to 80 SMATCH with 1,000 training examples; the model trained on only 2,000 samples achieves 90% of the performance of our best parser trained on all available training data. This rapid improvement with domain specific data is a positive indication of the effectiveness of continued training from a generic model and its ability to rapidly generalize from the domain-specific data.\n\nAI has revolutionized art generation, exemplified by advancements in machine learning models such as GANs (Generative Adversarial Networks) and diffusion models. These techniques enable the creation of high-quality, unique artworks, challenging traditional boundaries and influencing contemporary art practices. Recent models have demonstrated significant capabilities in mimicking various artistic styles."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Discussion",
            "text": "Our results have highlighted the advantages of employing data augmentation techniques for domain adaptation fine-tuning. This opens up the possibility for additional follow-up studies, including the incorporation of data from domain-specific Propbank roleset development. For instance, in the case of THYME, leveraging example sentences for newly added named-entity types like “anatomical-site” could prove beneficial. Initializing the word embedding vectors with such domain-specific concepts would enable a better fit with the pre-trained foundational models. Future investigations involving more sophisticated foundational models and data augmentation approaches hold great promise for enhancing AMR parsing in the medical domain and other specialized domains. By harnessing the capabilities of cutting-edge language models and innovative data augmentation strategies, we can expect significant advancements in semantic parsing tasks and domain adaptation techniques.\nWith these advances, AMR parses have wide applicability to core information extraction tasks from the clinical narrative such as entity recognition, negation detection, uncertainty detection, coreference, temporality and relation extraction."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In our investigation, we have presented substantial evidence highlighting the critical role of domain-specific AMR annotations in the context of domain adaptation. Our findings illuminate how variances in the distribution between original and target domains can precipitate a marked decline in the performance of AMR parsing. This phenomenon underscores the challenge of catastrophic forgetting, a significant hurdle in the training of neural network models where new learning can disrupt previously acquired knowledge.\nTo counteract this issue, we demonstrated the critical role of data augmentation techniques. Specifically, by integrating domain-specific examples into the training dataset, we significantly bolstered the model’s capability to acclimate to the nuances of the new domain while preserving its proficiency in the original domain. This strategic approach of coupling domain-specific annotation with thoughtful data augmentation has emerged as a formidable solution, ensuring both the robustness and accuracy of AMR parsing across different domain adaptation scenarios.\nOur study reaffirms the indispensability of domain-specific annotation in achieving effective domain adaptation and also supports data augmentation as an essential tool in maintaining a delicate balance between learning new domain characteristics and retaining essential knowledge from the original domain. This balanced approach provides a promising avenue for future research and development in the field of AMR parsing, potentially paving the way for more nuanced and adaptable AI systems capable of navigating other domains with limited data yet maintain robustness."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations and Future Work",
            "text": "Our study faced constraints primarily due to computational limitations, which necessitated a focus on a specific subset of model and data augmentation strategies. A reasonable extension of this research could involve the exploration of more advanced foundational models, including GPT-3.5, GPT-4, and their publicly accessible counterparts such as LLAMA. These platforms present opportunities for experimenting with zero- or few-shot learning techniques. Importantly, our use of clinical data mandates adherence to stringent privacy standards; thus, it is imperative that any models employed can be locally installed and operated within a secure, firewall-protected environment. This requirement currently excludes the use of proprietary models like those within the GPT family, which are tailored for commercial applications and do not meet the privacy criteria essential for our research objectives."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "Acknowledgements",
            "text": "This research and the paper it informs have been funded by the United States National Institutes of Health (grants R01LM010090, R01LM013486). The content is solely the responsibility of the authors and does not necessarily represent the official views of the United States National Institutes of Health. The results presented in this paper were obtained using the Chameleon testbedKeahey et al. (2020  ###reference_b21###) supported by the National Science Foundation. We wish to extend our heartfelt gratitude to Ahmed Elsayed and Gaby Dinh for their exceptional annotation efforts, without which this research would not have been possible. Additionally, we are deeply appreciative of the thorough discussions and invaluable suggestions from Skatje Myers, Steven Bethard, David Harris, Timothy Miller, Danielle Bitterman, Piet de Groen, and Dmitriy Dligach."
        }
    ]
}