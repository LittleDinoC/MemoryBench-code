{
    "title": "EBBS: An Ensemble with Bi-Level Beam Searchfor Zero-Shot Machine Translation",
    "abstract": "The ability of zero-shot translation emerges when we train a multilingual model with certain translation directions; the model can then directly translate in unseen directions. Alternatively, zero-shot translation can be accomplished by pivoting through a third language (e.g., English). In our work, we observe that both direct and pivot translations are noisy and achieve less satisfactory performance. We propose EBBS, an ensemble method with a novel bi-level beam search algorithm, where each ensemble component explores its own prediction step by step at the lower level but they are synchronized by a “soft voting” mechanism at the upper level. Results on two popular multilingual translation datasets show that EBBS consistently outperforms direct and pivot translations as well as existing ensemble techniques. Further, we can distill the ensemble’s knowledge back to the multilingual model to improve inference efficiency; profoundly, our EBBS-based distillation does not sacrifice, or even improves, the translation quality.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Machine translation is a widely applicable NLP task that translates a text from a source language to a target language Brown et al. (1990  ###reference_b6###); Bahdanau et al. (2015  ###reference_b2###).\nThe Transformer architecture Vaswani et al. (2017  ###reference_b49###) and pretrained large language models Radford et al. (2019  ###reference_b38###); Raffel et al. (2020  ###reference_b39###); Lewis et al. (2020  ###reference_b29###) have largely improved translation performance, especially in the supervised setting, where a model can learn from large volumes of parallel corpora.\nHowever, machine translation remains challenging for low-resource languages, because there are not enough data for large neural networks to learn these languages.\nWe specifically focus on multilingual translation in the zero-shot setting, where the system is required to translate between unseen language pairs.\nSince collecting parallel data and training individual models for every translation pair are prohibitively expensive, it is common to build a single multilingual system Johnson et al. (2017  ###reference_b23###); Fan et al. (2021  ###reference_b14###) that can perform translation for all language pairs, most of which are zero-shot translation directions with few exceptions (e.g., English).\nThese models work by prepending a language-indicator token, and zero-shot ability emerges as the model generalizes from trained language pairs to unseen ones (Liu et al., 2021  ###reference_b30###; Wicks and Duh, 2022  ###reference_b55###).\nThe main drawback of such a multilingual model is that they are noisy in the zero-shot setting due to the lack of supervision, and as a result, they tend to generate less satisfactory outputs (Zhang et al., 2020  ###reference_b63###; Liu et al., 2021  ###reference_b30###).\nAlternatively, zero-shot translation can be performed by pivoting (Wu and Wang, 2007  ###reference_b59###, 2009  ###reference_b60###), where the model first translates the input into a high-resource language such as English, which is then translated to the target language.\nHowever, pivoting requires two translation steps, often leading to an accumulation of errors Babych et al. (2007  ###reference_b1###); Gu et al. (2019  ###reference_b17###).\nIn this paper, we propose a multi-pivot ensemble approach, where we design a novel ensemble method to aggregate direct translation and the predictions made by pivoting through different languages.\nOur ensemble approach overcomes the drawback of direct and pivot translations as it can utilize these multiple weak models, yielding high-quality output text despite lacking parallel data.\nBuilding an ensemble for text generation is nuanced as it involves a sequence of word predictions.\nWord-level ensembles aggregate predictions at each generation step, which is usually achieved by averaging the predicted probabilities Sennrich et al. (2016a  ###reference_b43###); Freitag et al. (2017  ###reference_b15###); Shanbhogue et al. (2023  ###reference_b45###).\nThis may not be ideal for zero-shot translation as the predictions are too noisy, making the averaged probabilities overly smooth.\nOn the other hand, minimum Bayes risk decoding (Bickel and Doksum, 2015  ###reference_b4###, MBR) can be considered a sequence-level voting ensemble, but it is only able to select from weak and noisy candidates given by the direct and pivot translations.\nTo this end, we propose an ensemble decoding algorithm with bi-level beam search (EBBS). Our EBBS performs two levels of beam search at each generation step: at the lower level, beam search is applied individually to each ensemble component; at the upper level, the ensemble maintains a shared beam by voting and synchronizing the candidates (sub-sequences) in individual beams.\nUnlike word-level ensembles Freitag et al. (2017  ###reference_b15###); Shanbhogue et al. (2023  ###reference_b45###), EBBS does not average the predicted distributions, encouraging individual predictors to explore their own preferences;\nunlike sequence-level ensembles Kobayashi (2018  ###reference_b25###); Eikema and Aziz (2020  ###reference_b13###), EBBS does not select from a candidate set, and thus is more flexible since voting is performed throughout the generation process.\nWe conducted experiments on IWSLT (Cettolo et al., 2017  ###reference_b8###) and Europarl (Koehn, 2005  ###reference_b26###), two popular multilingual datasets for zero-shot machine translation.\nResults show that EBBS can generate high-quality translations and outperform existing ensemble techniques.\nIn addition, we used EBBS-generated outputs as the distillation signal to further finetune our multilingual translation model, which largely improves the efficiency while retaining the performance or even surpassing EBBS on Europarl."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "Zero-shot machine translation. With monolingual data, it is possible to accomplish zero-shot machine translation by training language-specific autoencoders that share the same latent space (Lample et al., 2018a  ###reference_b27###, b  ###reference_b28###; Mohiuddin and Joty, 2020  ###reference_b32###). In a multilingual setting, zero-shot ability emerges when a single model is trained with multiple translation directions, allowing it to generalize to unseen directions (Dabre et al., 2020  ###reference_b11###; Ranathunga et al., 2023  ###reference_b40###; Johnson et al., 2017  ###reference_b23###; Fan et al., 2021  ###reference_b14###). A key research direction for multilingual translation is to alleviate task interference among different translation directions (Zaremoodi et al., 2018  ###reference_b62###; Wang et al., 2020  ###reference_b51###). Researchers have developed various parameter-sharing schemes Baziotis et al. (2022  ###reference_b3###); Chronopoulou et al. (2023  ###reference_b9###) and applied optimization-based methods to locate language-specific neurons Wang and Zhang (2022  ###reference_b50###); He et al. (2023  ###reference_b20###); such a model is able to better learn individual translation directions while pooling the knowledge of all languages together. In our work, we use a standard Transformer model following Johnson et al. (2017  ###reference_b23###) and Liu et al. (2021  ###reference_b30###). Our proposed ensemble algorithm EBBS is compatible with the above methods, as it is agnostic to model architectures. Ensemble learning. Ensemble methods integrate multiple machine learning systems to form a stronger one (Dong et al., 2020  ###reference_b12###; Yang et al., 2023  ###reference_b61###). Bagging, a classic ensemble technique, works by training multiple models with different portions of data and combining their predictions by averaging or voting (Breiman, 1996  ###reference_b5###; Bühlmann and Yu, 2002  ###reference_b7###). Another popular ensemble approach is boosting, where multiple models are trained sequentially, with each subsequent model focusing on the mistakes of the previous ones (Schapire, 2003  ###reference_b42###; Hastie et al., 2009  ###reference_b19###; Natekin and Knoll, 2013  ###reference_b34###). Unfortunately, bagging and boosting are not compatible with our setting, because we build a self-ensemble with only a single model. Alternatively, stacking combines the outputs by training a meta-model (Wolpert, 1992  ###reference_b57###; Ganaie et al., 2022  ###reference_b16###), but this does not apply in our zero-shot setting either because we do not have groundtruth signal to train the meta-model. These ensemble techniques nevertheless may be applied to supervised text generation (Freitag et al., 2017  ###reference_b15###; Kobayashi, 2018  ###reference_b25###; Hendy et al., 2021  ###reference_b21###). That being said, they are not ideal as they do not take advantage of the sequential nature of sentences. Unlike previous work, our EBBS performs bi-level beam search, allowing each component to explore its own predictions at every step but synchronizing all individuals by a “soft voting” mechanism. Our approach is specifically suited to the sequence generation process. \n\nAI in autonomous vehicle navigation. Recent advancements in AI have significantly enhanced autonomous vehicle navigation by utilizing deep learning techniques for environment perception and decision-making (Kendall et al., 2021; Chen et al., 2022). Techniques like reinforcement learning enable vehicles to learn from real-world environments, improving route optimization and safe maneuvering (Zhu et al., 2023)."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Approach",
            "text": "In this section, we first explain our ensemble components in §3.1  ###reference_###.\nWe then propose EBBS, a novel ensemble decoding algorithm in §3.2  ###reference_###.\nFinally, we describe in §3.3  ###reference_### knowledge distillation with EBBS-decoded outputs to improve efficiency."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Ensemble Components",
            "text": "In this work, we focus on zero-shot multilingual machine translation, which requires a system to perform translations for multiple languages, where some translation directions are unseen.\nSpecifically, our multilingual model is an encoder–decoder Transformer with a byte pair encoding tokenizer (Sennrich et al., 2016b  ###reference_b44###) shared among all languages. The encoder can capture the semantics of tokens in any language, whereas the decoder translates the encoded text into the desired language based on a target-language indicator Johnson et al. (2017  ###reference_b23###); Fan et al. (2021  ###reference_b14###).\nWe follow the standard English-centric training (Johnson et al., 2017  ###reference_b23###; Liu et al., 2021  ###reference_b30###), where the multilingual model is trained with parallel data with English on one of the sides (e.g., German-to-English and English-to-Romanian). The zero-shot ability emerges during such training, and the model is able to translate directly between unseen language pairs (e.g., German-to-Romanian), known as direct translation Dabre et al. (2020  ###reference_b11###); Ranathunga et al. (2023  ###reference_b40###). An alternative approach is pivot translation, where the multilingual model performs two translations using a high-resource language as a pivot (e.g., first translating German to English, and then English to Romanian).\nHowever, both direct and pivot translations have major weaknesses: the quality of direct translation tends to be low due to the lack of parallel data, whereas pivot translation suffers from an error accumulation as it requires two translation steps (Babych et al., 2007  ###reference_b1###; Gu et al., 2019  ###reference_b17###).\nIn this paper, we would like to build a self-ensemble of the multilingual model to boost translation quality, where direct and pivot translations are our ensemble components.\nHowever, standard ensemble methods such as averaging and voting may not work well for text generation. Voting, for example, chooses the most voted prediction, but in text generation, the components’ votes often do not share anything in common, because there could be tens of thousands of tokens in the vocabulary.\nAn averaging ensemble, on the other hand, averages the predicted distributions of all components, potentially leading to an overly smooth distribution. As reported in a pilot study in the appendix of Fan et al. (2021  ###reference_b14###), a multilingual averaging ensemble only achieves a small improvement over direct translation. Overall, ensemble methods have not been widely explored for zero-shot multilingual translation in previous literature."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Our Proposed EBBS Algorithm",
            "text": "###figure_1### To this end, we propose an ensemble with bi-level beam search (EBBS), a novel decoding framework that enables different ensemble components to collaborate and vote on each other’s partial generations with two levels of beam search.\nAt the lower level, each ensemble component performs beam search individually, exploring its own preferred regions of the sentence space.\nAt the upper level, EBBS synchronizes the lower-level beam candidates through a voting mechanism, only keeping the most promising partial generations in a shared, upper-level beam.\nThis allows the ensemble components to vote out spurious partial candidates and improve zero-shot translation performance.\nConcretely, we assume there are  ensemble components , each predicting the probability of the next word given some prefix.\nFor the th decoding step, EBBS initializes a shared, upper-level beam , suggesting that a sequence is forced to start with a special token bos with probability .\nFor step , each ensemble component performs a lower-level beam search individually, based on the prefixes in the last step’s shared beam :\nfor . Here,  selects -many sequences with the highest probabilities,  represents string concatenation,  is the vocabulary, and  is the th ensemble component’s predicted probability at step  given the prefix  and input .\nAt the upper level, EBBS synchronizes the individual beams , for , into a single, shared,\nupper-level beam through a soft voting mechanism, where the candidate set  is the union of the sequences in individual beams:\nThen, we evaluate each candidate in  and compute its overall vote as the sum of the probabilities.\nIn this way, the upper level synchronizes every ensemble component with the shared beam  for the next step of generation.\nIntuitively, our voting scheme gives an ensemble component -many votes, each weighted by the predicted probability. The votes (probabilities) are then tallied (summed) for each candidate to form the upper-level beam.\nOur bi-level beam search terminates when we have -many terminated sequences in the shared beam, and returns the sequence with the highest score111For selecting the final output, we follow standard implementations and normalize the joint probabilities by length, i.e., taking the geometric mean of step-wise probabilities (Wolf et al., 2019  ###reference_b56###; Ott et al., 2019  ###reference_b35###). Otherwise, beam search algorithms are often biased towards short sequences.\n as the ensemble output. We provide the detailed pseudocode for EBBS in Algorithm 1  ###reference_### and an illustration in Figure 1  ###reference_###.\nDiscussion. As shown in Algorithm 2  ###reference_### (Appendix A  ###reference_###), traditional beam search keeps a fixed-size beam of high-likelihood partial sequences. It is tempting to combine such vanilla beam search with multiple predictors by directly averaging their probabilities\n as the score for beam search (Line 8, Algorithm 2  ###reference_###), which has been experimented in previous work Sennrich et al. (2016a  ###reference_b43###); Shanbhogue et al. (2023  ###reference_b45###).\nHowever, our intuition suggests that such an approach may suffer from the over-smoothing problem Wei et al. (2019  ###reference_b52###); Wen et al. (2023b  ###reference_b54###): when multiple translations (known as modes) are plausible given an input, the ensemble process will overly smooth out the modes by probability averaging.\nBy contrast, EBBS allows each ensemble component to explore its own mode (Lines 4–11, Algorithm 1  ###reference_###). In Figure 1  ###reference_###, for example, the top sequence yields two plausible next tokens, suggested by each component in the lower level. Their probabilities are not smoothed out in our approach, unlike averaging ensembles. The upper level performs soft voting (Lines 12–19, Algorithm 1  ###reference_###) so as to maintain tractable inference."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "EBBS-Based Distillation",
            "text": "To improve inference efficiency, we may perform knowledge distillation based on the outputs of our EBBS algorithm.\nIn particular, we follow Kim and Rush (2016  ###reference_b24###) and apply a sequence-level knowledge distillation loss, treating the output  of our ensemble (called a teacher) as the pseudo-groundtruth for finetuning the multilingual translation model (called a student):\nOur self-distillation is an ensemble-then-distill process. This differs from a straightforward practice of multi-teacher distillation, where the student learns from the union of teachers’ outputs Wu et al. (2021  ###reference_b58###). The commonly applied cross-entropy loss is known to yield overly smooth distributions Wen et al. (2023a  ###reference_b53###, b  ###reference_b54###), and the problem becomes more severe with multiple teachers, leading to unsatisfactory performance of union distillation Shayegh et al. (2024  ###reference_b46###). By contrast, our approach provides the student with a consolidated pseudo-groundtruth translation for an input, causing less confusion during the distillation process especially when teachers disagree with each other."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": ""
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Settings",
            "text": "Datasets. We evaluated EBBS on two popular benchmark datasets for zero-shot machine translation: IWSLT (Cettolo et al., 2017  ###reference_b8###), which contains 4 languages (with English) and 6 zero-shot directions; and Europarl v7 (Koehn, 2005  ###reference_b26###), which contains 9 languages and 56 zero-shot directions.\nMetrics. We evaluated translation quality with BLEU scores (Papineni et al., 2002  ###reference_b36###), which measure the -gram overlap between generated and reference translations.\nIn particular, BLEU denotes the -gram overlap, and BLEU denotes the geometric mean of BLEU for  with a brevity penalty.\nWe used the standard SacreBLEU Post (2018  ###reference_b37###), following recent translation studies Liu et al. (2021  ###reference_b30###); Scao et al. (2022  ###reference_b41###).\nModel architecture.\nWe replicated Liu et al. (2021  ###reference_b30###) and trained a multilingual system as our base model.\nSpecifically, we had a 5-layer encoder–decoder Transformer for IWSLT, but used an 8-layer Transformer for Europarl to accommodate more training data and languages.\nWe also followed Liu et al. (2021  ###reference_b30###) and removed residual connections in certain middle layers of the encoder (2nd layer for IWSLT; 2nd and 4th layers for Europarl). Liu et al. (2021  ###reference_b30###) show weakening positional correspondence between layers can significantly improve zero-shot performance, which was also observed in our replication experiments.\nMore details about our experimental setup can be found in Appendix B  ###reference_###."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Competing Methods",
            "text": "We compare our EBBS against the following methods, including pivoting and different ensembles.\nEnglish pivoting. Pivoting is commonly applied for translation (Wu and Wang, 2007  ###reference_b59###, 2009  ###reference_b60###; Vamvas and Sennrich, 2022  ###reference_b47###), and we used English as the pivot in our setting because we have parallel data for translations both from and to English.\nWord-level averaging ensemble. Averaging is one of the most widely used ensemble techniques in text generation (Sennrich et al., 2016a  ###reference_b43###; Freitag et al., 2017  ###reference_b15###; Shanbhogue et al., 2023  ###reference_b45###). Essentially, the ensemble components’ probabilities are first averaged before being fed to the standard beam search (Algorithm 2  ###reference_###).\nWord-level voting ensemble. The voting ensemble, common in classification tasks, picks the output class based on the number of votes from ensemble components (given by ).\nHowever, voting is not common in text generation, because  may select completely different words by the ensemble components due to the large vocabulary size, making voting ineffective.\nAs a remedy, we pick the word by the highest probability when there is a tie for votes.\nSequence-level voting ensemble. Minimum Bayes risk decoding is originally designed as a single-model decoding algorithm, where it selects a sequence from a set of beam search results based on similarity (Eikema and Aziz, 2020  ###reference_b13###; Müller and Sennrich, 2021  ###reference_b33###). Here, we use it as a sequence-level ensemble technique, where the candidates are the output sequences from different ensemble components.\nLet  be the set of candidate outputs given by  ensemble components. The best output is selected as\nwhere  computes the BLEU score between a hypothesis  and a reference .\nIn essence, MBR selects an output that resembles others most, using BLEU as the similarity metric."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Results and Analysis",
            "text": "Main results.\nWe first replicated the base multilingual model Liu et al. (2021  ###reference_b30###). As shown in Rows 1–2, Table 1  ###reference_###, the results are generally close, indicating that the replication is successful and ready for our ensemble research. Further, we tried English pivoting (Row 3), a common zero-shot translation method.\nIn our experiments, we find that it does not outperform direct translation, as pivoting methods may suffer from the error accumulation problem since it requires two steps of translation.\nWe then compare different ensemble techniques, including the proposed EBBS and alternative ensemble methods.\nSpecifically, we notice that IWSLT contains four languages (with English); thus we have two available pivoting directions (excluding source and target), which, along with direct translation, are our three ensemble components. For Europarl, it contains nine languages; for performance and efficiency concerns (to be shown in Figure 2  ###reference_###), we also consider three translation paths as our ensemble components: direction translation, English pivoting, and a second pivot.222We use the first available language in the order of Spanish, German, and French. For example, Spanish-to-German translation will have to use French as the pivot. These languages are chosen because they have the most content on the Internet according to the Web Technology Surveys (https://w3techs.com/technologies/overview/content_language  ###reference_content_language###), allowing us to better simulate real-world applications.\nWe start by studying the standard ensemble technique of word-level averaging (Row 4), which has been used in previous translation research (Freitag et al., 2017  ###reference_b15###).\nIn particular, our averaging ensemble performs worse than direct translation on IWSLT, but is slightly better on Europarl. Our results are not consistent to Freitag et al. (2017  ###reference_b15###), who show a word-level averaging ensemble of random seeds can improve performance. This is understandable because models trained with random seeds exhibit similar behavior, and averaging their probabilities achieves a denoising effect. However, our ensemble components are drastically different in terms of their strengths and expertise, because they learn diverse translation patterns from different languages.\nThus, word averaging fails to improve translation quality in our setting.\nAlternatively, voting ensembles can also be applied, at either the word level or the sequence level.\nAs seen, word-level voting is not effective, as it does not achieve significant improvements (Row 5).\nThis is expected because the voted words (top predictions) by the ensemble components may not overlap due to the large vocabulary size.\nIn such cases, the algorithm defaults to choosing the word with the highest probability, causing the ensemble to follow the most peaked distributions.\nSequence-level voting should also be done in a soft manner, and minimum Bayes risk (MBR) decoding can be thought of as using a Bayes risk to softly “vote” the candidate outputs. As seen from Row 6, such a method works relatively well on Europarl, achieving the second-highest performance across all competing methods; however, it works poorly on the IWSLT dataset.\nThe main drawback of sequence-level voting is that it can only select one of the ensemble components’ outputs.\nThis may not work well when the individual ensemble components are weak, as in our zero-shot setting, and especially with the IWSLT dataset due to a relatively small training set.\nSuch a selective sequence-level ensemble cannot integrate different expertise of its components during generation.\nUnlike existing ensemble methods, our EBBS algorithm achieves the highest performance in most directions on both datasets. Notice that Europarl contains 56 zero-shot directions; due to the space limit, we can only present in Table 1  ###reference_### the first seven directions based on the order provided by the dataset. Table 2  ###reference_### further shows a pairwise comparison against direct translation (a strong baseline in our experiment) in all zero-shot directions.\nAs seen, EBBS achieves higher performance in 56 out of 62 cases across two datasets, showing strong statistical evidence for its effectiveness, with a -value of 3e-11 in a two-sided binomial test.\nAnalysis of voting methods in EBBS. In our EBBS algorithm, the lower-level beams are synchronized into a shared upper-level beam by voting.\nSpecifically, EBBS uses a sum-voting mechanism, where we add the ensemble components’ probabilities for each appearance of a candidate in the lower-level beam, shown in Eqn. (3  ###reference_###).\nHere, we analyze a few alternative voting methods for EBBS.\nIf EBBS adopts total-sum voting, it still uses lower-level beams to find candidates, but adds all components’ probabilities together. This is equivalent to applying the common averaging ensemble to the top- candidates. However, it\ndiffers from our approach, because in total-sum voting, a component will vote even if the candidate does not appear in its own lower-level beam; the probability after voting in Eqn. (3  ###reference_###) is substituted with .\nAs shown in Table 3  ###reference_###, EBBS with total-sum voting performs worse than direct translation, suggesting the importance of ignoring the components whose lower-level beam does not contain the candidate. This is analogous to nucleus sampling Holtzman et al. (2019  ###reference_b22###), where the long tail of a distribution is mainly noise and should be ignored.\nOther voting schemes that EBBS may use include 0/1 voting and max voting.\nThe former selects the candidates that appear most in the lower-level beams, disregarding the probability values (unless for ties);\nthe latter chooses the maximum probability across the lower-level beams, which gives preference to sequences through a maximization bias (Hasselt, 2010  ###reference_b18###; van Hasselt et al., 2016  ###reference_b48###).\nAs seen in Table 3  ###reference_###, EBBS performs relatively well with both of these voting schemes, achieving a decent improvement over the baseline approach;\nhowever, their performance is consistently worse than our sum voting scheme.\nOverall, our bi-level beam search ensemble is effective with different voting schemes (except for the total-sum voting), and our sum voting works the best among these variants.\nAnalysis of ensemble components. In Table 4  ###reference_###, we analyze our ensemble components to better understand our ensemble technique for zero-shot machine translation. As seen, direct translation is an effective approach, which is consistent with previous literature Fan et al. (2021  ###reference_b14###); Liu et al. (2021  ###reference_b30###). English pivoting achieves higher BLEU scores for some  but lower for others; its overall BLEU is slightly worse than direct translation in our experiment, as it has the error accumulation problem. Pivoting through non-English languages degrades the performance to a large extent because lacking supervision along the pivoting path leads to two steps of zero-shot translation.\nNotably, EBBS can achieve a solid improvement (~0.6 BLEU points) over the baseline despite including weak ensemble components (e.g., Finnish pivoting, which is almost 5 BLEU points lower than direct translation).\nIf we limit the ensemble components to the strong ones (top-3), EBBS can achieve an even higher improvement of ~0.8 BLEU points.\nThis analysis highlights the robustness of our EBBS algorithm.\n###figure_2### We further study how EBBS performs with different numbers of ensemble components.\nSpecifically, we analyze two incremental ensemble settings: best-to-worst and worst-to-best. In both cases, we start with direct translation; then we incrementally add the next “best” or “worst” pivot translation according to Table 4  ###reference_###.\nFigure 2  ###reference_### shows the trends of incremental ensembles. If we add best pivot directions, the performance peaks at three ensemble components; interestingly, the inclusion of weaker components does not affect EBBS much.\nOn the other hand, adding the worst pivot translation leads to an immediate drop of 1.6 BLEU points, which then largely recovers with the second pivot.\nThis is reasonable because the worst pivot (Finnish) is 4.6 BLEU points lower than direct translation, and EBBS cannot decide on which of the two ensemble components to trust; despite this, the performance of EBBS is still much better than the average performance of the components.\nWith a second pivot, it gives a third “opinion” when the first two components “disagree.”\nThe performance continues to rise if more and stronger components are added.\nIn fact, our ensemble even surpasses the baseline with 4 weakest pivot translations, each of which is at least 1 BLEU point lower than the baseline. This demonstrates that EBBS is flexible and works well with both strong and weak ensemble components.\nDistillation results. We apply distillation techniques to our ensemble outputs to speed up inference. We follow the same ensemble setting (three components) as in Table 1  ###reference_###, but only focus on Italian-to-Dutch translation because generating the training samples for all 66 zero-shot directions (each containing more than 100K samples) requires significant computing resources.\nWe compare our EBBS-based distillation with two alternatives. A straightforward way to distill from multiple teachers (here, translation paths) is to take the union of teachers’ outputs for training. We also include self-distillation, which does not utilize different translation paths but generates samples by standard beam search for self-training.\nAs seen in Table 5  ###reference_###, self-distillation improves zero-shot translation on both IWSLT and Europarl.\nThis is because the base model has never learned from parallel data between Italian and Dutch, and the self-distillation process enables the multilingual model to further refine its translation capabilities in this zero-shot direction. Similarly, we observe that union distillation also improves performance to some degree, but it is not better than self-distillation.\nThis is consistent with the challenges of one-to-many learning seen in previous work (Wen et al., 2023a  ###reference_b53###, b  ###reference_b54###). In our case, learning from the outputs of multiple teachers in a straightforward manner may confuse the student, failing to consolidate and transfer the teachers’ knowledge.\nIn comparison, EBBS-based distillation consistently outperforms both self-distillation and union distillation, achieving near-EBBS performance on Europarl. For IWSLT, our model even outperforms EBBS, as IWSLT is a small dataset and the high-quality outputs generated by EBBS can largely improve the base model (no distillation) by 2.7 points.\nWe provide an efficiency analysis in Appendix D  ###reference_###, showing that the inference time of EBBS is linear to the number of ensemble components. Overall, our EBBS-based distillation achieves a significant speed up while maintaining, or even improving, translation quality.\nAdditional results. We show additional results in the appendices.\nC  ###reference_###: Analysis of beam size, D  ###reference_###: Analysis of inference efficiency, E  ###reference_###: Entropy of distilled models, and F  ###reference_###: Case study."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this work, we address ensemble-based zero-shot machine translation by directly translating and pivoting through different languages. We further design a novel bi-level beam search algorithm (called EBBS) for decoding. We evaluated EBBS on two popular zero-shot translation datasets, IWSLT and Europarl.\nResults show that EBBS outperforms existing ensemble techniques, and that the high-quality translations produced by EBBS can be used for distillation to improve translation efficiency (and sometimes also quality over EBBS)."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "Our work features both algorithmic design and empirical effectiveness, but may also have limitations.\nFirst, our work focuses on zero-shot translation, due to the background of our project. Nevertheless, the EBBS algorithm that we have developed is a general decoding method and is potentially applicable to various text generation tasks. We are happy to explore this direction as future work, such as building ensembles of large language models.\nSecond, our distillation experiments were conducted on Italian-to-Dutch translation because it appears in both IWSLT and Europarl datasets. We are unable to perform all-direction distillation in this project, because Europarl, say, has 56 zero-shot directions, and distillation techniques require extensive computing resources to generate pseudo-groundtruth sentences. Nevertheless, our distillation results are consistent on both datasets, and therefore, not including all-direction distillation does not hurt the validity of our method. Moreover, our work points to interesting future work, such as iteratively applying our ensemble-then-distill procedure to build a self-improving multilingual machine translation system.\nThird, we have mainly used BLEU (in particular, SacreBLEU) scores to evaluate translation quality, which is standard in multilingual translation research Johnson et al. (2017  ###reference_b23###); Liu et al. (2021  ###reference_b30###); Fan et al. (2021  ###reference_b14###). We are aware of language model-based scores, such as BERTScore Zhang et al. (2019  ###reference_b64###), for evaluating the translation in certain languages, but they may not be appropriate for low-resource languages and are not commonly used in our setting. We have not performed human evaluation either, due to both practical and ethical concerns.\nPractically, it is difficult to find qualified annotators because our multilingual setting requires an annotator to know a large number of languages in addition to English. Ethically, it is inappropriate to ask annotators to study these languages before or during annotation, which is exhausting and may last for extended periods of time. That being said, our work uses the most standard metrics and results are consistent in most BLEU variants on both datasets, with a strong statistical confidence level based on 62 translation directions.\nIn addition, we have provided case studies to further illustrate how our EBBS works.\nTherefore, we deem our evaluation ethical, appropriate, and adequate."
        }
    ]
}