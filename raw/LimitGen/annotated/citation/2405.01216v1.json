{
    "title": "DMON: A Simple yet Effective Approach for Argument Structure Learning",
    "abstract": "Argument structure learning (ASL) entails predicting relations between arguments.\nBecause it can structure a document to facilitate its understanding, it has been widely applied in many fields (medical, commercial, and scientific domains).\nDespite its broad utilization, ASL remains a challenging task because it involves examining the complex relationships between the sentences in a potentially unstructured discourse.\nTo resolve this problem, we have developed a simple yet effective approach called Dual-tower Multi-scale cOnvolution neural Network (DMON) for the ASL task.\nSpecifically, we organize arguments into a relationship matrix that together with the argument embeddings forms a relationship tensor and design a mechanism to capture relations with contextual arguments.\nExperimental results on three different-domain argument mining datasets demonstrate that our framework outperforms state-of-the-art models.\nThe code is available at https://github.com/VRCMF/DMON.git.\n\n\n\nKeywords:â€‰argument structure learning, argument mining",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Argument structure learning (ASL) Moens (2013  ###reference_b24###); Lawrence and Reed (2020  ###reference_b16###) involves detecting and tagging relationships between argumentative components in a text.\nFigure 1  ###reference_### shows an illustrative example of an argumentative structure for a medical report where pairs of sentences are annotated with whether there is a supportive or attacking relationship between them.\nThis problem is a cornerstone in the semantic analysis of natural language text because it helps to elucidate the relational structure.\nConsequently, it helps facilitate more accurate and deeper comprehension of text and hence plays a critical role in various NLP applications such as patient-generated content analysis Mayer et al. (2020  ###reference_b22###); Stylianou and Vlahavas (2021  ###reference_b29###), legal reasoning Poudyal et al. (2020  ###reference_b28###), and opinion mining Niculae et al. (2017  ###reference_b26###).\nDespite of its broad application, solving the ASL task is still challenging due to the complexity of text structures and diversity of relationships.\nMoreover, real-world data often contains inconsistencies and are largely unstructured.\nFully understanding the relationship between two arguments often require contextual knowledge from other arguments, or even their relationships.\nA key challenge posed by ASL is that fully understanding the relationship between two arguments often requires capturing contextual knowledge about other arguments and their relationships.\nIn Figure 1  ###reference_###, to classify the relationship ,\nexamples of contextual argument relationships are  and .\nMayer et al. (2020  ###reference_b22###), Stylianou and Vlahavas (2021  ###reference_b29###) and Galassi et al. (2021  ###reference_b12###) tried to conduct pairwise relation classification for ASL without contextual information, yielding sub-optimal classification performance.\nA more recent attempt by Hua and Wang (2022  ###reference_b13###)\nencodes the contextual arguments with a transformer architecture.\nThis helped to improve its accuracy, but they still ignored the relationships between contextual arguments.\n###figure_1### In this paper, we for the first time propose to exploit contextual argument relationships to solve the ASL task.\nAs shown in Figure 2  ###reference_###, we represent the argument structure as a relationship tensor to capture the contextual information about argument relationships.\nThis also allows us to naturally model the relationships between pairs of arguments that can be bidirectional and asymmetric.\nWe propose a bidirectional learning approach that uses a separate model for each direction.\nMoreover, training is also hampered by the fact that there is limited labeled data for ASL problems due to the high annotation costs.\nTherefore, we propose a cropping strategy that randomly samples a subtensor that maintains the ordering of the selected relationships.\n###figure_2### The main contributions of this paper are the following:\nWe propose a novel approach called DMON to encode contextual arguments and their relationships by connecting the argument structure with a relationship tensor.\nWe propose a bidirectional learning mechanism that allows distinguishing head and tail arguments in a relationship.\nWe design a cropping strategy to handle the scarcity of training data.\nExperimental results on three different-domain argument mining datasets show that our method outperforms state-of-the-art models for the ASL task.\nFirst, we discuss related works in section 2  ###reference_###.\nNext, in section 3  ###reference_###, we provide a detailed description of the DMON framework.\nThen, in section 4  ###reference_###, we present experimental results on two argument mining datasets from different domains and conduct an ablation study to analyze the proposed framework and its outcomes.\nFinally, in section 5  ###reference_###, we summarize this paper.\n###figure_3###"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Argument Structure Learning",
            "text": "Argument Structure Learning is a challenging but essential task in text mining Moens (2013  ###reference_b24###); Lawrence and Reed (2020  ###reference_b16###). Most papers tackle argument relationship classification by performing pairwise ASL and classifying two concatenated sentences due to it simplicity and effectiveness Mayer et al. (2020  ###reference_b22###); Stylianou and Vlahavas (2021  ###reference_b29###); Galassi et al. (2021  ###reference_b12###). In Hua and Wang (2022  ###reference_b13###), argument components and their contextual sentences were encoded together using a RoBERTa encoder to obtain neighboring arguments information. The experimental results demonstrate that incorporating contextual information enhances performance. This method primarily relies on self-attention to capture relationships between the concatenated sentences. However, self-attention can be computationally expensive as it involves computing a pairwise similarity matrix for every token in all argument components. In this paper we explicitly model contextual argumentative relationships and, given that a convolution operation can effectively capture input-data features Alzubaidi et al. (2021  ###reference_b1###); Andreoli (2019  ###reference_b2###); Dumoulin and Visin (2016  ###reference_b7###), we utilize convolutional modules to represent a pair of arguments and contextual pairs of arguments. \n\nThe integration of AI in autonomous vehicles is an evolving research field showing significant promise in enhancing driving safety and efficiency. Neural networks, especially deep learning models, have been instrumental in processing sensor data to enable autonomous decision-making Chen et al. (2015  ###reference_b10###); Bojarski et al. (2016  ###reference_b3###). Reinforcement learning also plays a crucial role, particularly in dynamic decision-making scenarios, like navigation and obstacle avoidance Kendall et al. (2019  ###reference_b15###). However, challenges such as data interpretability and real-time processing remain areas for ongoing investigation."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Structured Learning in NLP",
            "text": "Structured learning (SL) also called structured prediction plays a crucial role in many NLP tasks.\nIt models complex relationships and dependencies within text data to improve the performance of various discourse-related applications, such as sentiment analysis Ein-Dor et al. (2022  ###reference_b9###), and summarization Xu et al. (2020  ###reference_b34###).\nIn argument mining, Niculae et al. (2017  ###reference_b26###) use a structured support vector machine, while Bao et al. (2021  ###reference_b3###) implement transition-based dependency parsing to reveal the argumentative structure."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Method",
            "text": "Problem Setting: Given a document containing  sentences, we treat each one as a potential argument and use  to denote the argument set. We convert  into the set of ordered pairs .\nThe goal of ASL is to classify all relations in the set  with the domain-specific labels contained in the given dataset.\nMethod Overview: We introduce a Dual-tower Multi-scale cOnvolution neural Network (DMON) for the ASL task.\nThe model has four components\n(Figure 3  ###reference_###).\nFirstly, we use an encoder to extract pairwise argument representations.\nGiven that an argumentative graph is a directed acyclic graph (DAG), potential argumentative relationships can be represented as an asymmetric relationship matrix, or as a relationship tensor when it includes the pairwise argument embeddings.\nSecondly, during training, a cropping strategy selects sub-tensors from the relationship tensor.\nThirdly, a bidirectional learning mechanism is applied to the cropped relationship tensors to capture contextual arguments and their relationships. Finally, we employ\nlabel fusion to merge two predicted label matrices into one label matrix.\nDuring testing, we feed full relationship tensors instead of cropped tensors into the model."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Pairwise Arguments Representation",
            "text": "Following the literature Mayer et al. (2020  ###reference_b22###); Hua and Wang (2022  ###reference_b13###); Stylianou and Vlahavas (2021  ###reference_b29###), we treat each sentence as a potential argument.\nTo capture pairwise interactions, we create all possible pairs  and concatenate them with a special token placed between them. Next, we use a linkBERT model to encode the paired arguments into an average pooled embedding with dimensionality .\nWe organize these into a tensor . Figure 2  ###reference_### illustrates how to transform the sentences of a discourse into a relationship tensor.\nEach cell in the relationship tensor represents the concatenation of a coupled argument, which typically consists of two elements: the first element is known as the head argument, while the second element is referred to as the tail argument."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Cropping Strategy",
            "text": "We use a cropping strategy to mitigate scarcity of labeled training data.\nDuring each training iteration, we sample a new sub-tensor  from .\nConcretely, we sample  indices  without replacement from  where  and  is called the window size.\nNow we describe in mathematical notation how these indices induce a sub-tensor.\n represents an element of sub-tensor  whose row and column indexes are  and , and .\nThe cropping strategy keeps the discourse order of arguments and relations of the full relationship tensor in its rows and columns. Because the cropping strategy looks at the sub-graph induced by the selected vertices, it maintains the alignment of contextual arguments (graphâ€™s vertices) and relations (graphâ€™s edges).\nThe cropped relationship tensors are resampled in each training iteration, which can be viewed as a form of data augmentation."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   Bidirectional Learning Mechanism",
            "text": "We have developed a bidirectional learning mechanism to predict the labels of a relationship between its head and tail.\nHead and tail relationship information is captured by applying a multi-scale (1D) convolution on the relationship tensor both horizontally and vertically, respectively.\nBecause the relationship tensor can take into account both short- and long-distance relationships between the argument sentences in a discourse, we leverage a multi-scale residual module (MSRM).\nPrior work Li and Yu (2020  ###reference_b17###) reveals that a multi-filter convolutional layer (similar to an Inception block) can capture varied relationships.\nHowever, Li et al. (2018  ###reference_b18###) stated that the Inception architecture leads to the underutilization of local features.\nTherefore, we choose the MSRM Li et al. (2018  ###reference_b18###) as our base module\nand use different kernel sizes for the convolutional filters to capture the short- and long distance relationships.\nBecause of the asymmetry of the relationships, we apply the MSRM both horizontally and vertically on the relationship tensor to generate predictions while taking into account the contextual argument structure of the discourse.\nFigure 4  ###reference_### illustrates the structure of the MSRM.\n###figure_4### We illustrate here how to capture the contextual arguments and head relationship information using the horizontal branch during trainng with a cropped tensor. Firstly, we obtain the representations of the first row of the relationship tensor,  and pass them into the MSRM.\nWe denote the 1D convolutional layer with kernel size  as .\nWe omit the bias item in the equations and the output  is:\nwhere  represents the ReLU activation function and  is the feature concatenation operation.\nWe repeat the above calculations for  times and we concatenate all output features to get the resulting tensor of the head convolution .\nThirdly, a linear classifier layer consisting of flattened logits are applied to produce the predictions. On the horizontal branch, this is  where  represents the label space dimension.\nThe vertical branch uses the same operations as above but the logits are denoted as .111Note that during testing (inference stage) in the above computations  is replaced by  (number of paired arguments of the full text) and  by .\nThe cross-entropy losses of the horizontal and vertical branches are calculated as follows:\nwhere  are one-hot encoded vectors representing the ground-truth labels.\nWe adopt joint training for the two branch losses and the joint training loss is defined as:\nwhere  and  are scaling factors for the horizontal and vertical branches, respectively."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4.   Label Fusion",
            "text": "During testing,\na confidence voter fuses the label predictions from the horizontal and vertical branches.\nInspired by Vyas et al. (2018  ###reference_b30###) and Weng et al. (2023  ###reference_b31###), we measure the confidence scores of logits by the difference between top- and top- probabilities.\nAssume that we have logits  and ,\nthe difference between the top- and top- probabilities for  is :\nwhere  returns the th largest elements from the given input and  is the softmax function.222Results with other normalization functions (e.g., L1, L2, min-max) did not improve results.\nSecondly, we get the confidence score for the vertical branch  by following the above computations.\nThridly, we\napplied the argmax operation to get the predictions of two branches,  and .\nWe merge two matrices into  based on confidence scores  and .\nThe merging process for the  is:\n###table_1###"
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Experiments",
            "text": "The goal is to evaluate the Macro F1 score (it returns objective results on imbalanced ASL datasets) of the detection and correct classification of argumentative relationships in a discourse, to compare the results with the results of state-of-the-art baselines, and to assess the influence of the proposed components of the DMON model."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Datasets",
            "text": "We conduct experiments in the medical, legal and scientific domains, represented by the AbstRCT Mayer et al. (2020  ###reference_b22###), the Cornell eRulemaking Corpus (CDCP) Niculae et al. (2017  ###reference_b26###), and the SciDTB Yang and Li (2018  ###reference_b35###) datasets.\nAbstRCT: The AbstRCT corpus consists 659 medical documents about the treatment for specific disease (neoplasm, glaucoma, hypertension, hepatitis-b, diabetes).\nFollowing Mayer et al. (2020  ###reference_b22###), the corpus is divided into three datasets based on disease category: neoplasm, glaucoma, and mixed.\nThe neoplasm (neo) dataset contains 350 documents for training, 50 for validation and 100 notes for testing. The neoplasm train set is used as train set for the glaucoma (gla) and mixed (mix) dataset, which each have 100 instances for testing.\nThe labels of the relationships of the three AbstRCT datasets are â€˜attackâ€™, â€˜supportâ€™, and â€˜un-relatedâ€™.\nSciDTB: The SciDTB (SCI) dataset includes 1049 scientific abstracts collected from the ACL Anthology.\nIt consists of 743 examples for training, 154 samples for validation and 152 for testing.\nThe dataset has more fine-grained discourse relationship categories while the number of labels is 27.\nCDCP: The CDCP dataset contains 731 user comments about consumer debt collection practices from an eRulemaking website and include 581 examples for training and 150 for testing.\nLabels of the CDCP dataset are â€˜relatedâ€™ and â€˜un-relatedâ€™."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Experimental Set-up",
            "text": "Model Settings:\nThe maximum sequence length is .\nThe combination of kernel sizes for the multi-scale convolution module is set to .\nThe window size for the cropping is .  and  are set to 0.5.\n and  is set as 1 and 2 in the label fusion part.\nTraining Details:\nWe fine-tune the BioLinkBERT Yasunaga et al. (2022  ###reference_b36###) for the AbstRCT dataset and LinkBERT Yasunaga et al. (2022  ###reference_b36###) for the SciDTB and CDCP dataset.\nFor the training, all baseline models and our framework are trained with FP16.\nWe train all models on a NVIDIA GeForce RTX 3090 GPU.\nAll models use the AdamW optimizer Loshchilov and Hutter (2019  ###reference_b20###) with a learning scheduler initialized at  and linearly decreased to 0.\n###table_2###"
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Baselines",
            "text": "We consider models that classify the argument relationships given a representation of the pairs of sentences obtained with a pretrained encoder.\nAMPERE++ Hua and Wang (2022  ###reference_b13###) uses a Roberta model to concatenate  neighbouring sentences with an argument and only predicts whether this argument is a head or tail argument.\nThe authors did not name this model so we call it AMPERE++.\nBERT Devlin et al. (2019  ###reference_b5###) fine-tunes a pretrained BERT model to encode an argument pair and predict its relationship.\nRoberta Liu et al. (2019  ###reference_b19###) fine-tunes a pretrained Roberta model to represent a pair of sentences and classifies the relationships.\nAMCT-Sci Stylianou and Vlahavas (2021  ###reference_b29###) is similar to Roberta, but encodes argument pairs with a domain-specific BERT model.333https://huggingface.co/allenai/scibert_scivocab_uncased  ###reference_vocab_uncased###\nTransforMED Stylianou and Vlahavas (2021  ###reference_b29###)\nintegrates a medical knowledge system to extract medical entities from arguments.\nThe authors inject medical knowledge into their model by concatenating features of arguments and medical entities.\nWe also consider models that use attention mechanisms to model relationships between arguments.\nRESARG Galassi et al. (2021  ###reference_b12###) used a BiLSTM to extract textual feature and then applied a residual neural network to deal with the ASL task.\nRESATTARG Galassi et al. (2021  ###reference_b12###) extended RESARG with a coarse-grained parallel co-attention mechanism to predict argumentative relations.\nTSP-PLBA Morio et al. (2020  ###reference_b25###) consists of task-specific parameterization (TSP) and proposition-level biaffine attention (PLBA) to capture argument structure from documents.\nTSP encodes the arguments while PLBA predicts argument relations by using a biaffine scoring function.\nWe then consider models that train a transition-based dependency parser.\nBERT-Trans Bao et al. (2021  ###reference_b3###)\nleverage the BERT language model to obtain representation and propose a neural transition-based model to generate a sequence of actions (shift, delete-delay, delete, right-arc, right-arc-delay, and left-arc) that build an argument structure (predicted nodes and relations).\n###table_3###"
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "4.4.   Results and Discussion",
            "text": "We run each model five times with different seeds and report the average macro-F1 scores and their variance obtained on the three absRCT datasets the CDCP dataset and the SciDTB dataset.\nAbsRCT: Table 1  ###reference_### shows that the DMON outperforms all baselines on all average F1 scores.\nCompared with the state-of-the-art model TransforMED, our model improves the average macro-F1 scores by , , and  percentage points on the Neoplasm, Glaucoma, and Mixed datasets, respectively.\nEven though TransforMED explicitly injects external medical knowledge, our approach still performs better.\nSciDTB: Table 2  ###reference_### shows that the DMON outperforms baseline models by a large margin when evaluated on the SciDTB dataset.\nCompared to the Roberta model, our model improves the average macro-F1 scores by , , and  percentage points on Full-F1, F1, and R-F1 scores.\nCDCP: Table 3  ###reference_### shows that DMON also achieves the best performance in terms of average macro-F1 score on the CDCP dataset.\nCompared to the BERT-Trans model\nour method improves the averaged macro-F1 and R-F1 by  and  percentage points, respectively.\nCompared with the BERT-Trans, our model is simple (can be applied to other pairwise classification models) and can achieve better performance.\nAdditionally, BERT is the transformer encoder but the proposed neural transition-based model is to generate a sequence of actions (shift, delete-delay, delete, right-arc, right-arc-delay, and left-arc) that build an argument structure (predicted nodes and relations).\nTo train this transition system, they need to convert argument structure learning data into the transition-based structure data.\nThis preprocessing adds complexity.\nDiscussion: We observe that the performance gains of DMON oompared to state-of-the-art baselines are different when analyzing the results obtained on the three domains.\nFor instance, when comparing with baseline RESATTARG, DMON improves the macro-F1 scores by 13.92, 5.38, 3.74 percentage points on SciDTB, Neoplasm, and CDCP datasets, respectively. The AbstRCT (of which Neoplasm is a part) and CDCP are imbalanced and have a high ratio of sentence pairs that exhibit no argumentative relationship (\"unrelated\" relationship).\nThis could be a reason why DMON has somewhat lower performance gains.\nOn the other hand, AbstRCT and CDCP have few relationship types and it might be that the baselines already deal with these in a satisfactory way, while they have more difficulties with the 27 relationship types of SciDTB.\nFor this more difficult case of argumentative structure learning, DMON has the highest gains in performamce and improves the average macro-F1 scores by , , and  percentage points on all 27 relationship type, on the \"unrelated\" class and on the other 26 relationships, respectively.\nLarge Language Models:\nAs large language models capture the attention of the NLP communities, we conduct a comparison of LLMs with the proposed algorithm.\nWe pick the GPT 3.5 turbo (gpt-3.5-turbo-0613), a widely used LLM, and validate it on the ASL task.\nWe use the in-context prompt learning (ICL) Brown et al. (2020  ###reference_b4###) to validate the ASL task.\nWe found the zero-shot ICL is much worse than the few-shot ICL, so we reported the results of the GPT 3.5 turbo by using the few-shot ICL method.\nExperimental results show the number of the demonstration samples is 2.\nWe report the Macro-F1 scores of the GPT 3.5 on the AbstRCT (gla), AbstRCT (neo), AbstRCT (mix), CDCP and SciDTB datasets, which are 12.03, 13.84, 11.19, 11.89, and 17.24, respectively.\nResults of the GPT 3.5 turbo are much lower than the fine-tuned models, i.e., our DMON model, whose scores are 73.16, 76.30, 74.07, 87.36, and 68.14.\nWe think the reason why the GPT 3.5 performs badly on the ASL datasets is because LLMs fail to deal with tasks which require complex reasoning ability.\n###figure_5### ###figure_6### ###figure_7### ###figure_8### ###figure_9###"
        },
        {
            "section_id": "4.5",
            "parent_section_id": "4",
            "section_name": "4.5.   Ablation Study and Analysis of Results",
            "text": "We conduct ablation experiments to study DMONâ€™s components and analyze them."
        },
        {
            "section_id": "4.5.1",
            "parent_section_id": "4.5",
            "section_name": "4.5.1.   Bidirectional Learning Mechanism and Confidence Voter",
            "text": "Table 4  ###reference_### shows results when ablating the bidirectional learning mechanism and confidence voter. The F1 scores obtained on all datasets are largely reduced if we remove the bidirectional learning mechanism and confidence voter.\nThe macro-F1 scores on all three datasets (Neoplasm, Glaucoma, and CDCP) decrease when we just use the predictions of one of the two branches (i.e., head or tail relationships) and use no confidence voter. The same pattern holds when we directly remove one of two branches when training the model.\nThe macro-F1 score is reduced on the Mixed dataset when we remove the confidence voter and use tail prediction.\nThe macro-F1 shows the same pattern when we only remove the head branch.\n###table_4###"
        },
        {
            "section_id": "4.5.2",
            "parent_section_id": "4.5",
            "section_name": "4.5.2.   Cropping Strategy",
            "text": "We analyze several aspects of the cropping strategy.\nTraining with Different Cropped Tensors: Figure 5  ###reference_### compares results of DMON using cropped tensors with the results of using the full relationship tensor as input.\nWe observe that DMON using cropped tensors outperforms DMON with the full tensor on the four datasets.\nUsing the cropping strategy improves the macro-F1 score of our framework by , , , , and  percentage points on Neoplasm, Glaucoma, Mixed and SciDTB datasets, respectively. The cropped tensors offer more variation in the training data, and its representations contribute to the generalization capabilities of the model.\n###table_5### Information Alignment: To study the information alignment of the cropping with the original relationship tensor, we develop two shuffle approaches called order shuffle (ord) and\nrandom shuffle (rad).\nord scatters the order of the arguments, that is, horizontal and vertical indexes of the cropped relationship tensor are shuffled.\nrad randomly chooses pairwise samples to fill the cropped relationship tensor.\nFigure 6  ###reference_### shows an example illustrating the ord and rad approaches.\n###figure_10### Table 6  ###reference_### shows that the macro-F1 score decreases by using the rad method.\nTherefore, it is important to keep head and tail relationships aligned, that is, correctly representing the asymmetric relationships between arguments.\nTable 6  ###reference_### also reveals that the order of the argumentative sentence pairs in the relationship tensor is important as it implicitly captures the coherence of the discourse.\n###table_6### Contextual Windows Size: The results demonstrate that\nencoding contextual arguments and their relationships is beneficial.\nFigure 5  ###reference_### shows the macro-F1 scores by changing the window size of the cropped relationship tensor for the evaluated datasets.\nThe macro-F1 score curve shows an upward trend by encoding more neighboring arguments and relationships, but slightly decreases when considering the full discourse (Table 5  ###reference_###)."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Conclusion",
            "text": "In this paper, we have proposed a novel framework called the Dual-tower Multi-scale cOnvolution neural Network (DMON) to deal with the ASL task that in a flexible way can learn the argumentative DAG structure taking into account contextual argumentative relationships. A sentence or clause on its own seldom fulfils an argumentative role in a discourse, it is only when paired with another sentence and in the context of other sentences that its argumentative role becomes apparent. In an argumentative DAG structure a sentence can have multiple parents and children, and our model can deal with this flexibility.\nWe conduct experiments on four datasets covering the medical, legal and scientific domains, namely abstRCT, CDCP SciDTB and achieve new state-of-the-art performance, when compared to several strong baselines.\nFurthermore, we perform ablations and in-depth analyses to prove the effectiveness of each component of our model."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Acknowledgements",
            "text": "This research was funded by the CHIST-ERA projects ANTIDOTE (ERA-NET CHIST-ERA IV FET PROACT JTC 2019) and iTRUST (ERA-NET CHIST-ERA JTC 2021)."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Bibliographical References",
            "text": ""
        }
    ]
}