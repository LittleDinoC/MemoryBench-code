{
    "title": "CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling",
    "abstract": "Using large language models (LLMs) to assist psychological counseling is a significant but challenging task at present. Attempts have been made on improving empathetic conversations or acting as effective assistants in the treatment with LLMs. However, the existing datasets lack consulting knowledge, resulting in LLMs lacking professional consulting competence. Moreover, how to automatically evaluate multi-turn dialogues within the counseling process remains an understudied area. To bridge the gap, we propose CPsyCoun, a report-based multi-turn dialogue reconstruction and evaluation framework for Chinese psychological counseling. To fully exploit psychological counseling reports, a two-phase approach is devised to construct high-quality dialogues while a comprehensive evaluation benchmark is developed for the effective automatic evaluation of multi-turn psychological consultations. Competitive experimental results demonstrate the effectiveness of our proposed framework in psychological counseling. We open-source the datasets and model for future research. 111https://github.com/CAS-SIAT-XinHai/CPsyCoun",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "\"No health without mental health\" is becoming more than a slogan, with approximately 14% of the global disease burden attributed to neuropsychiatric disorders Prince et al. (2007  ###reference_b16###). Despite the affordability and effectiveness of many mental health treatments, a significant gap persists between those in need and those able to access care Freeman (2022  ###reference_b7###). The World Health Organization (WHO) continually advocates for increased investment to augment understanding and dispel the stigma associated with mental health disorders. Yet, the challenge of ensuring quality, affordable care for mental health conditions remains formidable. Consequently, the identification of novel treatments and enhancement of existing therapies for all mental diseases are key objectives in the research domain.\nThe Natural Language Processing (NLP) community is actively contributing to the advancement of AI-assisted psychological counseling and treatment. Various research topics have been proposed to conduct mental disease counseling Orr et al. (2022  ###reference_b14###); Toleubay et al. (2023  ###reference_b23###), improve emotional support ability Buechel et al. (2018  ###reference_b3###); Rashkin et al. (2019  ###reference_b19###); Liu et al. (2021  ###reference_b12###); Cheng et al. (2023  ###reference_b6###), and provide online psychological consultation Sun et al. (2021  ###reference_b21###).\n###figure_1### The advent of large language models (LLMs) such as ChatGPT 222https://chat.openai.com/  ###reference_chat.openai.com/### and LLaMA Touvron et al. (2023  ###reference_b24###), has spurred more research efforts on generating not just empathetic conversations, but also serving as therapeutic aids and effective assistants in treatment. For instance, Psy-LLM Lai et al. (2023  ###reference_b9###) is a psychological consultation model that leverages the LLM PanGu and is trained with Q&A from professional psychologists and large-scale Chinese psychological articles from public databases. This model demonstrates proficiency in psychological knowledge and counseling services. Parallel to this, other LLM-based psychological models such as MeChat Qiu et al. (2023  ###reference_b18###), SoulChat Chen et al. (2023b  ###reference_b5###) and MindChat Yan and Xue (2023  ###reference_b27###) are also available online. Recent trends in adopting LLMs for psychological counseling focus on generating more interpretable mental health analyses Yang et al. (2023  ###reference_b28###) and simulating psychiatrist-patient interactions Chen et al. (2023a  ###reference_b4###). This shift in focus from generating responses to diagnosing mental health issues as an expert signifies a trend change in research. The quest for interpretability in mental health analysis serves a dual purpose. First, it provides a detailed rationale behind each response, making it more amenable for human evaluation and debugging. Second, the simulation approach not only addresses data privacy concerns but also challenges the traditional symptom collection method via questionnaires. Providing a range of professional skills, this approach enables more effective completion of consultation tasks.\nDespite these advancements, there remains a dearth of authentic counseling datasets from psychological counseling sessions, which include symptom descriptions of the consultant and treatment methodologies employed by the counselor. Such data could offset issues arising from doctor-patient simulations being template-based and lacking control. For example, psychiatrists have observed that chatbots do not typically resemble patients Chen et al. (2023a  ###reference_b4###). However, it’s noteworthy that these diagnoses are generally sensitive, warranting careful attention to potential privacy issues.\nIn addition to the form of psychological counseling conversations, there is a wealth of psychological counseling data in the real world, which is hidden in professional psychological counseling reports. However, due to its structured nature, it is unsuitable for model training.\nIn this paper, we propose a new framework CPsyCoun for Chinese Psychological Counseling, which consists a dialogue reconstruction method based on psychological counseling reports and a benchmark for multi-turn consultation dialogue evaluation.\nSpecifically, we first collect anonymized psychological counseling reports from publicly accessible websites and further propose a privacy shadowing method to postprocess these reports into a dataset CPsyCounR.\nCPsyCounR includes nine types of psychological consultation and seven classic schools of psychological counseling.\nThrough our proposed Memo2Demo dialogue reconstruction method, we construct another dataset CPsyCounD, which contains 3,134 high-quality multi-turn consultation dialogues.\nFurther, we propose a psychological counseling benchmark for automatic evaluation on multi-turn dialogues and fine-tune an open-sourced LLM on CPsyCounD, named CPsyCounX.\nExperimental results from both intrinsic and extrinsic evaluations consistently verify the superiority of the proposed method.\nFigure 1  ###reference_### illustrates the general framework of our proposed CPsyCoun.\nOur contributions are the following:\nTo the best of our knowledge, our work is the first to generate psychological consultation dialogues based on psychological counseling reports, which effectively expands the source of psychological consultation dialogue data. For efficient dialogue reconstruction, we specifically introduce a two-phase method named Memo2Demo.\nWe propose a benchmark for automatic evaluation of multi-turn dialogues in psychological counseling, which includes comprehensive evaluation metrics, datasets and methods.\nWith the help of Memo2Demo, we construct CPsyCounD, a dataset contains 3,134 high-quality multi-turn consultation dialogues. The model CPsyCounX fine-tuned on this dataset outperforms other models in the benchmark, validating the effectiveness of our proposed framework in psychological counseling."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Dialogue Generation and Reconstruction using LLMs",
            "text": "Dialogue generation and reconstruction using LLMs have been proven to be effective in data augmentation and conversation denoising.\nFor example, SAFARI Wang et al. (2023a  ###reference_b25###) harnesses the planning and understanding capabilities of LLMs to generate persona-consistent and knowledge-enhanced responses.\nIn the medical domain, DISC-MedLLM Bao et al. (2023  ###reference_b2###) undertakes real-world dialogue reconstruction for consultation records sourced from medical forums. This process addresses issues of informal language usage and unregulated expressive styles.\nIn the realm of psychology, numerous studies concentrate on augmenting emotional support capability by enhancing empathy.Qian et al. (2023  ###reference_b17###) amplifies empathetic responses by enriching the dialogue context with a commonsense knowledge graph, thereby stimulating the relevant knowledge encoded by LLMs.\nIn this work, we propose a two-phase method for efficient dialogue reconstruction."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Evaluation of Generated Dialogues using LLMs",
            "text": "The search for better automatic evaluation metrics in natural language generation (NLG) has been a hot topic for the natural language processing (NLP) community.\nCompared to conventional lexicon-based metrics like BLEU Papineni et al. (2002  ###reference_b15###) and Rouge Lin (2004  ###reference_b10###), these new metrics capture deeper semantic meaning and usually have better alignment with human judgments.\nThere have been a series of transformer-based evaluation metrics available in the community, such as BERTScore Zhang et al. (2020  ###reference_b31###), BARTScore Yuan et al. (2021  ###reference_b29###) and GPTScore Fu et al. (2023  ###reference_b8###).\nIn specific domains, there are also derivatives of such metrics tailored for the domain.\nFor example, CodeBERTScore Zhou et al. (2023  ###reference_b32###) is proposed to achieve a higher correlation with human preference and with functional correctness.\nCBERTScore Shor et al. (2023  ###reference_b20###) can penalize clinically-relevant mistakes more than others.\nThe same trend continues with LLMs. Wang et al. (2023b  ###reference_b26###) shows that ChatGPT achieves state-of-the-art or competitive correlation with human judgments in most cases.\nA new framework constructed over GPT-4 called G-Eval Liu et al. (2023b  ###reference_b13###) makes use of LLMs with chain-of-thoughts (CoT) and a form-filling paradigm to assess the quality of NLG outputs, outperforming all previous methods by a large margin.\nIn this work, we design a psychological counseling benchmark for automatic evaluation."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "CPsyCoun",
            "text": "###figure_2### ###figure_3### Considering the differences in data sources of our collection, we need to reformat these collected reports according to a uniform standard.\nTo build a comprehensive and helpful dataset, we combine the case format of China’s National Class 2 Psychological Counselor Examination and other psychological counseling literature to regularize collected reports, where the following 6 components are included: Title, Type, Method, Case Brief, Consultation Process and Experience Thoughts.\nNote that the consultation process is written from a third-person perspective and does not contain specific dialog.\nFor a detailed description of components and examples of psychological counseling report, please refer to Appendix A  ###reference_###.\nAccording to statistics, there are about 230 types of psychological counseling cases and more than 250 counseling methods used in psychological counseling.\nConsidering that the classification of the original types is too detailed, we further summarized the case types into 9 representative topics based on common scenarios of psychological counseling.\nThe distribution of counseling topics is shown in Figure 2a  ###reference_sf1###.\nBased on relevant information from the American Psychological Association (APA) and the International Academy of Psychotherapy (IACP), we have categorized the professional counselor’s methods utilized in psychological counseling reports into 7 classic schools of psychological counseling. The distribution of methods is shown in Figure 2b  ###reference_sf2###.\nDirect role-play prompting is utilized as our baseline method for generating multiple rounds of dialogue from a single round, which has been successfully used in previous work on dialogue generation Qiu et al. (2023  ###reference_b18###); Chen et al. (2023b  ###reference_b5###).\nHowever, we believe that there are still aspects for improvement when applying direct role-play prompting to multi-round dialogue generation in the field of psychological counseling:\n(1) Comprehensiveness: Despite presenting high-quality counseling reports to the language model, it may fail to focus on the significant descriptions of the client’s situation within the report, leading to subsequent dialogues that lack completeness.\n(2) Professionalism: Role-playing prompted dialogues merely reference psychological methods in generated dialogues. We hope that language models could integrate these methods into the problem-solving process, thereby obtaining reconstructed dialogue with professionalism.\n(3) Authenticity: Dialogue constructed by the baseline method lacks the emotional interaction between the client and the psychological counselor present in real scenarios, leaving a deficit in terms of authenticity.\nWe present the detailed prompt of role-play method in Figure 6  ###reference_### in the appendix.\nTo address the aforementioned issues of the baseline method, we propose a two-phase framework named Memo2Demo to generate high-quality psychological consultation dialogue from counseling reports. Mirroring real-life scenarios, we incorporate two key roles into this framework: a psychological supervisor together with a psychological counselor. The psychological supervisor guides the psychological counselor on counseling techniques while ensuring the privacy of the clients during the counseling process. Meanwhile, the psychological counselor engages in direct dialogue with the clients to conduct specific psychological counseling. Figure 3  ###reference_### illustrates the general framework of our proposed method Memo2Demo, where a psychological counseling report is first converted into a counseling note by the psychological supervisor, then the psychological counselor generates the multi-turn consultation dialogue based on both the report and the note. We present detailed prompts used for Memo2Demo in Figure 7  ###reference_### and 8  ###reference_### in the appendix.\nIn psychological counseling, the evaluation metrics remain diverse and not universally standardized. For instance, SoulChat Chen et al. (2023b  ###reference_b5###) proposes evaluation metrics: Content, Empathy, Helpfulness and Safety. Some of these metrics hinge on expert evaluations and lack specific scoring criteria, favoring manual rather than objective and automatic evaluations.\nSimilarly, ChatCounselor Liu et al. (2023a  ###reference_b11###) introduces the Counseling Bench, encompassing seven different perspectives. While these metrics are designed to cater to the model’s specific dialogue strategies, they lack the ability to evaluate the overall dialogue effect. They are more adapted to single-round dialogue evaluations and are not suitable for multi-turn dialogues.\nRecognizing the aforementioned limitations in evaluating consultation dialogues, and in order to analyze the counseling case used for dialogue generation, we propose new evaluation metrics for multi-turn consultation dialogues in psychological counseling. These metrics encompass four different perspectives: Comprehensiveness, Professionalism, Authenticity, and Safety, which are used for automatic evaluation in the rest of this paper. For each perspective, we give its description and corresponding score criterion in Appendix C  ###reference_###.\nWe propose a turn-based dialogue evaluation approach to effectively evaluate multi-turn consultation dialogues.\nDenote a -turn dialogue as a set of paired elements , where each  represents a query from the client, and each corresponding  represents the counselor’s reply. We first split it into  single-turn dialogue, then prompt the model with query together with its dialogue history in each single-turn dialogue, resulting in the corresponding single-turn response:\nwhere  signifies the dialogue history before -th turn, and  denotes the inference process of LLMs.\nTo automatically obtain reliable evaluation results,\nWe employ GPT-4 Achiam et al. (2023  ###reference_b1###) to assess these responses, utilizing the evaluation metrics we previously proposed. Concretely, we ask the model to assign an evaluation score  for a single-turn response . Then we average them to yield the total evaluation score of the current -turn dialogue:\nFor detailed prompts of single-turn response generation, please refer to Figure 11  ###reference_### in the appendix.\nSMILECHAT Qiu et al. (2023  ###reference_b18###), a richly diverse and realistic multi-turn dialogue dataset, comprises 56k multi-turn counseling dialogues, averaging 6.36 rounds per dialogue. Given its wide range of dialogue types, we choose it as our base dataset. However, the open-source data of this dataset is not classified by topic type.\nTo address this limitation and conduct a more comprehensive and explainable evaluation of models’ capabilities, we construct a general multi-turn dialogue evaluation dataset with clear topic classification - CPsyCounE. Leveraging the nine common counseling topics we introduce in CPsyCounR, we manually select the five most representative dialogues from SMILECHAT for each topic, resulting in a comprehensive evaluation dataset of 45 cases."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Data Collection",
            "text": "We conduct a survey of publicly available psychological counseling cases online and collect data from well-known Chinese psychological communities.\nThe online communities used in this work are:\n(1) Yidianling 333https://www.ydl.com, a top-tier mental health platform in China, serves approximately 39 million users, backed by a robust network of over 6,000 professional counselors.\n(2) Psy525 444https://www.psy525.cn, another prominent mental health platform in China, caters to over 1 million users and is supported by nearly 30,000 professional counselors.\nAs the data are anonymized by the websites, there’s a low privacy risk.\nTo enhance the security of the collected data, we further conduct an analysis of privacy and security issues about the data.\nThe procedures adopted during data collecting to ensure no sensitive or privacy-related content in the dataset include rule-based cleaning, manual rewriting, and human proofreading.\nAfter cleaning procedures, relevant private information has been completely removed, and we ensure that relevant private information is protected.\nIn total, we collected 4,700 psychological counseling reports in different formats, with a variety of types and counseling methods. These reports will not be released to the public unless a Privacy Data Protection Agreement is signed upon reasonable request."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Data Processing",
            "text": "To construct a high-quality dataset, we carefully selected 3,134 psychological counseling reports.\nThey contain complete methods and types, clear case briefs, detailed consultation processes and experience thoughts. In the selection process, we found that some of the collected reports contained several counseling cases in one report.\nWe did not select this type of report due to multiple cases in one report where the background information of the client and the consultation processes are incomplete.\nTherefore, among the selected 3,134 psychological counseling reports, each report corresponds to only one case. This high-quality report dataset is named CPsyCounR.\n###figure_4### Considering the differences in data sources of our collection, we need to reformat these collected reports according to a uniform standard.\nTo build a comprehensive and helpful dataset, we combine the case format of China’s National Class 2 Psychological Counselor Examination and other psychological counseling literature to regularize collected reports, where the following 6 components are included: Title, Type, Method, Case Brief, Consultation Process and Experience Thoughts.\nNote that the consultation process is written from a third-person perspective and does not contain specific dialog.\nFor a detailed description of components and examples of psychological counseling report, please refer to Appendix A  ###reference_###  ###reference_###.\nAccording to statistics, there are about 230 types of psychological counseling cases and more than 250 counseling methods used in psychological counseling.\nConsidering that the classification of the original types is too detailed, we further summarized the case types into 9 representative topics based on common scenarios of psychological counseling.\nThe distribution of counseling topics is shown in Figure 2a  ###reference_sf1###  ###reference_sf1###.\nBased on relevant information from the American Psychological Association (APA) and the International Academy of Psychotherapy (IACP), we have categorized the professional counselor’s methods utilized in psychological counseling reports into 7 classic schools of psychological counseling. The distribution of methods is shown in Figure 2b  ###reference_sf2###  ###reference_sf2###."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Dialogue Generation Method for Psychological Counseling",
            "text": "Direct role-play prompting is utilized as our baseline method for generating multiple rounds of dialogue from a single round, which has been successfully used in previous work on dialogue generation Qiu et al. (2023  ###reference_b18###  ###reference_b18###); Chen et al. (2023b  ###reference_b5###  ###reference_b5###).\nHowever, we believe that there are still aspects for improvement when applying direct role-play prompting to multi-round dialogue generation in the field of psychological counseling:\n(1) Comprehensiveness: Despite presenting high-quality counseling reports to the language model, it may fail to focus on the significant descriptions of the client’s situation within the report, leading to subsequent dialogues that lack completeness.\n(2) Professionalism: Role-playing prompted dialogues merely reference psychological methods in generated dialogues. We hope that language models could integrate these methods into the problem-solving process, thereby obtaining reconstructed dialogue with professionalism.\n(3) Authenticity: Dialogue constructed by the baseline method lacks the emotional interaction between the client and the psychological counselor present in real scenarios, leaving a deficit in terms of authenticity.\nWe present the detailed prompt of role-play method in Figure 6  ###reference_###  ###reference_### in the appendix.\nTo address the aforementioned issues of the baseline method, we propose a two-phase framework named Memo2Demo to generate high-quality psychological consultation dialogue from counseling reports. Mirroring real-life scenarios, we incorporate two key roles into this framework: a psychological supervisor together with a psychological counselor. The psychological supervisor guides the psychological counselor on counseling techniques while ensuring the privacy of the clients during the counseling process. Meanwhile, the psychological counselor engages in direct dialogue with the clients to conduct specific psychological counseling. Figure 3  ###reference_###  ###reference_### illustrates the general framework of our proposed method Memo2Demo, where a psychological counseling report is first converted into a counseling note by the psychological supervisor, then the psychological counselor generates the multi-turn consultation dialogue based on both the report and the note. We present detailed prompts used for Memo2Demo in Figure 7  ###reference_###  ###reference_### and 8  ###reference_###  ###reference_### in the appendix."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Automatic Evaluation of LLM-based Psychological Counseling",
            "text": "In the field of psychological counseling, assessing the quality of multi-turn consultation dialogues has always been a challenging task. Despite having successfully generated high-quality counseling dialogues from case reports using Memo2Demo, we still need to verify the impact of these dialogues on subsequent tasks. To this end, we elect to utilize CPsyCounD for supervised fine-tuning on publicly accessible LLMs. This allows us to assess the changes in the psychological counseling competency before and after the use of data.\nNonetheless, the multi-turn consultation dialogue that characterizes the psychological counseling process is complex to evaluate without the input of human experts. To address this, we first introduce evaluation metrics tailored for multi-turn consultation dialogue. Then a turn-based dialogue evaluation method is proposed for automatic evaluation of the psychological counseling process.\nMoreover, we acknowledge the current shortfall of a comprehensive, general multi-turn dialogue evaluation dataset within the psychological counseling community. Such a dataset is vital for assessing LLM-based psychological counseling. To bridge this gap, we present CPsyCounE, a general multi-turn dialogue evaluation dataset.\nIn psychological counseling, the evaluation metrics remain diverse and not universally standardized. For instance, SoulChat Chen et al. (2023b  ###reference_b5###  ###reference_b5###) proposes evaluation metrics: Content, Empathy, Helpfulness and Safety. Some of these metrics hinge on expert evaluations and lack specific scoring criteria, favoring manual rather than objective and automatic evaluations.\nSimilarly, ChatCounselor Liu et al. (2023a  ###reference_b11###  ###reference_b11###) introduces the Counseling Bench, encompassing seven different perspectives. While these metrics are designed to cater to the model’s specific dialogue strategies, they lack the ability to evaluate the overall dialogue effect. They are more adapted to single-round dialogue evaluations and are not suitable for multi-turn dialogues.\nRecognizing the aforementioned limitations in evaluating consultation dialogues, and in order to analyze the counseling case used for dialogue generation, we propose new evaluation metrics for multi-turn consultation dialogues in psychological counseling. These metrics encompass four different perspectives: Comprehensiveness, Professionalism, Authenticity, and Safety, which are used for automatic evaluation in the rest of this paper. For each perspective, we give its description and corresponding score criterion in Appendix C  ###reference_###  ###reference_###.\nWe propose a turn-based dialogue evaluation approach to effectively evaluate multi-turn consultation dialogues.\nDenote a -turn dialogue as a set of paired elements , where each  represents a query from the client, and each corresponding  represents the counselor’s reply. We first split it into  single-turn dialogue, then prompt the model with query together with its dialogue history in each single-turn dialogue, resulting in the corresponding single-turn response:\nwhere  signifies the dialogue history before -th turn, and  denotes the inference process of LLMs.\nTo automatically obtain reliable evaluation results,\nWe employ GPT-4 Achiam et al. (2023  ###reference_b1###  ###reference_b1###) to assess these responses, utilizing the evaluation metrics we previously proposed. Concretely, we ask the model to assign an evaluation score  for a single-turn response . Then we average them to yield the total evaluation score of the current -turn dialogue:\nFor detailed prompts of single-turn response generation, please refer to Figure 11  ###reference_###  ###reference_### in the appendix.\nSMILECHAT Qiu et al. (2023  ###reference_b18###  ###reference_b18###), a richly diverse and realistic multi-turn dialogue dataset, comprises 56k multi-turn counseling dialogues, averaging 6.36 rounds per dialogue. Given its wide range of dialogue types, we choose it as our base dataset. However, the open-source data of this dataset is not classified by topic type.\nTo address this limitation and conduct a more comprehensive and explainable evaluation of models’ capabilities, we construct a general multi-turn dialogue evaluation dataset with clear topic classification - CPsyCounE. Leveraging the nine common counseling topics we introduce in CPsyCounR, we manually select the five most representative dialogues from SMILECHAT for each topic, resulting in a comprehensive evaluation dataset of 45 cases."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "To delve deeper into whether the proposed dataset can effectively enhance the psychological counseling capabilities of LLMs, we further fine-tune InternLM2-7B-Chat Team (2023  ###reference_b22###) on CPsyCounD and derive a chat model CPsyCounX tailored specifically for psychological counseling.\nCPsyCounX is fine-tuning for 9 epochs with the batch size set to 448, and the learning rate set to . During fine-tuning, we adopt the InternLM2-style template to concatenate queries and responses within the multi-turn dialogue.\n###figure_5### ###figure_6### ###figure_7### The turn-based dialogue evaluation method is adopted on CPsyCounE for the following extrinsic evaluation. We include InternLM2-7B-Chat Team (2023  ###reference_b22###), SoulChat Chen et al. (2023b  ###reference_b5###), ChatGPT and GLM-4 Zeng et al. (2023  ###reference_b30###) as major baseline models.\nThe evaluation standard refers to the evaluation metrics in Table 4  ###reference_### in the appendix. To accommodate multi-turn dialogues, we adjust the authenticity criterion accordingly.\nFor detailed evaluation prompts, please refer to Figure 10  ###reference_### in the appendix.\nWe present the overall results of extrinsic evaluation on CPsyCoun in Table 3  ###reference_###, where CPsyCounX surpasses other models in terms of Professionalism and Authenticity, falling behind GLM-4 only slightly in terms of Comprehensiveness.\nFigure 4  ###reference_### further shows detailed scores of CPsyCounX and other baselines, where CPsyCounX significantly outperforms nearly all other baselines on Professionalism, demonstrating the efficacy of proposed method Memo2Demo. While judging by the topic distribution, CPsyCounX leads in all metrics in the topic \"Mental Disease\", demonstrating its high usability in the field of psychological counseling.\nFor full results, please refer to Appendix E  ###reference_###.\nUpon evaluation, we find that GLM-4 scores the highest in Comprehensiveness, largely because its single-turn dialogues encompass vast information. A manual investigation reveals that GLM-4 prioritizes summarizing previous dialogues in each turn, accounting for its high scores in Comprehensiveness. However, our evaluation shows that excessive content tends to compromise Authenticity scores.\nIn psychological counseling, Authenticity and Comprehensiveness need a balanced consideration. In our experiments, we prioritize natural and authentic dialogues that contain key information. Consequently, while CPsyCounX scores lower than GLM-4 in Comprehensiveness, it surpasses GLM-4 in Authenticity.\nThese results highlight that fine-tuning on CPsyCounD enables the model to naturally acquire professional psychological counseling techniques used in counseling dialogues. Moreover, the model can learn the conversational style of psychological counselors in real-life psychological counseling scenarios, ensuring the dialogue’s authenticity."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "CPsyCounD",
            "text": "To validate the effectiveness of our proposed dialogue reconstruction approach, we adopt direct role-play prompting and Memo2Demo to generate dialogues from CPsyCounR respectively.\nWe denote the set of dialogues generated by Memo2Demo as CPsyCounD, which has a total of 3,134 multi-turn consultation dialogues, covering nine topics and seven classic schools of psychological counseling. For statistical information, please refer to Table 1  ###reference_###."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Extrinsic Evaluation of CPsyCoun",
            "text": "To delve deeper into whether the proposed dataset can effectively enhance the psychological counseling capabilities of LLMs, we further fine-tune InternLM2-7B-Chat Team (2023  ###reference_b22###  ###reference_b22###) on CPsyCounD and derive a chat model CPsyCounX tailored specifically for psychological counseling.\nCPsyCounX is fine-tuning for 9 epochs with the batch size set to 448, and the learning rate set to . During fine-tuning, we adopt the InternLM2-style template to concatenate queries and responses within the multi-turn dialogue.\n###figure_8### ###figure_9### ###figure_10### The turn-based dialogue evaluation method is adopted on CPsyCounE for the following extrinsic evaluation. We include InternLM2-7B-Chat Team (2023  ###reference_b22###  ###reference_b22###), SoulChat Chen et al. (2023b  ###reference_b5###  ###reference_b5###), ChatGPT and GLM-4 Zeng et al. (2023  ###reference_b30###  ###reference_b30###) as major baseline models.\nThe evaluation standard refers to the evaluation metrics in Table 4  ###reference_###  ###reference_### in the appendix. To accommodate multi-turn dialogues, we adjust the authenticity criterion accordingly.\nFor detailed evaluation prompts, please refer to Figure 10  ###reference_###  ###reference_### in the appendix.\nWe present the overall results of extrinsic evaluation on CPsyCoun in Table 3  ###reference_###  ###reference_###, where CPsyCounX surpasses other models in terms of Professionalism and Authenticity, falling behind GLM-4 only slightly in terms of Comprehensiveness.\nFigure 4  ###reference_###  ###reference_### further shows detailed scores of CPsyCounX and other baselines, where CPsyCounX significantly outperforms nearly all other baselines on Professionalism, demonstrating the efficacy of proposed method Memo2Demo. While judging by the topic distribution, CPsyCounX leads in all metrics in the topic \"Mental Disease\", demonstrating its high usability in the field of psychological counseling.\nFor full results, please refer to Appendix E  ###reference_###  ###reference_###.\nUpon evaluation, we find that GLM-4 scores the highest in Comprehensiveness, largely because its single-turn dialogues encompass vast information. A manual investigation reveals that GLM-4 prioritizes summarizing previous dialogues in each turn, accounting for its high scores in Comprehensiveness. However, our evaluation shows that excessive content tends to compromise Authenticity scores.\nIn psychological counseling, Authenticity and Comprehensiveness need a balanced consideration. In our experiments, we prioritize natural and authentic dialogues that contain key information. Consequently, while CPsyCounX scores lower than GLM-4 in Comprehensiveness, it surpasses GLM-4 in Authenticity.\nThese results highlight that fine-tuning on CPsyCounD enables the model to naturally acquire professional psychological counseling techniques used in counseling dialogues. Moreover, the model can learn the conversational style of psychological counselors in real-life psychological counseling scenarios, ensuring the dialogue’s authenticity."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we introduce CPsyCoun, an innovative framework for report-based multi-turn dialogue reconstruction and evaluation in Chinese psychological counseling. Our research encompasses data collection, effective data construction methods, and domain evaluation benchmarks.\nTo harness the full potential of psychological counseling reports, we design a two-phase approach to construct high-quality consultation dialogues. Concurrently, we propose a comprehensive evaluation benchmark for multi-turn consultation dialogue, inclusive of metrics, datasets and methods.\nExperimental results validate the effectiveness of our proposed framework, demonstrating its superiority in building a comprehensive, professional, and authentic psychological counseling assistant.\nAll datasets and model weights developed in this paper are publicly available.\nFor future work, a more refined balance between authenticity and professional knowledge in dialogue generation needs to be achieved. We aspire this work will furnish fresh perspectives and references for the development of LLMs in the field of psychological counseling."
        }
    ]
}