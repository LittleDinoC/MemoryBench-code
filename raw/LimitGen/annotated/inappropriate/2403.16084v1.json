{
    "title": "Argument Quality Assessment in the Age of Instruction-Following Large Language Models",
    "abstract": "The computational treatment of arguments on controversial issues has been subject to extensive NLP research, due to its envisioned impact on opinion formation, decision making, writing education, and the like. A critical task in any such application is the assessment of an argument’s quality—but it is also particularly challenging. In this position paper, we start from a brief survey of argument quality research, where we identify the diversity of quality notions and the subjectiveness of their perception as the main hurdles towards substantial progress on argument quality assessment.\nWe argue that the capabilities of instruction-following large language models (LLMs) to leverage knowledge across contexts enable a much more reliable assessment. Rather than just fine-tuning LLMs towards leaderboard chasing on assessment tasks, they need to be instructed systematically with argumentation theories and scenarios as well as with ways to solve argument-related problems. We discuss the real-world opportunities and ethical issues emerging thereby.\n\n\n\nKeywords: Computational Argumentation, Argument Quality, Large Language Model, Instruction Fine-Tuning",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "“In some sense, the question about the quality of an argument is the ‘ultimate’ one for argumentation mining.” Stede and Schneider (2018  ###reference_b110###).\nWhen learning about controversial issues, people rarely accept arguments they encounter without further contemplation. Rather, they seek to find the best arguments; those that help them form an opinion or write texts that persuade others; those that make them reach agreement or at least understand each other better. That is to say, argument quality is of interest as soon as arguments are presented to an audience. Computational argumentation aids the treatment of arguments at a larger scale, with important applications in search Wachsmuth et al. (2017c  ###reference_b122###), business Slonim et al. (2021  ###reference_b106###), and education Wambsganss and Niklaus (2022  ###reference_b124###). But the situation there is the same: It is not enough to mine or generate arguments; their quality also needs to be evaluable Park and Cardie (2018  ###reference_b87###), so that it can be assessed Lauscher et al. (2020  ###reference_b68###), flaws can be found Goffredo et al. (2022  ###reference_b40###), and accounted for Skitalinskaya et al. (2023  ###reference_b104###).\nWachsmuth et al. (2017b  ###reference_b121###) surveyed research on argument quality assessment, organizing theories and methods under 15 quality notions, from logical cogency to rhetorical effectiveness to dialectical reasonableness. Even though computational argumentation was just gaining momentum in natural language processing (NLP) back then, rarely going beyond argument mining, two inherent challenges of argument quality were visible already: the diversity of quality notions as well as the subjectivity of their perception and, hence, of their assessment for both humans and computational models. Consider the following argumentative claim against censoring Mark Twain’s usage of the N-word, taken from the debate platform kialo.com:\n“In Huckleberry Finn, Twain captured the essence of everyday midwest American English.\"\nThis claim is certainly relevant to the discussion, but whether people will deem it effective may strongly depend on their individual context. A person without African-American background may be willing to accept the argument; one with high literacy might look for clearer logical connections.\nWhile the challenges of diversity and subjectivity prevail until today Lapesa et al. (2023  ###reference_b66###), NLP is now seeing a revolutionary breakthrough: the rise of instruction-following large language models (henceforth, LLMs) that can tackle various NLP tasks with little to no task-specific fine-tuning, enabled by their supreme capability to integrate and leverage knowledge across contexts OpenAI (2023  ###reference_b83###). The question is: What are the implications for argument quality assessment specifically as well as for computational argumentation in general?\nIn this position paper, we revisit the computational assessment of argument quality in light of the availability of LLMs such as GPT-4 and Alpaca Taori et al. (2023  ###reference_b113###). Starting from the status quo reported by Wachsmuth et al. (2017b  ###reference_b121###), we carry out a brief survey of recent NLP research on the topic (Section 2  ###reference_###). To bring order into the various lines of research pursued since 2017, we organize them into three general directions, as laid out in Figure 1  ###reference_###:\nConceptual notions of maximal and minimal argument quality,\nInfluence factors of argument quality from the context where arguments occur, and\nComputational models for assessing or improving argument quality.\nOn this basis, we establish the central question to which we provide answers in this paper:\nHow to drive research on LLM-based argument quality assessment in order to face the prevailing challenges of diverse quality notions and their subjectivity?\nIn particular, we are convinced that the capabilities of instruction-following LLMs enable research to overcome many aspects of the two challenges. To this end, the primary focus of NLP research on argument quality should be put on systematic ways to teach LLMs to follow instructions, including concepts and settings of arguing in addition to ways to solve argument-related problems (Section 3  ###reference_###). Instead of fine-tuning LLMs on predefined domains (manifested in the training data) and preselected theories (manifested in the data’s annotations), as well as simple engineering of prompts, we expect the greatest impact to lie in teaching LLMs the theories, circumstances, and ethical constraints to adhere to. The rationale behind this is that LLMs will often have processed data from all contexts needed to make an informed judgment about an argument’s quality, due to their heavy pretraining on huge amounts of data. In contrast, LLMs cannot access, by default, the knowledge of what is to be prioritized in a given setting.\nWe state upfront that the blueprint delineated in this paper comes with several limitations and ethical considerations that we critically analyze below. Moreover, we are naturally aware of the general issues of LLMs, including hallucinated facts and the reproduction of common social biases. These issues deserve treatment in computational argumentation as well; they are even particularly critical there due to the sensitivity of many controversial topics Holtermann et al. (2022  ###reference_b49###). Keeping this in mind, we believe that it is necessary to explore now how to best employ LLMs for argument quality assessment in order to harness their full potential for the main applications, while avoiding to waste energy for the typical pursuit of leaderboard rankings on existing quality assessment tasks. This is the goal of the paper at hand.\nNow, why is it important to discuss LLMs for argument quality assessment specifically? We address this matter when we look at the real-world opportunities emerging from the capabilities of LLMs in academia and industry (Section 4  ###reference_###). While Argyle et al. (2023  ###reference_b3###) developed LLMs that tone down argumentative conversations, we postulate a contrary path: Exploiting the means of LLMs to proactively enable people to learn and better reason about controversial issues, thus contributing towards more deliberate conversations Vecchi et al. (2021  ###reference_b119###). We think that the time has come to revisit and pursue the core visions of computational argumentation research, from the overcoming of filter bubbles to the individualized mass education of learners. We sketch how these visions could be realized with the LLMs available today, before we conclude (Section 5  ###reference_###) and stress ethical concerns that arise with LLMs that actively affect human views (Section 6  ###reference_###).\nWith the discussion in this position paper, we provide two main contributions to research:\nA survey of the main lines of recent research on argument quality and its assessment\nA blueprint for impactful future research on LLMs for argument quality assessment"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   A Brief Survey of Recent Research",
            "text": "To start, this section briefly but systematically surveys recent NLP work on argument quality assessment. We identify three general directions, each with two main aspects, and organize the research accordingly, as illustrated in Figure 1  ###reference_###.\n###figure_1### 24 of the papers primarily deal with the question of what is actually meant by argument quality, considered from either of two complementary perspectives:\nNotions of maximal quality based on arguing goals such as agreement and deliberation or on preferences between different arguments\nNotions of minimal quality in terms of what makes an argument evaluable or appropriate to be stated as well as how to avoid fallacies\nThis direction covers 30 papers studying (or controlling) two types of factors that influence the perception of quality beyond the content, structure, and style of the argument itself:\nArgument-related factors such as the argument’s length, its structure in terms of relations between units, and revisions applied to it\nContext-related factors, such as the domain of the discussion, the audience addressed, and the debaters involved\nFinally, 21 papers aim mainly at methodological novelty in the modeling of argument quality for two quality-related tasks:\nModels for assessment of argument quality, capturing specificities of the task, the whole discussion, or the context of arguing\nModels for improvement of argument quality, targeting the need for improvement, actual optimizations, or feedback on what to improve\nThe remaining eight papers pursue individual research directions.\nWe note that many of the surveyed papers do not fall under one general direction only; rather, they often have a visible focus on one of them. In particular, our internal discussion revealed that contributions to influence factors and computational models are not always easy to distinguish and that, sometimes, models may rather target downstream applications. Still, the directions and aspects were agreed upon in general.111For validation, we reassigned 16 papers (19%) to other authors: 11 got the same main direction; for four, it was seen as the second contribution. Only in one case, a fully different direction was assigned. After rechecking, the newly assigned direction did not seem adequate.\nIn the following, we discuss selected works from each of the general research directions. Table 1  ###reference_### in the appendix shows the full list of all 83 covered publications, grouped by the primary general research direction and the main aspect.\nSome researchers build on the argument quality taxonomy proposed by Wachsmuth et al. (2017b  ###reference_b121###), including Lauscher et al. (2020  ###reference_b68###) who model the main taxonomy notions using multitask learning across Q&A, debate, and review forums. Others question the simplifying view that argument quality is about persuasion only: El Baff et al. (2018  ###reference_b29###) consider the goal of agreement, defining good news arguments as those that challenge or corroborate stance. Gretz et al. (2020  ###reference_b41###) see argument quality as a preference relation, and Falk et al. (2021  ###reference_b32###) examine its connection to deliberation. With an entirely different perspective, some papers examine what makes an argument good irrespective of topic Beigman Klebanov et al. (2017  ###reference_b9###), whereas, for example, Dumani et al. (2020  ###reference_b23###) operationalize argument quality for practice in a quality-based framework for argument retrieval.\nPark et al. (2015  ###reference_b86###) establish the notion of an argument’s evaluability, that is, the prerequisite of assessing logical quality soundly. A key research line on minimal quality is the detection of fallacies: arguments with flawed or deceptive reasoning. Neural models have shown success on this deep semantic problem; some aim at ad-hominem arguments only Habernal et al. (2018  ###reference_b45###), others at various fallacies Jin et al. (2022  ###reference_b53###). Persing and Ng (2017b  ###reference_b92###) tackle the broader problem of spotting an argument’s weaknesses, from grammar errors to lack of objectivity and unclear justifications. More practice-oriented, Pauli et al. (2022  ###reference_b89###) look at the misuse of fallacies for rhetorical appeals in online forums and fake news. Finally, Ziegenbein et al. (2023  ###reference_b131###) refine the notion of appropriateness, emanating from Aristotle’s work Aristotle (ca. 350 B.C.E./ translated\n2007  ###reference_b4###). They see it as the minimal quality that makes arguments worthy of being considered and annotate data for violations of appropriateness.\nIn terms of textual factors influencing the perceived quality of arguments, researchers display the questionable power of length as a predictor Potash et al. (2017  ###reference_b94###) and account for this in dataset creation Toledo et al. (2019  ###reference_b115###). The impact on quality of internal argument structure has been investigated using the notion of organization quality in learner essays Chen et al. (2022a  ###reference_b17###) and by using annotations of argument components in business model pitches Wambsganss and Niklaus (2022  ###reference_b124###). Notions of structure within an argument are further extended through adding attributes to argument components Carlile et al. (2018  ###reference_b14###), shifting the focus to component-related factors, or by comparing different revisions of the same claim Skitalinskaya et al. (2021  ###reference_b103###).\nLukin et al. (2017  ###reference_b76###) analyze the interaction between argumentative styles (emotional vs. factual) and the personality of the audience, as modeled by the Big Five traits. Similarly, Durmus and Cardie (2018  ###reference_b24###) model political and religious ideologies, based on the audience’s stances on various controversial topics. Both indicate that audience-level factors often outweigh language use in their persuasive effect. Alshomary et al. (2022  ###reference_b2###) turn the view to rhetorical strategies of debaters, assessing the effect of morally-framed arguments. They find that morals are particularly successful in challenging the audience’s beliefs. Wiegmann et al. (2022  ###reference_b128###) analyze stylistic and behavioral characteristics of debaters that contribute to their persuasiveness over multiple debates. Aside from debate participants, Liu et al. (2022  ###reference_b74###) explore arguments on social media that are accompanied by images, highlighting the potential of multimodal approaches to quality assessment, whereas Fromm et al. (2023  ###reference_b36###) generalize the contextual scope of assessment to multiple domains at the same time.\nMany approaches aim at specific quality notions. For example, the attentive interaction model of Jo et al. (2018  ###reference_b54###) predicts an opinion holder’s view change by detecting vulnerable regions in their reasoning and modeling its relation to a challenger’s argument. Gleize et al. (2019  ###reference_b39###) propose a Siamese neural network to assess the convincingness of evidence, while Song et al. (2020  ###reference_b107###) develop a hierarchical multitask learning approach to jointly model discourse element identification and organization assessment for essay scoring. Gurcke et al. (2021  ###reference_b44###) examine to what extent an argument’s logical sufficiency can be predicted based on whether its conclusion can be inferred from its premises using the generation capabilities of transformers. Kondo et al. (2021  ###reference_b64###) assess the validity of an argument’s reasoning using Bayesian networks and predicate logic facilitated by argumentation schemes. A few works also look beyond single quality notions, such as Falk and Lapesa (2023  ###reference_b34###) who inject knowledge about the interactions between different quality notions to improve the prediction of individual ones.\n###figure_2### While only a few models for improvement have been presented so far, we expect more to come soon, also seeing related efforts on topics beyond those covered in this survey Chakrabarty et al. (2021  ###reference_b15###); Ihori et al. (2022  ###reference_b51###); Li et al. (2022  ###reference_b72###). An early attempt was made by Ke et al. (2018  ###reference_b56###) who design neural models that predict the persuasiveness and other attributes of arguments in a student essay, to provide feedback to students on how to improve their arguments. Recently, Skitalinskaya and Wachsmuth (2023  ###reference_b105###) identified arguments in need of improvement, leveraging complex revision-based data with transformer models. Skitalinskaya et al. (2023  ###reference_b104###) go one step further, presenting the first approach to the optimization of argumentative claims. It combines neural claim rewriting with quality-based ranking."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Frame of the Survey",
            "text": "Beyond holistic computational argumentation (CA) surveys Stede and Schneider (2018  ###reference_b110###); Cabrio and Villata (2018  ###reference_b13###); Lawrence and Reed (2019  ###reference_b70###), Wang et al. (2023a  ###reference_b126###) specifically reviewed works on argument generation, Lauscher et al. (2022b  ###reference_b69###) on knowledge in CA, and Vecchi et al. (2021  ###reference_b119###) on the use of CA for the social good. Also, some tutorials treated argument mining and its applications Budzynska and Reed (2019  ###reference_b11###); Bar-Haim et al. (2021  ###reference_b6###). In contrast, we focus on argument quality assessment.\nAside from our recent tutorial Lapesa et al. (2023  ###reference_b66###), the only argument quality review that we are aware of is the one of Wachsmuth et al. (2017b  ###reference_b121###) who organize relevant literature until mid 2017 into a taxonomy of 15 logical, rhetorical, and dialectical quality dimensions. The authors already discussed the diversity of quality notions as well as the subjectivity of their perception, both of which are still hampering research. In this paper, we seek to delineate ways to overcome them, in line with the authors’ organization of what argument quality means. We start from their work here, so we restrict our survey to work that is published after theirs.\nBased on our experience with NLP research on CA, we cover four groups of publication venues:\nAll NLP venues covered by the ACL anthology\nThe leading artificial intelligence (AI) conferences, all from AAAI.org and IJCAI\nThe leading information retrieval (IR) conferences, SIGIR and ECIR\nThe leading CA conference, COMMA\nWe used Google site search and Springer and ACM’s internal search on September 1, 2023 (updated on October 17, 2023), to gather all papers containing any of the following pairs of words:\nThis led to 257 papers (202 NLP, 35 AI, 11 IR, 9 CA). From these, we kept all 119 papers that deal with quality of natural language arguments based on title, abstract, and skimming (98 NLP, 12 AI, 6 IR, 3 CA). To focus on scientific novelty, we further excluded surveys, tutorials, demos, shared tasks, and system papers, leaving 104 papers (87 NLP, 10 AI, 5 IR, 2 CA). We checked these in more detail to ensure that argument quality is actually part of the research. After filtering out others, we obtained a final set of 83 papers (69 NLP, 9 AI, 3 IR, 2 CA)."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   General Research Directions",
            "text": "Analyzing the 83 papers as a whole, we identified the following three general directions of research on argument quality, each with two main aspects. Concretely, one author of this paper proposed the organization. The papers were then distributed among all other authors who ranked them by the directions and aspects they contribute, if any.\n24 of the papers primarily deal with the question of what is actually meant by argument quality, considered from either of two complementary perspectives:\nNotions of maximal quality based on arguing goals such as agreement and deliberation or on preferences between different arguments\nNotions of minimal quality in terms of what makes an argument evaluable or appropriate to be stated as well as how to avoid fallacies\nThis direction covers 30 papers studying (or controlling) two types of factors that influence the perception of quality beyond the content, structure, and style of the argument itself:\nArgument-related factors such as the argument’s length, its structure in terms of relations between units, and revisions applied to it\nContext-related factors, such as the domain of the discussion, the audience addressed, and the debaters involved\nFinally, 21 papers aim mainly at methodological novelty in the modeling of argument quality for two quality-related tasks:\nModels for assessment of argument quality, capturing specificities of the task, the whole discussion, or the context of arguing\nModels for improvement of argument quality, targeting the need for improvement, actual optimizations, or feedback on what to improve\nThe remaining eight papers pursue individual research directions.\nWe note that many of the surveyed papers do not fall under one general direction only; rather, they often have a visible focus on one of them. In particular, our internal discussion revealed that contributions to influence factors and computational models are not always easy to distinguish and that, sometimes, models may rather target downstream applications. Still, the directions and aspects were agreed upon in general.111For validation, we reassigned 16 papers (19%) to other authors: 11 got the same main direction; for four, it was seen as the second contribution. Only in one case, a fully different direction was assigned. After rechecking, the newly assigned direction did not seem adequate.\nIn the following, we discuss selected works from each of the general research directions. Table 1  ###reference_###  ###reference_### in the appendix shows the full list of all 83 covered publications, grouped by the primary general research direction and the main aspect."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3.   Conceptual Notions",
            "text": "Naturally, all surveyed literature builds on some notion of argument quality, at least implicitly. However, we found that 24 of the 83 papers have the explicit treatment of quality notions as their main focus and 10 further papers contribute to quality notions to some extent. About two-thirds of the works discuss how an argument should be ideally (maximal quality), the others what an argument should at least achieve or avoid (minimal quality).\nSome researchers build on the argument quality taxonomy proposed by Wachsmuth et al. (2017b  ###reference_b121###  ###reference_b121###), including Lauscher et al. (2020  ###reference_b68###  ###reference_b68###) who model the main taxonomy notions using multitask learning across Q&A, debate, and review forums. Others question the simplifying view that argument quality is about persuasion only: El Baff et al. (2018  ###reference_b29###  ###reference_b29###) consider the goal of agreement, defining good news arguments as those that challenge or corroborate stance. Gretz et al. (2020  ###reference_b41###  ###reference_b41###) see argument quality as a preference relation, and Falk et al. (2021  ###reference_b32###  ###reference_b32###) examine its connection to deliberation. With an entirely different perspective, some papers examine what makes an argument good irrespective of topic Beigman Klebanov et al. (2017  ###reference_b9###  ###reference_b9###), whereas, for example, Dumani et al. (2020  ###reference_b23###  ###reference_b23###) operationalize argument quality for practice in a quality-based framework for argument retrieval.\nPark et al. (2015  ###reference_b86###  ###reference_b86###) establish the notion of an argument’s evaluability, that is, the prerequisite of assessing logical quality soundly. A key research line on minimal quality is the detection of fallacies: arguments with flawed or deceptive reasoning. Neural models have shown success on this deep semantic problem; some aim at ad-hominem arguments only Habernal et al. (2018  ###reference_b45###  ###reference_b45###), others at various fallacies Jin et al. (2022  ###reference_b53###  ###reference_b53###). Persing and Ng (2017b  ###reference_b92###  ###reference_b92###) tackle the broader problem of spotting an argument’s weaknesses, from grammar errors to lack of objectivity and unclear justifications. More practice-oriented, Pauli et al. (2022  ###reference_b89###  ###reference_b89###) look at the misuse of fallacies for rhetorical appeals in online forums and fake news. Finally, Ziegenbein et al. (2023  ###reference_b131###  ###reference_b131###) refine the notion of appropriateness, emanating from Aristotle’s work Aristotle (ca. 350 B.C.E./ translated\n2007  ###reference_b4###  ###reference_b4###). They see it as the minimal quality that makes arguments worthy of being considered and annotate data for violations of appropriateness."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "2.4.   Influence Factors",
            "text": "Assessing the different notions of argument quality is a complex task and is influenced by many factors, some of which have no explicit relation to the argument itself. Accordingly, research has dealt with the identification, modeling, and controlling of such factors and their impact on argument quality. We found that 30 of the 83 papers mainly focus on influence factors, and a further 19 papers are to some extent devoted to them. Of these, about 60% discuss argument-related factors while the rest looks at context-related factors.\nIn terms of textual factors influencing the perceived quality of arguments, researchers display the questionable power of length as a predictor Potash et al. (2017  ###reference_b94###  ###reference_b94###) and account for this in dataset creation Toledo et al. (2019  ###reference_b115###  ###reference_b115###). The impact on quality of internal argument structure has been investigated using the notion of organization quality in learner essays Chen et al. (2022a  ###reference_b17###  ###reference_b17###) and by using annotations of argument components in business model pitches Wambsganss and Niklaus (2022  ###reference_b124###  ###reference_b124###). Notions of structure within an argument are further extended through adding attributes to argument components Carlile et al. (2018  ###reference_b14###  ###reference_b14###), shifting the focus to component-related factors, or by comparing different revisions of the same claim Skitalinskaya et al. (2021  ###reference_b103###  ###reference_b103###).\nLukin et al. (2017  ###reference_b76###  ###reference_b76###) analyze the interaction between argumentative styles (emotional vs. factual) and the personality of the audience, as modeled by the Big Five traits. Similarly, Durmus and Cardie (2018  ###reference_b24###  ###reference_b24###) model political and religious ideologies, based on the audience’s stances on various controversial topics. Both indicate that audience-level factors often outweigh language use in their persuasive effect. Alshomary et al. (2022  ###reference_b2###  ###reference_b2###) turn the view to rhetorical strategies of debaters, assessing the effect of morally-framed arguments. They find that morals are particularly successful in challenging the audience’s beliefs. Wiegmann et al. (2022  ###reference_b128###  ###reference_b128###) analyze stylistic and behavioral characteristics of debaters that contribute to their persuasiveness over multiple debates. Aside from debate participants, Liu et al. (2022  ###reference_b74###  ###reference_b74###) explore arguments on social media that are accompanied by images, highlighting the potential of multimodal approaches to quality assessment, whereas Fromm et al. (2023  ###reference_b36###  ###reference_b36###) generalize the contextual scope of assessment to multiple domains at the same time."
        },
        {
            "section_id": "2.5",
            "parent_section_id": "2",
            "section_name": "2.5.   Computational Models",
            "text": "The majority of the 83 surveyed papers include empirical experiments with models for argument quality. However, we found that only 21 of them actually focus on proposing novel approaches targeting either of the above-mentioned conceptual quality notions, whereas 26 other papers have such approaches as secondary contributions to support their claims with experimental results and analysis. Almost all approaches aim at the assessment of argument quality, but a few recent ones go beyond assessment, studying how to improve quality.\nMany approaches aim at specific quality notions. For example, the attentive interaction model of Jo et al. (2018  ###reference_b54###  ###reference_b54###) predicts an opinion holder’s view change by detecting vulnerable regions in their reasoning and modeling its relation to a challenger’s argument. Gleize et al. (2019  ###reference_b39###  ###reference_b39###) propose a Siamese neural network to assess the convincingness of evidence, while Song et al. (2020  ###reference_b107###  ###reference_b107###) develop a hierarchical multitask learning approach to jointly model discourse element identification and organization assessment for essay scoring. Gurcke et al. (2021  ###reference_b44###  ###reference_b44###) examine to what extent an argument’s logical sufficiency can be predicted based on whether its conclusion can be inferred from its premises using the generation capabilities of transformers. Kondo et al. (2021  ###reference_b64###  ###reference_b64###) assess the validity of an argument’s reasoning using Bayesian networks and predicate logic facilitated by argumentation schemes. A few works also look beyond single quality notions, such as Falk and Lapesa (2023  ###reference_b34###  ###reference_b34###) who inject knowledge about the interactions between different quality notions to improve the prediction of individual ones.\n###figure_3### While only a few models for improvement have been presented so far, we expect more to come soon, also seeing related efforts on topics beyond those covered in this survey Chakrabarty et al. (2021  ###reference_b15###  ###reference_b15###); Ihori et al. (2022  ###reference_b51###  ###reference_b51###); Li et al. (2022  ###reference_b72###  ###reference_b72###). An early attempt was made by Ke et al. (2018  ###reference_b56###  ###reference_b56###) who design neural models that predict the persuasiveness and other attributes of arguments in a student essay, to provide feedback to students on how to improve their arguments. Recently, Skitalinskaya and Wachsmuth (2023  ###reference_b105###  ###reference_b105###) identified arguments in need of improvement, leveraging complex revision-based data with transformer models. Skitalinskaya et al. (2023  ###reference_b104###  ###reference_b104###) go one step further, presenting the first approach to the optimization of argumentative claims. It combines neural claim rewriting with quality-based ranking."
        },
        {
            "section_id": "2.6",
            "parent_section_id": "2",
            "section_name": "2.6.   Other Research Directions",
            "text": "Among the eight papers that do not fit under the three main research directions, we identified the following two rough research areas.\nFive papers deal with specific applications for which argument quality assessment is key. Rach et al. (2020  ###reference_b97###) and Kiesel et al. (2020  ###reference_b59###) target argument search, both taking a human-interaction perspective: The former studies the effects of integratting argument search into an avatar-based dialogue system; the latter investigates user expectations on voice-based argument search systems, such as preferred ranking criteria. Chalaguine and Hunter (2020  ###reference_b16###) develop a chatbot that relies on an argument graph for persuasive counterargument generation, and Falk et al. (2021  ###reference_b32###) address expert moderation in a deliberative forum, taking moderator interventions as implicit labels for the need to improve comment quality. Fromm et al. (2021  ###reference_b37###) use argument mining for analyzing peer reviews.\nThe other works tackle the bottleneck of (scarce) assessment training data. Heinisch et al. (2022  ###reference_b48###) employ data augmentation to support the prediction of argument validity and novelty. Kees et al. (2021  ###reference_b58###) evaluate active learning strategies for supporting argument strength estimation, and Yang et al. (2019  ###reference_b129###) introduce a quality control method that they apply to annotate argument acceptability."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   LLMs for Argument Quality",
            "text": "Section 2  ###reference_### stresses that a big part of argument quality research tackles the key challenges of diverse views of quality (by developing or refining notions) and subjectivity (by controlling or modeling influence factors). However, the intricated interdependencies between different quality notions and the various factors that influence them have hampered substantial progress in the reliable assessment of argument quality so far. We argue that manual rule-based scoring systems have the potential to overcome many limitations, if systematic ways to teach them accordingly are established. In this section, we start from the main advantages of such systems. Then, we outline what to instruct these systems with and how to do so (beyond simple in-context learning/prompting techniques) in order to advance these systems for argument quality in future research."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Assessment without Instructions",
            "text": "Conceptually, argument quality assessment is a classification or regression problem, even if partly treated as preference learning. For decades, research in NLP relied on the traditional supervised learning paradigm for most such problems: to induce a mapping from one representational space to another using training pairs of input and output. As sketched in Figure 2  ###reference_###a, the input spaces (usually, representing natural language) and output spaces (label schemes or value ranges, such as argument quality scores) are separated thereby. This separation prevents any exchange of knowledge across spaces and across tasks.\nWith the shift to transformers in NLP, the learning effort is mostly reduced to the self-supervised pretraining of a language model Vaswani et al. (2017  ###reference_b118###); Devlin et al. (2019  ###reference_b21###). Under the transfer learning paradigm, only fine-tuning remains supervised, to make a model address the task it is supposed to. This way, knowledge is shared between input representations across tasks and contexts, that is, all texts ever processed affect how an input is encoded. In classification and regression, however, using a manual rule-based scoring system (say, of a BERT encoder with a quality scoring head) reintroduces a key restriction of traditional methods, illustrated in Figure 2  ###reference_###b: The input space is separated again from the output space, preventing models from fully leveraging knowledge acquired from solving other tasks.\nFine-tuning for text generation tasks keeps input and output in the same space; thereby, for example, connections between an argument and its improved version can be learned. Still, it faces a second restriction that is shown in Figure 2  ###reference_###b’: The idea behind the mapping from input to output (why is an output correct for an input) remains fully implicit in the training pairs. For argument quality assessment, both restrictions imply that only those interdependencies between quality notions as well as those contextual influence factors are taken into account that are explicitly modeled or controlled by the human developer. Even though a lot of other interdependencies and factors may be well-known in argumentation theory van Eemeren and Grootendorst (2004  ###reference_b117###); Aristotle (ca. 350 B.C.E./ translated 2007  ###reference_b4###), they are widely ignored thereby. This is where instruction-following LLMs go beyond."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Instruction-Following LLMs",
            "text": "Manual rule-based scoring system teaches LLMs to follow user instructions to solve tasks Peng et al. (2023  ###reference_b90###). As Figure 2  ###reference_###c stresses, it does so by representing the task in the joint space of inputs and outputs across all tasks and contexts, that is, in natural language (more precisely, in the embedding space in which language is encoded and from which it is decoded). Following the manual rule-based scoring system paradigm, deriving an output from an input remains a language modeling problem as well as how to operationalize the derivation. This means that all knowledge ever processed in pretraining is still accessible in principle (bounded by the technical constraints of the model). Then, the supreme capability of transformers to integrate and leverage knowledge across contexts enables instruction-following LLMs to tackle unseen tasks with no or little fine-tuning.\nIn argument quality assessment, we can expect that most knowledge about quality notions and their interdependencies as well as about influence factors and their effect on the subjective perception of argument quality has already been processed by leading LLMs, such as GPT-4 OpenAI (2023  ###reference_b83###) and Alpaca Taori et al. (2023  ###reference_b113###), in their pretraining stage. It should thus be possible to learn through instructions what is important in the assessment task at hand while not ignoring interactions with the surrounding concepts of argument quality."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   Instructions for Assessment",
            "text": "Fine-tuning LLMs on general-purpose instruction data Wang et al. (2023b  ###reference_b127###) will help them solve language modeling tasks in principle. By default, however, LLMs do not necessarily have access to what is to be prioritized for the setting of the task at hand. We expect that this is the information an LLM needs to be instructed with to assess argument quality reliably. Accordingly, we see the survey results from Section 2  ###reference_### as an adequate basis to explore what to teach LLMs for the assessment. Instructions may thus include but are not limited to:\narguing goals, from agreement El Baff et al. (2018  ###reference_b29###) to deliberation Falk et al. (2021  ###reference_b32###);\ndefinition of various quality notions, be it for maximal quality Lauscher et al. (2020  ###reference_b68###) or minimal quality Jin et al. (2022  ###reference_b53###);\nspecificities of audiences Lukin et al. (2017  ###reference_b76###) and debaters Durmus and Cardie (2019  ###reference_b25###);\nbackground on controversial topics, such as other arguments Luu et al. (2019  ###reference_b77###) or relationships between the topics Zhao et al. (2021  ###reference_b130###);\nethical aspects, such as biases Holtermann et al. (2022  ###reference_b49###) and culture Chen et al. (2022a  ###reference_b17###);\nany examples of respective assessments, following the common few-shot learning idea.\nExemplarily, let us get back to the Huckleberry Finn claim from Section 1  ###reference_### taken from kialo.com. On this online platform, users create and refine claims, and they give impact votes from 1 to 5. These impact votes may serve as gold labels. For voting, users are asked to consider both a claim’s persuasiveness and its relevance to the claim it replies to, in equal weight.222https://support.kialo-edu.com/en/hc/about-voting/\nWhen using such labels, supervised learning (Figure 2  ###reference_###a) and a manual rule-based scoring system (Figure 2  ###reference_###b/b’) can learn the semantics of the task only through the mapping from claim to vote, risking spurious correlations Thorn Jakobsen et al. (2021  ###reference_b114###) as well as bias Spliethöver and Wachsmuth (2020  ###reference_b108###). The equal weighting will likely not to be captured either, as users may not weigh systematically, may not have read instructions, or may just have a subjective perception.\nMoreover, the same claim should certainly be assessed differently depending on the setting (beyond kialo.com). From a deliberative perspective, for example, it lacks a concrete counterproposal (e.g., even if we do not censor, a preface should be added or teachers should discuss the load of the N-word in everyday life). Moving to quality improvement, the claim may need to be revised for specific audiences, for example, the concept of “everyday midwest American English” may be completely opaque to people with low literacy.\nInstructions may overcome all these challenges. An example may be: “Rate the claim’s quality from the perspective of deliberation, when presented to a person of low literacy”. This makes the semantics of the task much more explicit, likely reducing biases and spurious correlations. It performs a stage-setting and an addressee-setting function which are crucial for assessment and improvement. We do not aim to come up with the best instructions in this paper, but see this as a task for future work. Rather, we discuss how to systematize respective manual rule-based scoring system attempts."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "3.4.   Blueprint for Instruction Fine-Tuning",
            "text": "Effective processes for the general manual rule-based scoring system of LLMs have already been established in prior work Taori et al. (2023  ###reference_b113###). Given the discussed advantages of such LLMs over previous models, we argue that argument quality assessment may be brought to the next level through systematic approaches to task-related manual rule-based scoring systems. The idea is to bring specific knowledge about theories, circumstances, and ethical constraints of arguing along with ways of how to solve argument-related problems into the scoring process. As a blueprint, such an approach could roughly consist of the following stages:\nStart from a general instruction-following LLM, such as Alpaca Taori et al. (2023  ###reference_b113###). Even some standard pretrained transformer may suffice, if general instructions are added to Step 2.\nAcquire a seed set of argumentation-specific instructions, covering concepts such as those in the previous subsection. For example, these instructions can be derived manually or semi-automatically from the various datasets and experiments covered in the surveyed papers.\nDepending on available resources, apply techniques such as reinforcement learning using human feedback Ouyang et al. (2022  ###reference_b84###), fine-tuning on self-generated instructions Wang et al. (2023b  ###reference_b127###), or other manual rule-based scoring mechanisms that are proposed in research.\nAlign the behavior of the manual rule-based LLM on new unseen tasks at hand using systematic prompt design, for example, via soft prompting Qin and Eisner (2021  ###reference_b96###) or sociodemographic prompting to emulate social profiles of debaters and audiences Beck et al. (2023  ###reference_b8###). Due to Step 3, these tasks now benefit from argument-specific task-solving skills.\nAt least for fact-related argument quality dimensions, such local acceptability Wachsmuth et al. (2017b  ###reference_b121###), an additional step may be to systematically work against hallucinations, by teaching the LLM to check arguments against some fact source (e.g., a knowledge base or a corpus). Factuality measures may be included in the model optimization for this purpose. We note, though, that this presupposes a setting in which sources can also be accessed at inference time. Besides, many quality dimensions are actually not (inherently) about facts, such as those from rhetorics Wachsmuth et al. (2017b  ###reference_b121###).\nWe expect that the resulting LLM will assess argument quality more reliably in line with the theories behind diverse quality notions and will adjust to the subjective viewpoints of interest. Thereby, various new opportunities emerge for real-world applications, as discussed in the next section."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "3.5.   Evaluation of Quality Assessment",
            "text": "Finally, we make a note on the evaluation of LLM-based argument quality assessment, to give a basic guideline. Various ways of evaluating assessment have been pursued in prior work; particularly, there is a debate about whether quality should be assessed in absolute terms, based on a given score range, or in relative terms, comparing different arguments to one another Wachsmuth et al. (2017a  ###reference_b120###). Instruction-following LLMs might not entirely resolve the issue behind; while they provide new means for a reliable evaluation (e.g., handling of context), their generative nature may also complicate the validation against some ground-truth.\nUltimately, a fully unified evaluation procedure may not be possible, because it depends on what information is available in a given assessment setting. Rather, we propose that an evaluation procedure ideally takes into account the main decisive factors of quality, as we exemplified for the Huckleberry Finn claim above: What quality dimension is of interest, who is the audience of the argument, and similar. The evaluation may happen on a careful selection of existing datasets, but new benchmarks that account for the factors may be needed, too.\nCriteria-wise, we see a mix of absolute and relative assessment as best approximating how humans assess quality, but this requires careful operationalization: Many argument quality dimensions imply some hard constraints, which speaks for an absolute part (e.g., are the argument’s premise acceptable?). However, there may not be a clear best/worst quality for an argument, which speaks for a relative part wherever other arguments are accessible (e.g., are the premises more acceptable than those of other arguments?). A manual rule-based scoring system should prepare an LLM for dealing with both parts and, hence, be evaluated against them."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Opportunities for the Real World",
            "text": "Arguably, instruction-following LLMs generally provide great opportunities for NLP and its applications. Their wide and easy applicability, along with their often low need for task-specific training data, is particularly beneficial in the context of interdisciplinary research. With a successful realization of the blueprint delineated above, however, we explicitly see specific potential for computational argumentation applications, due to their inherent need for argument quality assessment (see Section 1  ###reference_###). We now sketch some of the main opportunities we see. Partly, they bring up ethical concerns, though, that we discuss at the end of the paper (Section 6  ###reference_###).\nSo far, one of the most impressive applications is IBM’s Project Debater, which has competed well with professional human debaters Slonim et al. (2021  ###reference_b106###). Its quality assessment methods are audience-agnostic Toledo et al. (2019  ###reference_b115###); Gretz et al. (2020  ###reference_b41###), which may not suffice to convince people across diverse backgrounds, as research indicates Alshomary et al. (2022  ###reference_b2###). Moreover, Project Debater’s arguments are retrieved, recomposed, and rephrased rather than written naturally. If controlled well, the generation capabilities of LLMs may advance notably on the latter, whereas our proposed fine-tuning process may explicitly target the adjustment to audiences.\nArgument search aims to find the best pros and cons on controversial topics. Unlike for debating technologies, its goal to aid self-determined opinion formation suggests not to tune towards audiences. However, argument search engines miss a reliable quality-based ranking so far Wachsmuth et al. (2017c  ###reference_b122###); Stab et al. (2018  ###reference_b109###); Dumani et al. (2020  ###reference_b23###), likely due to the heterogeneity of argumentative domains and genres on the web. The low training need of instruction-following LLMs may alleviate this shortcoming. In addition, the text rewriting capabilities of LLMs may be employed to optimize the presentation of arguments Skitalinskaya et al. (2023  ###reference_b104###), or to fill gaps as needed. We expect that convincing rankings and presentations are key to making people open to argument search, enabling them to overcome filter bubbles.\nThe moderation of (online) content is critical to ensure healthy and productive discussions Park et al. (2012  ###reference_b88###, 2021  ###reference_b85###); Vecchi et al. (2021  ###reference_b119###). This holds particularly for deliberative contexts, where participants should be supported in communicating their viewpoints.\nEffective moderation reaches a bottleneck as the scale of online discussions grows Klein (2012  ###reference_b60###); Shortall et al. (2022  ###reference_b101###). LLMs instructed for argument quality can assist moderation efforts by detecting possible violations of community guidelines, inappropriate language, or generally low-quality arguments in discussions. This way, moderators can focus their attention on nuanced cases and appeals, optimizing efficiency and ensuring a healthier discourse. In some settings, generative LLMs could even lead a dialogue with users to provide clarifications, feedback, and improvement suggestions.\nLLMs may further provide individualized education to learners (e.g., students or non-native speakers) as well as to everyday writers (e.g., e-commerce customers), for instance, by giving feedback on the quality of their arguments Carlile et al. (2018  ###reference_b14###); Chen et al. (2022a  ###reference_b17###). Instruction fine-tuning makes it easier to go beyond simple quality scoring (e.g., how clear an argument is) to targeted hints (e.g., Provide more evidence for your initial claim!). Prompted with the writing goal, LLMs may also suggest argument completions, such as missing conclusions Gurcke et al. (2021  ###reference_b44###). With these means, students may learn to reason more soundly, product reviews can become more informative, and so forth. LLMs instructed with the concrete feedback scenario (e.g., a student learning to write essays in English) will help to further individualize support and may even adjust to the specific learning need of the user.\nIn several other scenarios, argument quality is crucial. One example is to generate summaries of the best arguments in news articles Syed et al. (2020  ###reference_b111###) or online discussions Syed et al. (2023  ###reference_b112###). Here, instruction-following LLMs can interpret the term best as needed—without any task-specific fine-tuning. In the medical domain, argument quality plays a central role for evidence-based medicine Mayer et al. (2021  ###reference_b79###). A well-instructed LLM may assess evidence strength, thus enabling better inferences based on clinical trials or reports. Similarly, the reasonableness of arguments on health discussion online platforms may be evaluated.\nFurther scenarios include e-commerce. There, an LLM-based service chatbot can, for example, select arguments based on quality notions (e.g., clarity) to explain to customers why a request cannot be completed, to minimize their dissatisfaction. Argument quality may also be assessed in recommender systems to make justified suggestions based on compelling reasons.\nFinally, we also see great potential for diversity and subjectivity-aware instruction fine-tuning when it comes to driving fundamental research, as sketched here for two examples: interdisciplinary work at the interface of NLP and computational social science, and the methodological development driven by the need to cope with subjectivity in argument quality annotations.\nThe social science context adds even more diversity, including sophisticated quality notions and domain-specific language, along with new challenges, such as well-curated and annotated, but small and imbalanced datasets Falk and Lapesa (2022  ###reference_b33###). Our instruction fine-tuning blueprint fits exactly such scenarios: annotation guidelines serve as instructions, highly-curated annotations as reinforcement examples, and the knowledge encoded in LLMs alleviates resource-lean issues. Additionally, the scene-setting function of instruction fine-tuning (see Section 3  ###reference_###) has the potential to address the deliberative goal of defining and quantifying discourse quality across contexts Esau et al. (2021  ###reference_b31###).\nThe multiple factors of subjectivity influencing argument quality perception (debater and audience beliefs, values, etc.) often limit the inter-annotator agreement Wachsmuth et al. (2017b  ###reference_b121###). Ultimately, subjectivity is a constitutive feature of argument quality, as indicated above. Romberg (2022  ###reference_b98###) suggest to join the perspectivist turn of machine learning and NLP Plank (2022  ###reference_b93###); Cabitza et al. (2023  ###reference_b12###) in computational argumentation. LLMs’ perspective-taking capabilities could be a game changer for this, assuming that the risks of sociodemographic prompting Beck et al. (2023  ###reference_b8###) and stereotypes Cheng et al. (2023  ###reference_b19###) are properly dealt with."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Conclusion",
            "text": "Argument quality assessment has become a core task in NLP research on computational argumentation, due to its importance for various applications, from debating technologies and argument search to discussion moderation and writing support. However, a reliable assessment is often hampered by the diversity of quality notions involved and the subjectivity of their perception. In this survey-based position paper, we have raised the question of how to drive research on instruction-following large language models (LLMs) for argument quality to substantially evolve the state of the art.\nOur survey of 83 recent papers confirms that argument quality research often targets conceptual quality notions and the factors that influence these notions, aside from the computational assessment and improvement of argument quality. We have argued that many limitations of prior work can be overcome, if LLMs are not just simply prompted for argument quality assessment, but if systematic ways to instruct LLMs for argument quality during instruction fine-tuning are found. This is due to the fact that instruction-following LLMs, for the first time in machine learning-based NLP research, make the connection between inputs and outputs of tasks explicit, namely, through the instructions. Thereby, all knowledge that an LLM has processed during pretraining and fine-tuning can be shared across tasks and contexts.\nTo guide future work in this direction, we have delineated a blueprint of how to approach the instruction fine-tuning process. Realizations of this process will likely bring up further problems, not all are foreseeable at this point. Moreover, LLMs that effectively predict human perception of argument quality directly raise concerns, as detailed in our ethics statement below. Still, we are confident that coordinated efforts towards sustainable research on LLMs for argument quality will enable the community to progress on core visions of computational argumentation—whether it is about ways to overcome filter bubbles or about the individualized support of argumentation learners. The paper at hand seeks to lay the ground for this research."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Ethics Statement",
            "text": "Despite the huge potential of instruction-following LLMs for argument quality assessment across various applications of computational argumentation outlined in Section 4  ###reference_###, the blueprint from Section 3  ###reference_### also comes with limitations and ethical concerns. We acknowledge and analyze these in this section."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1.   Limitations",
            "text": "The discussed potential we see is based on our survey of argument quality research (Section 2  ###reference_###), initial works of the emerging body of instruction fine-tuning research (e.g., Peng et al., 2023  ###reference_b90###), and our own preliminary tests. Yet, the work at hand remains a position paper, meaning that experimental research still needs to establish whether the outlined blueprint or similar paths will actually result in substantial progress. It is possible that argument-specific instruction fine-tuning of large language models (LLMs) does not improve over the capabilities of a general large-scale tuning. Also, the systematic ways that we have proposed to establish above remain to be found; there is no obvious way of directly obtaining them. This challenge is in line with the overall state of instruction fine-tuning research, both in academia and in industry.\nRegarding the specific challenges of argument quality raised in Section 1  ###reference_###, another limitation refers to general possibility that information required to achieve a realiable assessment is simply not available, due to specificities of the setting or underlying privacy regulations. This particularly includes the audience whose quality perception is to be represented, but possibly also aspects of the (temporal, geographical, and social) context in which an argument is to be considered. Also, as soon as we rely on human-created training data for instruction fine-tuning, the creators’ biases and values affect its impact. Ultimately, we cannot expect LLMs to tackle a task reliably under conditions that simply do not suffice to make an informed judgment."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "6.2.   Ethical Concerns",
            "text": "Many arising ethical issues of the use of LLMs for argument quality assessment are general and not specific to computational argumentation, such as the increased environmental impact of bigger models, privacy issues, hallucinations, the potential of models to encode unfair exclusive Dev et al. (2021  ###reference_b20###); Lauscher et al. (2022a  ###reference_b67###) and stereotypical biases Blodgett et al. (2020  ###reference_b10###), which may result in allocational and representational harms (Barocas et al., 2017  ###reference_b7###). However, we believe that some of them deserve specific attention in scenarios where argument quality is assessed or optimized, particularly when leveraging the power of LLMs.\nIn particular, argument quality assessment may be used in sensitive applications such as digital education; for example, to support argumentative writing or to provide guidance on political opinion formation. For such applications, factual errors are particularly problematic, as they may easily lead to wrong or shifted beliefs. Whenever LLMs may generate argumentative content, say, for debating technologies or to fill gaps in argument search as discussed, extra measures should thus be taken to prevent hallucinations. We have sketched how to generally account for them in Section 3  ###reference_###, but fully avoiding them may be hard given how LLMs work.\nSimilarly, unfair social biases are easy to perpetuate in such applications, since the output of LLMs for argument quality assessment will often directly affect human views. This raises various integral and partly self-referential questions, such as who decides on what makes a good argument, or, how to decide on the ethical uses of instruction-following LLMs in argument quality assessment? We expect that universally-accepted answers to these questions may not exist, as they also depend on the values within a culture or society.\nAs the limitations discussed above imply, further ethical concerns refer to the tension between the inclusion of audience and debater information for a more accurate quality assessment. While an argument’s persuasive effect is, for instance, highly dependent on the sociodemographic aspects of its audience, it is questionable in general to what extent an application of respective methods should have access to personal data. Such aspects need to be handled with care, and under consultation with an ethics board, where needed.\nFor a successful and societal beneficial use of instruction-following LLMs, we thus conclude that future research on argument quality assessment needs to find answers to such questions and to proactively raise and discuss them explicitly."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Acknowledgments",
            "text": "This work was partially funded by the Deutsche Forschungsgemeinschaft (DFG) within the project OASiS, project number 455913891, as part of the Priority Program “Robust Argumentation Machines (RATIO)” (SPP-1999), as well as within the project ArgSchool, project number 453073654. It was also partially funded by the Bundesministerium für Bildung und Forschung (BMBF) within the project E-DELIB, project number 01IS20050, and under the Excellence Strategy of the German Federal Government and the States.\nThis work has also been supported by the French government, through the 3IA Côte d’Azur Investments in the Future project managed by the National Research Agency (ANR) with the reference number ANR- 19-P3IA-0002."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Bibliographical References",
            "text": ""
        }
    ]
}