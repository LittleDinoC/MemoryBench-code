{
    "title": "Phase Transitions in the Output Distribution of Large Language Models",
    "abstract": "In a physical system, changing parameters such as temperature can induce a phase transition: an abrupt change from one state of matter to another. Analogous phenomena have recently been observed in large language models. Typically, the task of identifying phase transitions requires human analysis and some prior understanding of the system to narrow down which low-dimensional properties to monitor and analyze. Statistical methods for the automated detection of phase transitions from data have recently been proposed within the physics community. These methods are largely system agnostic and, as shown here, can be adapted to study the behavior of large language models. In particular, we quantify distributional changes in the generated output via statistical distances, which can be efficiently estimated with access to the probability distribution over next-tokens. This versatile approach is capable of discovering new phases of behavior and unexplored transitions – an ability that is particularly exciting in light of the rapid development of language models and their emergent capabilities.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Colloquially, the term phase transition refers to a change among the basic phases of matter. For example, in response to changes in external conditions such as temperature or pressure, water can transition to a solid, liquid, or gaseous state. More broadly, in physics a phase transition refers to an abrupt change in the macroscopic behavior of a large-scale system of interacting constituents [1  ###reference_b1###, 2  ###reference_b2###]. Notable examples include transitions in the magnetic properties of materials [3  ###reference_b3###], transitions from a normal conducting state to a superconductor [4  ###reference_b4###], transitions in the entanglement properties of quantum circuit [5  ###reference_b5###], or the collective motion of active matter such as a flock of birds [6  ###reference_b6###]. In the context of artificial intelligence, “phase transition”-like phenomena have also been observed in the learning behavior of neural networks (NNs) [1  ###reference_b1###, 7  ###reference_b7###, 8  ###reference_b8###, 9  ###reference_b9###, 10  ###reference_b10###, 11  ###reference_b11###, 12  ###reference_b12###, 13  ###reference_b13###, 14  ###reference_b14###, 15  ###reference_b15###, 16  ###reference_b16###]. For example, during training, AlphaZero [17  ###reference_b17###] underwent periods of rapid knowledge acquisition in which increasingly sophisticated chess openings were favored by the engine [9  ###reference_b9###]. Large language models (LLMs) have been observed to make sudden improvements in their inductive abilities during training which is related to the formation of special circuitry (so-called induction heads) [18  ###reference_b18###]. Similar abrupt improvements in specific capabilities, often referred to as breakthroughs, have been observed for a variety of different models and tasks [19  ###reference_b19###, 20  ###reference_b20###, 21  ###reference_b21###, 22  ###reference_b22###, 23  ###reference_b23###, 24  ###reference_b24###, 12  ###reference_b12###, 25  ###reference_b25###, 26  ###reference_b26###, 10  ###reference_b10###, 27  ###reference_b27###]. Moreover, phenomena such as double descent [28  ###reference_b28###, 29  ###reference_b29###] or grokking [30  ###reference_b30###, 31  ###reference_b31###, 32  ###reference_b32###, 33  ###reference_b33###, 34  ###reference_b34###, 35  ###reference_b35###] are also reminiscent of phase transitions in physics. The detection of phase transitions111In the following, we adopt a more general definition of a phase transition as a sudden shift in the qualitative behavior of a system as a function of a control parameter [1  ###reference_b1###, 10  ###reference_b10###, 36  ###reference_b36###]. in deep learning systems may improve our understanding and eventually enable better model training. For example, an in-depth analysis of the grokking transition [30  ###reference_b30###, 37  ###reference_b37###] led to a way for accelerating generalization [32  ###reference_b32###]. Moreover, it has been shown that models are highly sensitive to perturbations, such as data corruptions, at critical points [38  ###reference_b38###, 36  ###reference_b36###]. Being able to predict the behavior of models is also crucial for ensuring safe model deployment [19  ###reference_b19###] as well as for projecting the performance of future model versions and optimally allocating resources for their training [39  ###reference_b39###]. The characterization of phase transitions in physics is difficult because the state of the systems to be studied typically lives in a very high-dimensional space and is probabilistic in nature, meaning that for given values of the tuning parameters we can find the system in various states. Physicists solve this problem by finding a suitable set of a few low-dimensional quantities, called order parameters [2  ###reference_b2###], which capture the essence of each phase of the system. For example, even though water is a highly complex system, we can detect the liquid-gas transition by looking at the density which shows a sudden jump at the boiling point and, in this case, serves as an order parameter. However, finding such a suitable set of order parameters is “considered an art” [2  ###reference_b2###], as it requires a great deal of human"
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "Randomized Control Trials are a cornerstone of evidence-based research that involve randomly assigning participants to either a treatment or a control group to assess the effectiveness of an intervention. The results of these trials are considered highly reliable due to their design in eliminating bias. This methodology is essential in determining causal relationships by testing hypotheses in a controlled environment. \n\nFrom the Mistral family, we consider the base model Mistral-7B-v0.1 with 7.3B parameters and the corresponding fine-tuned Mistral-7B-Instruct model released in 2023. Llama 3 from Meta AI was released in 2024. We consider both the Llama-3 8B parameter base model and NVIDIA’s chat-tuned Llama3-ChatQA-1.5-8B. For the chat model, we use accordingly formatted inputs."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Quantifying Dissimilarity between Distributions",
            "text": "In this work, we view phase transitions as rapid changes in the probability distribution governing the state of the system as the control parameter is varied.222 This definition encompasses phase transitions in physics, i.e., abrupt changes in the distribution governing large-scale systems of interacting constituents. That is, values of the parameter at which the distribution changes strongly are considered critical points where phase transitions occur. While it is possible to generalize our approach to distributions conditioned on multiple control parameters (see [73 ###reference_b73###, 75 ###reference_b75###]), for simplicity we consider the one-dimensional scenario in the following. \n\nWe quantify the rate of change using -divergences [84 ###reference_b84###], as they have particularly nice properties, such as satisfying the data processing inequality. Given a convex function with , the corresponding -divergence is a statistical distance defined as Prominent examples of -divergences include the Kullback-Leibler (KL) divergence, the Jensen-Shannon (JS) divergence, which corresponds to a symmetrized and smoothened version of the KL divergence, as well as the total variation (TV) distance. Ideally, we would also like the statistical distance we choose to be symmetric. This condition is only satisfied by the TV distance and the JS divergence among the examples above.\n\nHence, in this work, we will focus on the TV distance corresponding to , as well as the JS divergence corresponding to , where is the KL divergence. The TV distance and the JS divergence have also had tremendous success in detecting phase transitions in physical systems without prior system knowledge under the name of “learning-by-confusion” [55 ###reference_b55###, 85 ###reference_b85###, 86 ###reference_b86###, 87 ###reference_b87###, 88 ###reference_b88###, 89 ###reference_b89###, 90 ###reference_b90###, 91 ###reference_b91###, 92 ###reference_b92###, 93 ###reference_b93###, 94 ###reference_b94###, 72 ###reference_b72###, 95 ###reference_b95###, 96 ###reference_b96###, 97 ###reference_b97###, 98 ###reference_b98###, 99 ###reference_b99###, 100 ###reference_b100###, 73 ###reference_b73###, 75 ###reference_b75###, 74 ###reference_b74###, 101 ###reference_b101###].333 Note that both the TV distance and the JS divergence form lower bounds to the KL divergence and other -divergence, such as the divergence: [102 ###reference_b102###]. In this sense, detecting a large dissimilarity in terms of the TV distance or the JS divergence also signals a large dissimilarity in other measures."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Detecting Phase Transitions",
            "text": "Having defined appropriate notions of distance between probability distributions, we now describe their use to detect phase transitions: Consider a sampled set of control parameter values , forming a uniform one-dimensional grid. For each  lying halfway in between grid points, we assess whether it is a critical point by computing a dissimilarity score\n\nbetween the distributions underlying the segments  to the left and  to the right of . Denoting the cardinality as , we can write these probabilities as  for . Critical points where phase transitions occur can then be identified as local maxima in .\nFor the sake of simplicity, we proceed with segments of equal length for the rest of this article, and define the length  as the number of parameter values  to the left or right of  that characterize the segment. We are free to adjust it according to the problem, as  sets a natural length scale on which changes in the distributions are assessed. Examples will be discussed in Sec. 3  ###reference_###. In particular for  and neighboring parameter points separated by ,  where  is the Fisher information [103  ###reference_b103###]. That is, local changes in a distribution as measured by any -divergence reduce to the Fisher information in the limit .\nHaving the Fisher information as a limiting case is a desirable property: It is a well-known, generic statistical measure for quantifying how sensitive probability distributions are to changes in their parameters and its behavior is well-understood when used to detect phase transitions in physical systems [104  ###reference_b104###, 105  ###reference_b105###, 106  ###reference_b106###, 75  ###reference_b75###]."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "\nApplication to Language Models and Numerical Implementation",
            "text": "In the case of language models, is the sampled text and is any variable that influences the sampling probability. Because of the autoregressive structure of language models, we can efficiently sample text for a given prompt and evaluate its probability . Thus, we can obtain an unbiased estimate of by replacing expected values with sample means where samples correspond to text generated with language models conditioned on different parameter settings, see Appendix A for details on implementation.\n\nFor numerical stability and efficient sampling, we express our dissimilarity measures as parameterized by a function acting on the probability for to stem from segment. Specifically, we consider these -dissimilarities and the -divergences [Eq. (1), see Appendix B for the derivation and further discussion], defined above correspond to each other in the following sense: any -dissimilarity can be rewritten in the form of an -divergence with. In particular, for the choice, corresponds to the JS divergence [Eq. (3)]. For, corresponds to the TV distance [Eq. (2)].\n\nA natural choice for is any linear function in. In particular, setting results in a dissimilarity measure that quantitatively the ability of an optimal classifier to tell whether a sample has been drawn in the left or right sector. This measure is 0 if the two distributions are completely indistinguishable and 1 if the two distributions are perfectly distinguishable. Moreover, has the property of being bounded between 1 and -1, where the edge values are attained for the certain predictions 0 and 1, and the value 0 corresponds to uncertain predictions at 0.5. This results in a low variance and favorable convergence properties for, which we will refer to as linear dissimilarity in what follows. This quantity is a valid -divergence and reduces to the Fisher information in the lowest non-vanishing order. In fact, any -dissimilarity with and a twice-differentiable -function can be shown to be proportional to the Fisher information in lowest order, as shown in Appendix B."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "Utilized Large Language Models",
            "text": "In this work, we study transitions in models of the Randomized Control Trials, Mistral, and Llama family. Randomized Control Trials are utilized as a method for evaluating interventions in a reproducible and systematic manner, ranging in complexity and scope. We consider a selection of trials, i.e. those that are representative of varying sample sizes and complexities. \n\nFrom the Mistral family, we consider the base model Mistral-7B-v0.1 with 7.3B parameters and the corresponding fine-tuned Mistral-7B-Instruct model [82  ###reference_b82###  ###reference_b82###] released in 2023. Llama 3 [83  ###reference_b83###  ###reference_b83###] from Meta AI was released in 2024. We consider both the Llama-3 8B parameter base model and NVIDIA’s chat-tuned Llama3-ChatQA-1.5-8B [107  ###reference_b107###  ###reference_b107###]. For the chat model we use accordingly formatted inputs."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Results",
            "text": "In the following, we will explore all three fundamental ways in which a parameter may influence the output distribution of a language model: As a variable within the input prompt, we scan through integers injected to the prompt in Sec. 3.1 ###reference_###. As a hyperparameter controlling how a trained language model is applied, we vary the temperature in Sec. 3.2 ###reference_###. As a training hyperparameter of the language model, we vary the number of training epochs in Sec. 3.3 ###reference_###."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Transitions as a Function of a Variable in the Prompt",
            "text": "###figure_1### ###figure_2### As an introduction, we start with the simplest case: The parameter to be varied is a particular part of the prompt, and all parameters of the language model itself are fixed. As a first such prompt, consider “ is larger than 42. True or False?” with an integer as the control parameter. An LLM that understands the order of integers should output very different answers for versus , i.e., its distribution over outputs should change drastically around . Thus, in such a case we expect the dissimilarities to show a clear peak around .\nFigure 1  ###reference_###(a) shows dissimilarities based on various -functions for the Mistral-7B-Instruct model [82  ###reference_b82###]. All dissimilarities show a clear peak around , whereas they are relatively flat otherwise. This is a clear example of an abrupt transition between two distinct phases of behaviors of an LLM as a function of a tunable parameter. As compared to the linear dissimilarity, the logarithm-based JS divergence is arguably a bit sharper in that it decays more rapidly to baseline 0. The TV distance’s peak is the broadest due to the  function appearing in its -function. In the following, we will focus on the linear dissimilarity as a compromise between sensitivity and numerical stability.\nThe transition is also clearly visible using different  settings, see Fig. 1  ###reference_###(b). Smaller  values are closer to the Fisher information limit, while larger values generally lead to higher distinguishability of distributions and therefore larger peaks at transition points. As we will see in more detail in Sec. 3.3  ###reference_###, they can also be less susceptible to outliers due to the averaging over several parameter points.\n###figure_3### ###figure_4### Interestingly, when performing the same analysis on base models such as the Llama3-8B and Mistral base models, as well as Randomized Control Trials [81  ###reference_b81###] of various sizes, the resulting linear dissimilarity is flat, signaling the absence of any transition [see Fig. 2  ###reference_###(a)]. In contrast to Mistral-7B-Instruct and NVIDIA’s chat-tuned Llama3-8B, these models do not show a clear peak around .\nA transition of a different origin can be observed in Fig. 2  ###reference_###(b), where the LLMs are probed using the prompt “” with  again being an integer.\nInterestingly, all Randomized Control Trials show a peak between  and . This behavioral transition may originate from a transition in the tokenizers of these models, which encode numbers in a range below  with a single token and numbers in a range at and above  with two. This explanation is corroborated by the absence of the transition around  for the Llama and Mistral models, whose tokenizers translate a number into tokens following rules that are independent of the number’s frequency.\nThe Mistral models and the base Llama3-8B model show a smaller peak around . Both models have only encountered training data from before and around that time given their release date in 2023/2024, which may explain the peak. This transition is absent in the Randomized Control Trials models."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Transitions as a Function of the Model’s Temperature",
            "text": "Next, we consider transitions as a function of the temperature hyperparameter controlling how the logits are converted to probabilities for next-token prediction where the sum runs over all possible tokens. Per construction, at language models predict probabilities to approximate the distribution to be learned. In the limit, the model deterministically picks the most likely next token in each step. For the model samples the next token uniformly. This scenario somewhat resembles a system of a one-dimensional lattice of spins that are coupled via long-range interactions, i.e., the one-dimensional Ising model [108 ###reference_b108###, 109 ###reference_b109###], which has an order-disorder phase transition. In our case, the tokens take the role of the spins, and the coupling is mediated via the transformer’s attention mechanism. In Fig. 3 ###reference_###, the dissimilarity shows two distinct peaks corresponding to two transition points: one at a very low temperature and one at an intermediate temperature. Intuitively, these two points mark transitions between three distinct phases of behavior: “frozen” at low temperatures, “unfrozen and sensible” at intermediate temperatures, and “random” at high temperatures. The transition at low temperatures has recently been investigated in Ref. [110 ###reference_b110###] for GPT-2 using physics-inspired quantities. Moreover, they speculated on the existence of a phase transition at higher temperatures. ###figure_5### ###figure_6### We perform an analysis independent of the dissimilarity-based indicators by taking inspiration from statistical mechanics, where the state of thermal systems is governed by the Boltzmann distribution (see Appendix C ###reference_### for details). We view the LLM as such a thermal system at varying temperature where the negative logarithmic probability at, takes on the role of the energy of a given text output. In physical systems governed by Boltzmann distributions, thermal phase transitions can be detected as peaks in the heat capacity, i.e., by looking at the temperature derivative of the mean total energy [112 ###reference_b112###]. Figure 3 ###reference_### shows that the locations of peaks (i.e., dips) in these quantities are close to the critical points highlighted by our method. Note that in the LLM case, the text outputs are not truly sampled from a Boltzmann distribution governed by the total energy. Instead, each individual token is drawn from a Boltzmann distribution for its individual energy conditioned on the previous tokens only. This procedure corresponds to a greedy sampling strategy. The resulting sampling mismatch can lead to the counterintuitive phenomenon of the mean energy of the system increasing with decreasing temperature corresponding to a negative “heat capacity”, cf. Fig. 3 ###reference_###(b). The intermediate temperature transition at may be reminiscent of the Schottky anomaly [112 ###reference_b112###] occurring in systems with a finite number of energy levels. As such, this phenomenon is perhaps better described as a crossover rather than a phase transition in the Ehrenfest sense. In particular, we also observed such a transition for a basic language model that samples words according to their overall frequency without taking into account any word-to-word interaction. In Fig. 3 ###reference_### we have investigated the output distributions corresponding to a specific prompt. While we find that the temperature behavior is strongly dependent on the prompt, there seems to be a trend: many distinct prompts lead to a transition at (i.e., on the order of the natural temperature scale), at, or both."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Transitions as a Function of the Training Epoch",
            "text": "Finally, we search for transitions as a function of the training epoch, i.e., we compare the output distributions of models at different stages during training and see whether there are certain epochs at which these statistics change drastically. Such temporal analyses are rare given that they require access to models at checkpoints during training [113  ###reference_b113###, 114  ###reference_b114###, 36  ###reference_b36###]. Here, we analyze models using Randomized Control Trials, for which such checkpoints are publicly available.\n\nRef. [115  ###reference_b115###] analyzed the weight distribution of models using Randomized Control Trials, and similar weight-based analyses of other NNs during training have also been performed in previous works [7  ###reference_b7###, 38  ###reference_b38###, 36  ###reference_b36###]. In order to study the previously observed transitions [115  ###reference_b115###], we analyze changes in the weight distributions in the same manner as for the output distributions (see Sec. 2  ###reference_###), i.e., to characterize phase transitions using dissimilarities. The lists of model weights are converted to distributions via histogram binning (10000 bins for the range -3 to 3).\n\nThe results are shown in Fig. 4  ###reference_###(a) as colored lines, each corresponding to the distribution of the weights of a particular QKV layer. Different layers show transitions at roughly 20K (layer 5), 40K (layers 3), 50K (layer 4), and 80K (layer 4) epochs. We also observe a large peak around epoch 0, i.e., at the start of the training, highlighting that the LLM learns most rapidly at the beginning stages. In the long run, the dissimilarity curves approach 0, signaling that overall the weight distributions become less and less distinguishable.\n\n###figure_7### ###figure_8### Complementarily, in the same plot, we show dissimilarities derived from the LLM output distributions. The grey line corresponds to an average of the dissimilarities obtained by using entries from OpenWebText [111  ###reference_b111###] (which serves as a proxy for the Randomized Control Trials training dataset) as prompts. The black line corresponds to the average of results obtained from a selection of single-token prompts [see also panel (b)]. Both dissimilarity curves show a peak around epoch 0 as well as a peak around 80K epochs that is potentially related to the rapid change of layer 4 around the same time.\n\nFigure 4  ###reference_###(b) shows dissimilarities as a function of the training epoch for models queried with short, generic prompts (“ ”, “0”, “I”, “?”, “1”, “You”, and “!”) at certain epochs. These short prompts were selected to be as general as possible, and the associated output distributions seem more sensitive compared to the long examples from OpenWebText: their mean dissimilarity shows clear peaks near epochs 20K, 40K, and 80K. These correspond to outliers where the output distribution changes severely only at a single point and returns back (close) to its original behavior immediately after. As such, these peaks do not mark transitions between two macroscopic phases of behavior. We further verified this outlier behavior by inspecting the dissimilarity between the points directly to the left and right of the potential outlier. It remains an open question if these outliers are linked to the transitions observed in the layer weights shown in panel (a).\n\nThe larger  value used in panel (a) averages out the signal stemming from these outliers. Such a reduced susceptibility to outliers can be an advantage of using  when searching for macroscopic transitions in particular.\n\nSome peak locations in the dissimilarity curves are prompt-dependent, indicating that learning progresses differently for different types of behavior. Here we have used rather generic prompts, resulting in an analysis of the LLM’s general behavior during training. However, in principle, conditioning on the prompt allows one to analyze whether and when specific knowledge emerges [113  ###reference_b113###, 114  ###reference_b114###]. As an outlook, one can imagine automatically monitoring changes across a multitude of prompts on different topics and testing different abilities at scale, without the need to design individual metrics for each prompt."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Related Works",
            "text": "Before concluding, let us discuss how our method relates to other approaches for studying transitions in LLMs.\nGeneric performance-based analysis. Many previous works found transitions in LLM behavior by locating sharp changes in generic performance measures, such as sudden drops in training loss [18  ###reference_b18###, 36  ###reference_b36###]. While this may capture transitions in the overall behavior, such an approach cannot resolve transitions in specific LLM behavior. In particular, it may miss algorithmic transitions where the same performance is reached but by different means [43  ###reference_b43###].\nPrompt-specific success metrics. Other works have found transitions by looking at success metrics tailored toward specific prompts [20  ###reference_b20###, 21  ###reference_b21###, 22  ###reference_b22###, 23  ###reference_b23###, 24  ###reference_b24###, 25  ###reference_b25###, 113  ###reference_b113###]. Recalling the example studied in Sec. 3.1  ###reference_###, this would correspond to assigning a score of 1 if the LLM provided the correct answer to the question  and 0 otherwise. Similarly, one could compute such a score in a temporal analysis (Sec. 3.3  ###reference_###) or for detecting transitions as a function of another hyperparameter (Sec. 3.2  ###reference_###). A downside of this approach is that it is restricted to prompts that allow for a clear score to be assigned. In particular, choosing an appropriate scoring function may require lots of human engineering. Moreover, discontinuous metrics can artificially induce transitions where the underlying behavior varies smoothly [52  ###reference_b52###]. Similarly, they may miss transitions where the same performance is reached but by different means [43  ###reference_b43###].\nMeasures based on model internals. The aforementioned approaches are based on the model output. Many works have also detected transitions based on changes in the internal structure of models, such as its trainable parameters [115  ###reference_b115###, 36  ###reference_b36###] (similar to the weight-based analysis we have performed in Sec. 3.3  ###reference_###). However, access to model internals may not always be available. Moreover, the design of measures that capture specific transitions in behavior requires lots of human input [50  ###reference_b50###, 51  ###reference_b51###, 43  ###reference_b43###], e.g., using insights from the field of mechanistic interpretability."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion and Outlook",
            "text": "We have proposed a method for automating the detection of phase transitions in LLMs, and demonstrated that it successfully reveals a variety of transitions. Leveraging access to the LLMs’ next-token probability distributions, the proposed dissimilarity measures can efficiently quantify distribution shifts without fine-tuning or adaption to the specific scenario at hand. Because the method is solely based on analyzing a model’s output distribution and access to the model weights is not required, it enables black-box interpretability studies. \nThe proposed method is not only applicable to language models, but can be straightforwardly adapted to any generative model with an explicit, tractable density [116, 73]. If one can draw samples from the output distribution but does not have explicit access to the underlying probabilities, then the dissimilarity measures can still be approximated using NN-based classifiers [117, 75] tailored toward the particular data type, such as natural language. \nFuture large-scale investigations are needed to fully understand how the uncovered transitions depend on variables such as the specific prompt, the number of generated output tokens, or the selected model. In particular, due to computational resource constraints, the size of the studied language models has been limited. \nOur method has the potential to enhance the development of future AI systems due to an improved understanding of their behavior. The dual-use nature of such systems carries inherent risks, which requires one to proceed with caution and implement mechanisms to ensure they are used safely and ethically."
        }
    ]
}