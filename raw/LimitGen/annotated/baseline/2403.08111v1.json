{
    "title": "AI-Assisted Causal Pathway Diagram for Human-Centered Design",
    "abstract": "This paper explores the integration of human-centered design (HCD), investigating how this approach can enhance the early stages of the design process. A dedicated plugin for the online collaborative whiteboard platform Miro was developed to streamline design creation and offer real-time AI-driven guidance. Through a user study with designers, we found that this approach supported both divergent and convergent processes during design. It can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers’ cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1. Introduction",
            "text": "In this work, we offer several important contributions:\n\n1. Introduction and study of how practitioners can approach human-centered design in the early stages.\n2. Insights into a diagramming tool that helps designers generate and iterate on strategies to guide design.\n3. Insights into the challenges and opportunities of using digital assistance in supporting creative work and evidence-based designs.\n\nThe study revealed that designers are positive about integrating strategic frameworks in the early stages of human-centered design, especially for brainstorming and strategic prioritization. Designers emphasized approaches that directly address the root cause of the problem as a goal-oriented design process. However, designers also highlighted potential consequences of using suggestions irresponsibly and pointed out opportunities to make recommendations more evidence-based.\n\nThe main contributions of this study involve understanding practices in the early design phases and exploring tools that can aid in design processes. The findings underscore the potential for enhancing creative brainstorming and prioritization strategies, while advocating for responsible and evidence-based integration of external suggestions in the design workflow."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2. Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1. Theory Use in Human-Centered Design",
            "text": "Human-centered design (HCD) is based on the understanding that by thoroughly understanding people, we can create more effective designs (Shneiderman and Plaisant, 2010; Rogers et al., 2002; Carroll, 2003; Benyon, 2013). There is a longstanding tradition of using theory to guide design (Rogers, 2004), such as cognitive science theories for computer interfaces (Carroll, 1991), social psychology theories for online communities (Kraut and Resnick, 2012), and social and behavior theories for behavior change technologies (Consolvo et al., 2009).\n\nVan Turnhout and colleagues identify six key functions of theory in designing technologies (van Turnhout et al., 2019): (1) Description to consistently and clearly identify phenomena; (2) Explanation for exposing underlying causes and relationships; (3) Generative to support novel ideas and design alternatives; (4) Aspirational to define ideals and goals in design; (5) Prediction of effects in various situations; and (6) Prescription providing guidance on design practices.\n\nIn human-centered design, these functions appear in various stages. During brainstorming, theories can suggest ideas and support divergent thinking by identifying areas for exploration. They help consider how strategies influence user behavior and identify barriers. Theories assist in creating hypotheses about potential design outcomes. In the convergence stages, theories guide decisions on prototypes and implementations to optimize design goals. During evaluation, they inform study design and interpretation of findings. Theories also facilitate communication with stakeholders by explaining design goals and supporting design decisions.\n\nDespite the benefits, gaps between research and practice exist (Colusso et al., 2019; Norman, 2010; Gray et al., 2014; Roedl and Stolterman, 2013; Rogers, 2004). Effectively using theories in design poses challenges (Dourish, 2006; Schon, 1983). Barriers include designers' lack of training in basic science fields, making theory-driven approaches difficult (Beck and Stolterman, 2016; Colusso et al., 2017). Additionally, translating theoretical insights into real-world contexts is challenging (Rogers, 2004). Understanding when to engage theory and how to fit it into existing design processes is crucial for effective theory usage (Colusso et al., 2017, 2018)."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2. Causal Pathway Diagramming (CPD)",
            "text": "In this paper, we aim to explore methods that guide theory-driven human-centered design by examining how structured approaches can enhance design processes. In implementation science, evidence- or theory-based design is crucial to achieving intended changes, especially in health care and public health settings, where many implementations struggle to reach their goals. Structured approaches could contribute to different stages of design by informing strategy development, supporting brainstorming, increasing impact, and helping prioritize strategies for specific contexts.\n\nThere is a long-established history of using visual representations to describe relationships within variables across various fields. These representations are widely utilized in social and behavioral sciences and statistics. Such visual frameworks provide a way to plan and evaluate systems effectively, supporting nonprofits and philanthropy in adopting an evidence-based approach. However, the use of such visual mapping in human-centered design remains underutilized. Especially outside global health, where such methods are more commonly integrated, there is less reference to these approaches in human-centered design and human-computer interaction literature.\n\nOur work is grounded in a method developed by the OPTICC Center, focused on optimizing evidence-based intervention implementation. This method includes a formalized structure, starting with the intervention strategy, followed by mechanisms, barriers, and outcomes. Understanding these components can guide users in structuring their strategies more effectively. While having a structured syntax can improve consistency, it may also pose challenges in understanding and applying the approach. Hence, another research question we pursue is whether a tool can be developed to facilitate the use of structured pathways in design processes."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3. Potential Use of CPD During Ideation",
            "text": "Many tools have been designed to support creativity in HCD (Frich et al., 2019; Wang and Nickerson, 2017; Gabriel et al., 2016). However, few of these creativity support tools (CSTs) have been developed with an emphasis on supporting the generation of ideas in an evidence or theory-driven way. One set of CSTs simply stimulates designers to think creatively. These tools are not specific to the design context and often just contain inspirational images or words (Eames and Eames, 1952; Hsieh et al., 2023), or provocative concepts (Vines et al., 2012). Others support brainstorming by suggesting additional relevant ideas based on a set of existing ideas inputted by the user (Clark et al., 2018; Wan and Lu, 2023; Bunian et al., 2021; Feng et al., 2022; Lu et al., 2024; Wang et al., 2010; Andolina et al., 2015, 2017; Ferdowsi and Saad, 2023). Often, these tools help surface inspirational stimuli by varying the analogical distance, commonness, and modality of the example ideas (Chan et al., 2011; Lawton et al., 2023; Zhang et al., 2022; Cai et al., 2023; Zamfirescu-Pereira et al., 2023a). IdeaExpander, for example, draws on the conversations of group brainstorming and provides recommendations of related pictures to stimulate a divergent brainstorming process (Wang et al., 2010). Clark et al.’s work on creative writing suggests related information based on existing user inputs, which helped with ideating possible slogans and stories (Clark et al., 2018). VINS is a system that recommends relevant UI examples to support UI design brainstorming (Bunian et al., 2021). While these tools could help designers come up with more innovative ideas more efficiently, without the integration of evidence from user research or published research, it is unclear if the generated ideas will work when addressing the design problem."
        },
        {
            "section_id": "2.3.1",
            "parent_section_id": "2.3",
            "section_name": "2.3.1. AI-assisted creativity support tools",
            "text": "Thanks to the ability of AI to model data and extract knowledge (Hwang, 2022; Kun et al., 2019), creativity support tools have explored the use of AI in their design. One line of research is on using machine learning models fine-tuned to a specific domain to support a specific type of design and ideation task (e.g., Wan and Lu, 2023; Bunian et al., 2021; Clark et al., 2018; Feng et al., 2022; Lu et al., 2024; Wang et al., 2010). For example, VINS uses an attention-based neural network to retrieve related UI examples from a given collection to support the brainstorming process (Bunian et al., 2021), and recent work by Wan et al. (Wan and Lu, 2023) used GAN (generative adversarial network) trained with relevant research data to support visual brainstorming and help designers explore the semantic space of diagramming ideation. Despite the efficacy of such approaches, however, they are limited in that the set of evidence or resources these AI-assisted CSTs could draw on is quite limited. As most machine learning systems like these CSTs are trained specifically for one domain, they cannot easily generalize to other contexts. In addition, the evidence they use is often restricted in number or the range of content, as the sets were either hand-curated or drawn from a specific online resource."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3. Design of the Plugin",
            "text": "To streamline the process of supporting designers, we developed a plugin in Miro, a widely used diagramming platform. Miro lets users create diverse visual elements, such as text boxes, circles, and rectangles on a collaborative board. It is also often used in the early stages of Human-Centered Design (HCD) for brainstorming and ideation purposes. The simplicity of interactions and design elements within Miro, coupled with its plugin-friendly architecture, made it an appropriate platform for deploying and testing our concept.\n\nBelow we describe the design and implementation details of the key features embedded in our plugin. Our plugin uses a multi-tab design, where each feature of the plugin can be used separately and independently. We provide a more detailed visual walkthrough of each component in Appendix C."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1. Key Features of the Plugin",
            "text": "I'm sorry, I need the text of the section in order to make the required modifications. Please provide the text you'd like me to revise."
        },
        {
            "section_id": "3.1.1",
            "parent_section_id": "3.1",
            "section_name": "3.1.1. Component",
            "text": "For each item shown in the panel, users can easily drag and drop them onto the Miro board. Once the user drags and drops an element, the plugin creates an empty entity complemented by a hyperlinked title that directs users to the page that contains the definition of the entity. This not only facilitates quick access to the definition but also streamlines the process of element creation on the Miro platform, sparing users the hassle of manually having to locate the shape in the platform. Plus, the plugin shows the definition of the element in a tooltip when the user hovers their mouse over the element."
        },
        {
            "section_id": "3.1.2",
            "parent_section_id": "3.1",
            "section_name": "3.1.2. Wizard",
            "text": "To streamline the creation of educational models, we designed and developed a form-based wizarding tool that guides the user in a step-by-step manner. This functionality navigates users through the generation process by eliciting inputs for each component. We guide the creation using backward mapping, where participants focus on the distal outcome first, then work backward to the barrier, proximal outcome, strategy, and mechanism. For each component, the user is provided with an explanation of the component (e.g., Barrier - ”What is the obstacle that is getting in the way of achieving the desired outcome?”).\n\nOne of the challenges with the creation of educational models may be a lack of knowledge about relevant theory. In the long run, our plan is to establish a repository and to recommend factors from our repository. Until such a repository is well populated, we sought innovative methods to provide recommendations. \n\nOnce the user finalizes all components, users can easily drag & drop to a specific area on the board, creating a complete model populated with their inputs on a designated position."
        },
        {
            "section_id": "3.1.3",
            "parent_section_id": "3.1",
            "section_name": "3.1.3. Brainstorming",
            "text": "Our plugin provides users with the ability to explore potential candidates for a specific component. This feature supports expanding innovative thinking about addressing barriers. Users select a specific component they wish to brainstorm, and the plugin requests information regarding related components. With these inputs, the plugin generates and recommends candidates for the component."
        },
        {
            "section_id": "3.1.4",
            "parent_section_id": "3.1",
            "section_name": "3.1.4. Checking",
            "text": "In contrast to the previous features that primarily aim to initially create or brainstorm components, the checking feature is designed to help users verify the structures they have already generated. Specifically, our checking feature lets users diagnose if any of the following issues are present:\nOne or more required elements are missing\nOne or more elements are not connected correctly\nOne or more elements are connected in the wrong order\nThe structure does not start / end with specific elements\n\nThis feature mainly focuses on checking the basic correctness of what has been created. To start, users should select a generated structure on the board, including its components and connections between components. Then, users should click on the “check” button to perform the checking. If the selected structure does not contain any of the listed issues, we provide positive confirmation such as “No syntax issues!” If the selected structure contains one or more of these issues, we provide suggestive feedback about the specific problems, such as “You might consider adding the following components.”"
        },
        {
            "section_id": "3.1.5",
            "parent_section_id": "3.1",
            "section_name": "3.1.5. Help / Glossary",
            "text": "Finally, the help feature allows users to easily access the definition of an element that is already on the board. By selecting an existing element on the board and clicking on the \"learn more\" button, the plugin promptly displays the element's definition (i.e., strategy - \"Strategy is an element that the diagram is intended to unpack. It is important to make the strategy concrete, to write it as it would be performed in that particular setting.\")."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2. Implementation",
            "text": "Our system was built on a Javascript-based framework (SvelteKit), and deployed on the Miro SDK 2.0, which allowed the system to interact with the Miro board (e.g., add/detect items on the board)."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4. User Study",
            "text": "To understand the use of CPD and our plugin to support human-centered design, we conducted a user study with design practitioners."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1. Procedure",
            "text": "###figure_3### The study was a one-hour, within-subjects online study. First, we provided participants with an introduction to CPD, explaining its different components, and gave a tutorial on the process of generating a CPD using an example. We then asked participants to complete two 10-minute design sprints. For each design sprint, participants were given a design prompt, a user persona, and a scenario explaining the issues the persona was encountering in that context. Figure 3  ###reference_### shows an example design sprint. Participants were asked to generate CPDs to ideate possible solutions. We structured our study as design sprints as they are commonly used design methods during early-stage design to explore design ideas (Banfield et al., 2015  ###reference_b8###) and have been used in prior work to support the ideation of theory-driven designs (Colusso et al., 2018  ###reference_b22###).\nFor one of the design sprints, participants were given the plugin to help generate CPDs. In the other design sprint, they were not given the plugin. We randomized the order in which a participant would use the plugin, as well as the order of the design sprints to account for any ordering effects. After each design sprint, we asked participants questions about their experiences with using CPD (and the plugin when in the plugin condition). Details of these questions are shared in subsection 4.4  ###reference_###. After the design sprints, we interviewed participants to further understand their experiences. A detailed version of the protocol can be found in Appendix B  ###reference_###."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2. Recruitment & Participants",
            "text": "We recruited participants by posting a screener survey on social media. Of those who expressed interest, we were able to recruit 20 people to participate in our study. The study lasted an hour. All participants except one completed both design sprints. One participant had to leave early due to personal reasons and only completed one of the design sprints (one without the plugin). We provided a compensation of $50 gift card in compensation for an hour of the participants’ time. 13 of our participants are professional UX designers, while others are enrolled in design-related programs. 15 of the participants have at least 2 years of design experience, and all participants had no knowledge of causal pathway diagrams prior to the study. Detailed demographic information of the participants is shared in Appendix A  ###reference_###."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3. Qualitative Analysis",
            "text": "Each study session was recorded and transcribed using Zoom. We used thematic analysis on the transcripts. One researcher first used thematic analysis on five transcripts. Then four researchers discussed the excerpts extracted until they decided on a final codebook. The final codebook includes themes such as CPD facilitates brainstorming in the early stages of design, CPD helps establish a common language between designers, and AI recommendations help paraphrase ideas. The first author then used the codebook to code all 20 transcripts. Throughout the coding process, the researchers mainly focused on how designers used CPD in human-centered design, and how they used the plugin to generate CPDs."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "4.4. Measures & Statistical Analysis",
            "text": "After each design sprint, we asked participants to rate their experience on a Likert scale of 1-7, exploring whether having access to the plug-in influenced their experience generating CPDs. Specifically, we asked them to rate “how hard/easy it was to design a CPD”, “how hard/easy it was to create each component of CPD graphically”, and “how hard/easy it was to brainstorm the content of each component of CPD.” We also asked participants to rate their confidence in the structural correctness (all components are connected and ordered in the right way) and content usefulness (the likelihood of using the generated solution in the next stage of HCD) of the CPD generated. We analyzed these measures using paired sample t-tests to show how the use of the plugin influenced people’s experience using CPD for design.\nApart from the self-reported ratings, we also measured the amount of time participants spent on each design sprint and the number of CPD pathways designers generated for that sprint. We similarly performed paired sample t-tests to analyze the results."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5. Results",
            "text": "We focused our analysis on two aspects. First, we identified how the use of CPD facilitated evidence-based HCD. Secondly, we analyzed how our AI-assisted plugin helped UX practitioners more easily work with CPDs, identifying its potential to increase creativity and provide evidence-based support.\nRecall that creating CPDs involves mapping out factors of relevance and their relationships (e.g.“what is the distal outcome”, and “what is the barrier that may occur given this outcome”). Participants pointed out that when they performed this mapping, they had to think about the relevant constraints upfront. Thinking through all the possible barriers that may prevent strategies from achieving the outcome is a “realistic and down-to-the-ground strategy” (P7), and helps save time in the design process. For instance, P12 articulated that “instead of thinking about the happy and perfect best case user flow, it is more important to know the constraints.” P5 also pointed out that “laying out the barriers, setting up the constraints very very quickly” immediately highlights the pain point, so that “addressing these barriers would make the design goals quite tangible when thinking implementation strategies.” The close attention to the constraints behind a design prompt helps designers quickly break down the task at hand, and helps them focus their effort.\nAdditionally, participants appreciated the goal-oriented process, rather than free-form or solution-oriented as most existing design processes are (e.g., user journey map, whiteboarding, storyboarding, etc.). In many design sessions, practitioners may use whiteboarding to “simply throw out ideas, then sort out the details, whether an idea is a barrier or a mechanism at a later time.” (P7) Or they may use storyboarding, which starts at the beginning, and work from the solution to “play out how the solution impacts the outcome.” (P18)\nIn contrast, CPD starts from “the high-level vision of why focus on this particular problem, the distal outcome,” (P6) and “not just jumping into solutions.” (P2) The generation of a CPD emphasizes the answer to the question of “what is the long-term goal” and not to “what are some ways to solve this prompt” (P17). Starting the brainstorming process from these questions, the outcome of the design, is actually “a natural way of thinking, especially when tackling complex problems.” (P11) P16 pointed out that one needs to know “the root cause of the problem” as well as “the impact involved in resolving the issue” before “identifying the most effective way to address it.” (P16) Thus, CPD is effective in facilitating goal-oriented design because it offers “a direct connection between everything on the users’ side to the larger context side, from a visual standpoint.” (P6) Furthermore, CPD’s emphasis on the outcome helps designers pay attention to“the realistic and practical goal of the design,” (P15) and “addressing the most fundamental issue in the design context,” (P7) instead of thinking about “designing prettier solutions.” (P20)\nAs discussed in our quantitative findings, the use of the plugin increased the number of pathways designers were able to generate. Participants’ comments corroborated this observation and highlighted that some AI-generated content helped increase their creativity. For example, when given the same design sprints (Figure 5  ###reference_###), P13 (without tool) only generated one pathway, while P8 (with tool) not only generated a similar path as P13, but also generated a distinct second path.\nSpecifically, P8 commented that the brainstorming feature “prompted me to think about a new direction as I was thinking about what barriers there are in the problem space.” And P8 described that he would not have thought about “the idea of running an ad campaign in a short timeframe if I were just throwing out ideas by myself. But seeing the suggestions by the tool immediately clicked for me. So I also explored this path in the CPD.” Further, of the path that P13 and P8 generated that were similar, P8 also was able to consider a different mechanism. These differences would have allowed P8 a richer design space (that is still evidence-based) to explore. P9 shared a similar perspective: “having the AI on the side was like having lots of teammates with really different viewpoints.” Additionally, AI can be used to expand creativity by using it to weed out the wrong directions: “In any design, your first 50 ideas are going to be trashed, but you have to get them out to get to idea 51, which is how the AI can help.” (P14)\nAI did not always generate new ideas that the participants had not already thought of. When designers’ ideas overlapped with AI recommendations, designers found that how AI phrased these ideas was helpful. Participants noted that AI articulates these ideas in “effective, condensed phrasings,” or the AI “uses expressive terminologies (i.e. route optimization algorithms) to summarize” (P3). Reading the AI suggestions helped designers “build the idea firmly in the mind in a clear and direct way.” (P14) AI’s articulation and clarification of the concepts helped participants focus more of their energy on the “meaning and impact of the ideas” (P14), rather than “drilling on how to best describe them.” (P20). For example, when communicating the same barrier in their CPD (4(a)  ###reference_sf1### & 4(b)  ###reference_sf2###), P13 (without tool) had to use a full sentence to describe the barrier: “people are concerned that the metro does not follow the schedule” whereas P8 (using the tool) was able to describe it more succinctly “concerns about inconsistent schedule.”\nThough participants were generally positive about AI recommendations, they did point out that some of the AI recommendations were too generic and unhelpful, especially when users did not provide sufficient context information in existing components. For example, when P17 inputted (“improve bus schedule”) as a generic distal outcome in the Wizard, the plugin was not able to create specific and contextualized examples of barriers. Instead, the generated suggestions were “oversimplistic and did not seem to fit the problem context.” (P17) P14 had a similar issue, where the AI provided out-of-context suggestions when it was given non-descriptive component content to work with. Additionally, P6 said that in his previous encounters with AI recommendations, it is common for the AI to get repetitive, and it had the tendency to constantly resort to  “recommending designing an immersive VR experience” for any given design problem when he did not define it with excruciating detail.\nAnother challenge with using the AI recommendations is the lack of information about where the recommendations came from. Participants discussed the importance of determining whether the suggestions actually address the specific problem space. Making that determination requires that the designers “understand what is the background of this specific concept recommended.” (P12) For example, in our study, participants were careful about using AI-generated content and only chose to proceed if they had previously studied the concept or knew of its background research. But very often, designers do not know everything about the AI recommendations (e.g., “what is the meaning of the suggestions” (P2), “why is it being recommended” (P19), etc.). Participants expressed concerns about what designers may do in these situations. P3 highlighted that “not knowing the research behind these recommendations would sow doubt in my mind about my design, which is not a good sign.” P2 also emphasized that there could be significant consequences in product deployment if irresponsible designers just choose to “click through AI suggestions in Wizard without judging whether it actually fits the problem.” Participants noted that this could be addressed in the future by providing more context information for each recommendation. For instance, seeing “external links and research papers to explain the reasoning behind” (P18) would help them more easily understand and contextualize the AI recommendations. Plus, as the participants pointed out, seeing “the background research through external sources” (P20) would also validate that the AI is not hallucinating, addressing another common concern that participants shared when they were unfamiliar with the AI-generated content."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1. RQ1: Use of CPD in Human-Centered Design",
            "text": "Recall that creating CPDs involves mapping out factors of relevance and their relationships (e.g.“what is the distal outcome”, and “what is the barrier that may occur given this outcome”). Participants pointed out that when they performed this mapping, they had to think about the relevant constraints upfront. Thinking through all the possible barriers that may prevent strategies from achieving the outcome is a “realistic and down-to-the-ground strategy” (P7), and helps save time in the design process. For instance, P12 articulated that “instead of thinking about the happy and perfect best case user flow, it is more important to know the constraints.” P5 also pointed out that “laying out the barriers, setting up the constraints very very quickly” immediately highlights the pain point, so that “addressing these barriers would make the design goals quite tangible when thinking implementation strategies.” The close attention to the constraints behind a design prompt helps designers quickly break down the task at hand, and helps them focus their effort.\nAdditionally, participants appreciated the goal-oriented process, rather than free-form or solution-oriented as most existing design processes are (e.g., user journey map, whiteboarding, storyboarding, etc.). In many design sessions, practitioners may use whiteboarding to “simply throw out ideas, then sort out the details, whether an idea is a barrier or a mechanism at a later time.” (P7) Or they may use storyboarding, which starts at the beginning, and work from the solution to “play out how the solution impacts the outcome.” (P18)\nIn contrast, CPD starts from “the high-level vision of why focus on this particular problem, the distal outcome,” (P6) and “not just jumping into solutions.” (P2) The generation of a CPD emphasizes the answer to the question of “what is the long-term goal” and not to “what are some ways to solve this prompt” (P17). Starting the brainstorming process from these questions, the outcome of the design, is actually “a natural way of thinking, especially when tackling complex problems.” (P11) P16 pointed out that one needs to know “the root cause of the problem” as well as “the impact involved in resolving the issue” before “identifying the most effective way to address it.” (P16) Thus, CPD is effective in facilitating goal-oriented design because it offers “a direct connection between everything on the users’ side to the larger context side, from a visual standpoint.” (P6) Furthermore, CPD’s emphasis on the outcome helps designers pay attention to“the realistic and practical goal of the design,” (P15) and “addressing the most fundamental issue in the design context,” (P7) instead of thinking about “designing prettier solutions.” (P20)"
        },
        {
            "section_id": "5.1.1",
            "parent_section_id": "5.1",
            "section_name": "5.1.1. Established an effective and guided design process",
            "text": "Overall, participants found that utilizing CPD helped them design more effectively for the design sprint challenges. The use of CPD helped direct participants to think more about the constraints involved in the design, as well as the outcome of the design process.\nRecall that creating CPDs involves mapping out factors of relevance and their relationships (e.g.“what is the distal outcome”, and “what is the barrier that may occur given this outcome”). Participants pointed out that when they performed this mapping, they had to think about the relevant constraints upfront. Thinking through all the possible barriers that may prevent strategies from achieving the outcome is a “realistic and down-to-the-ground strategy” (P7), and helps save time in the design process. For instance, P12 articulated that “instead of thinking about the happy and perfect best case user flow, it is more important to know the constraints.” P5 also pointed out that “laying out the barriers, setting up the constraints very very quickly” immediately highlights the pain point, so that “addressing these barriers would make the design goals quite tangible when thinking implementation strategies.” The close attention to the constraints behind a design prompt helps designers quickly break down the task at hand, and helps them focus their effort.\nAdditionally, participants appreciated the goal-oriented process, rather than free-form or solution-oriented as most existing design processes are (e.g., user journey map, whiteboarding, storyboarding, etc.). In many design sessions, practitioners may use whiteboarding to “simply throw out ideas, then sort out the details, whether an idea is a barrier or a mechanism at a later time.” (P7) Or they may use storyboarding, which starts at the beginning, and work from the solution to “play out how the solution impacts the outcome.” (P18)\nIn contrast, CPD starts from “the high-level vision of why focus on this particular problem, the distal outcome,” (P6) and “not just jumping into solutions.” (P2) The generation of a CPD emphasizes the answer to the question of “what is the long-term goal” and not to “what are some ways to solve this prompt” (P17). Starting the brainstorming process from these questions, the outcome of the design, is actually “a natural way of thinking, especially when tackling complex problems.” (P11) P16 pointed out that one needs to know “the root cause of the problem” as well as “the impact involved in resolving the issue” before “identifying the most effective way to address it.” (P16) Thus, CPD is effective in facilitating goal-oriented design because it offers “a direct connection between everything on the users’ side to the larger context side, from a visual standpoint.” (P6) Furthermore, CPD’s emphasis on the outcome helps designers pay attention to“the realistic and practical goal of the design,” (P15) and “addressing the most fundamental issue in the design context,” (P7) instead of thinking about “designing prettier solutions.” (P20)"
        },
        {
            "section_id": "5.1.2",
            "parent_section_id": "5.1",
            "section_name": "5.1.2. Ideation",
            "text": "When participants were introduced to the concept of CPD, they were intrigued by its potential as a tool for ideation. This is because CPD diagrams can expand into branches, and thus help “lay out all of the possible solutions” (P5) and “generate a breadth of ideas” (P14). Multiple barriers could emerge, each having numerous potential mechanisms and strategies. During the brainstorming sessions, the CPD “turned into a huge diagram with a bunch of possibilities, moving in so many diverse directions.” (P7) Additionally, even after designers have identified a set of barriers and have started working on the design solutions, it is easy to “backtrack and simply extend another branch” (P18) if another barrier pops into their mind.\nAs designers expand the CPDs in multiple branches, a key step is to think about the causal connections between components. These causal connections kept designers’ attention span contained throughout the ideation process. As P19 said, “creative people are either hyper-focused or are not motivated. But CPD guides you through the brainstorming by asking you to connect from one component to another.” (P19) Similarly, P6 pointed out that “the set of questions highlights the connection between the component I’m working on and the other ones I’ve created, which kept me on track, dragging me back to the problem space.”\nHowever, some participants found that focusing on how the components should be connected to one another at a high level distracted them from brainstorming the individual elements. Specifically, they found that their attention was split between “ideating additional possibilities of an individual element” and “following the step-by-step process to brainstorm the next component.” (P19) P15 found herself “moving between the list of questions of the CPD process, jotting down the barrier, but then moving to list out strategies and connecting them to mechanisms.” Essentially, participants knew that they needed to implement both individual elements and the causal connections eventually. So they tried to multitask but found “the thoughts scattered across.” (P2) However, participants also pointed out this issue could be addressed by handling elements and the connections separately. P9 said that she would “focus on individual elements first,” then “come back to the connections in a second design session.” This process would ensure that one can focus their thoughts on either just component content or just high-level causal relationships."
        },
        {
            "section_id": "5.1.3",
            "parent_section_id": "5.1",
            "section_name": "5.1.3. Strategic prioritization",
            "text": "CPDs emphasize the connections between the components, which helps designers play out how a design solution addresses the design prompt, and assist in strategic evaluation. The directional relationships represented by causal connections in CPDs “served as a guardrail to keep track of why a component is created, how each component is addressing this design scenario.” (P14) The “simple but powerful” (P14) causal connections between components make it “easy to trace back through each pathway and figure out how a solution or a strategy plays out to its mechanisms, resolves the barriers, and achieves its final outcome.” (P20)\nIn addition, since CPD is able to demonstrate how each solution addresses the design problem, participants also used it to compare and prioritize different solutions. Designers shared that CPD is able to present various solutions on multiple branches without becoming too complex. Even as a CPD expands into a large tree with multiple pathways, its main structure retains a “simple and straightforward” nature due to the interconnection of components through causal relationships (P11). In addition, the different branches helped designers see “how the different design solutions are influenced by various barriers,” which is useful for them to then “evaluate the likelihood of each barrier, the significance of that barrier, and determine overall which corresponding solution to actually implement and prototype.” (P20)"
        },
        {
            "section_id": "5.1.4",
            "parent_section_id": "5.1",
            "section_name": "5.1.4. Facilitating communication",
            "text": "The use of CPD can also help facilitate communication with stakeholders. P10 pointed out that CPD helps establish a common language among designers in a team setting: “every designer has their own language, and I’ve noticed how common it is to have miscommunication issues with others about an idea in brainstorming sessions.” P20 also said that having a “clear and straightforward” process that everyone understands could “align the way we [designers] see each others’ ideas, banding to the same wavelength.” Furthermore, “reducing the cost of communication” means that designers could “focus more on the ideas themselves and not how to present them.” (P5)\nAdditionally, participants expressed that CPD can bridge the communication gap between designers and the executive team. As discussed before, the process of CPD underscores the goal of the design, which aligns with how product managers and sales consultants think about “strategizing a product and conducting business-level market research.” (P16) P9 also described that “the distal outcome in CPD” corresponds exactly to product managers’ viewpoint of “why this problem matters” and “what is the long-term business goal of the product.” Such correspondence means that CPD could easily and effectively communicate designers’ ideas to product managers. Furthermore, CPD offers “the visual clarity for people to easily trace through the logic” due to its simplistic structure and causal connections (P11). Such a benefit lowers the barrier of communication between designers and product managers."
        },
        {
            "section_id": "5.1.5",
            "parent_section_id": "5.1",
            "section_name": "5.1.5. Concerns about potential misuse",
            "text": "Because the CPD process was positively perceived to help with ideation and strategic evaluation, participants expressed concerns that it may be used as “a tool to oversimplify complex conversations without any proof.” (P8) As P20 further explains, “I’m concerned people would just use this without research, and that could mean putting in random things and coming up with solutions that don’t work.” Instead, CPD should be used as “a guided process that helps organize the results of user research.” (P17) P7 summarized this sentiment with “A useful tool such as this would only be effective when in the right hands. Simplifying and lowering the barrier to brainstorming is certainly great. But we also need responsible designers who do their due diligence, and do the right user research, before using the CPD to lay out their thoughts.” (P7)"
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2. RQ2: Use of Plugin in Generating CPDs",
            "text": "As discussed in our quantitative findings, the use of the plugin increased the number of pathways designers were able to generate. Participants’ comments corroborated this observation and highlighted that some AI-generated content helped increase their creativity. For example, when given the same design sprints (Figure 5  ###reference_###  ###reference_###), P13 (without tool) only generated one pathway, while P8 (with tool) not only generated a similar path as P13, but also generated a distinct second path.\nSpecifically, P8 commented that the brainstorming feature “prompted me to think about a new direction as I was thinking about what barriers there are in the problem space.” And P8 described that he would not have thought about “the idea of running an ad campaign in a short timeframe if I were just throwing out ideas by myself. But seeing the suggestions by the tool immediately clicked for me. So I also explored this path in the CPD.” Further, of the path that P13 and P8 generated that were similar, P8 also was able to consider a different mechanism. These differences would have allowed P8 a richer design space (that is still evidence-based) to explore. P9 shared a similar perspective: “having the AI on the side was like having lots of teammates with really different viewpoints.” Additionally, AI can be used to expand creativity by using it to weed out the wrong directions: “In any design, your first 50 ideas are going to be trashed, but you have to get them out to get to idea 51, which is how the AI can help.” (P14)\nAI did not always generate new ideas that the participants had not already thought of. When designers’ ideas overlapped with AI recommendations, designers found that how AI phrased these ideas was helpful. Participants noted that AI articulates these ideas in “effective, condensed phrasings,” or the AI “uses expressive terminologies (i.e. route optimization algorithms) to summarize” (P3). Reading the AI suggestions helped designers “build the idea firmly in the mind in a clear and direct way.” (P14) AI’s articulation and clarification of the concepts helped participants focus more of their energy on the “meaning and impact of the ideas” (P14), rather than “drilling on how to best describe them.” (P20). For example, when communicating the same barrier in their CPD (4(a)  ###reference_sf1###  ###reference_sf1### & 4(b)  ###reference_sf2###  ###reference_sf2###), P13 (without tool) had to use a full sentence to describe the barrier: “people are concerned that the metro does not follow the schedule” whereas P8 (using the tool) was able to describe it more succinctly “concerns about inconsistent schedule.”\nThough participants were generally positive about AI recommendations, they did point out that some of the AI recommendations were too generic and unhelpful, especially when users did not provide sufficient context information in existing components. For example, when P17 inputted (“improve bus schedule”) as a generic distal outcome in the Wizard, the plugin was not able to create specific and contextualized examples of barriers. Instead, the generated suggestions were “oversimplistic and did not seem to fit the problem context.” (P17) P14 had a similar issue, where the AI provided out-of-context suggestions when it was given non-descriptive component content to work with. Additionally, P6 said that in his previous encounters with AI recommendations, it is common for the AI to get repetitive, and it had the tendency to constantly resort to  “recommending designing an immersive VR experience” for any given design problem when he did not define it with excruciating detail.\nAnother challenge with using the AI recommendations is the lack of information about where the recommendations came from. Participants discussed the importance of determining whether the suggestions actually address the specific problem space. Making that determination requires that the designers “understand what is the background of this specific concept recommended.” (P12) For example, in our study, participants were careful about using AI-generated content and only chose to proceed if they had previously studied the concept or knew of its background research. But very often, designers do not know everything about the AI recommendations (e.g., “what is the meaning of the suggestions” (P2), “why is it being recommended” (P19), etc.). Participants expressed concerns about what designers may do in these situations. P3 highlighted that “not knowing the research behind these recommendations would sow doubt in my mind about my design, which is not a good sign.” P2 also emphasized that there could be significant consequences in product deployment if irresponsible designers just choose to “click through AI suggestions in Wizard without judging whether it actually fits the problem.” Participants noted that this could be addressed in the future by providing more context information for each recommendation. For instance, seeing “external links and research papers to explain the reasoning behind” (P18) would help them more easily understand and contextualize the AI recommendations. Plus, as the participants pointed out, seeing “the background research through external sources” (P20) would also validate that the AI is not hallucinating, addressing another common concern that participants shared when they were unfamiliar with the AI-generated content."
        },
        {
            "section_id": "5.2.1",
            "parent_section_id": "5.2",
            "section_name": "5.2.1. Quantitative results",
            "text": "###figure_4### Our analysis of the participants’ self-reported ratings showed that they had a positive attitude toward the plugin. As shown in Figure 4  ###reference_###, their self-reported rating of the ease of creating each component (, ) and ease of using the CPD process to design (, ) increased when they had access to the plugin. Additionally, the plugin increased participants’ rating of the easiness of brainstorming the content of each component (, ).\nIn addition to the self-reported perception towards the use of our plugin, participants’ self-rated confidence level of the generated CPD’s correctness (, ) and usefulness (, ) increased when they had access to the plugin (Figure 4  ###reference_###).\nWhen analyzing the CPDs generated, we also found that when using the tool, participants created more pathways in their diagrams ( vs. ; ), using about the same or less time ( vs. ; ). For examples of CPDs generated without and with the tool, see 4(b)  ###reference_sf2### and 4(a)  ###reference_sf1###.\nOverall, our quantitative analyses demonstrated the plugin helped designers more easily navigate the use of CPD, helped them brainstorm more possibilities, and increased their confidence in the work produced.\n###figure_5### ###figure_6###"
        },
        {
            "section_id": "5.2.2",
            "parent_section_id": "5.2",
            "section_name": "5.2.2. Alleviated cognitive workload",
            "text": "Generating CPD involves remembering the framework itself, which could distract designers from attacking the problem. The plugin provided the framework details in an easily consumable way and guided users through the process of creating a CPD in an orderly fashion, allowing participants to focus on the design task. By reducing the cognitive workload involved, the plugin not only expedited participants’ design process but also increased their confidence in the work they produced.\nWhen participants did the design sprints without any additional help, they expressed that it was particularly difficult to remember the association between each component and its corresponding shapes, such as “remembering if the shape for the barrier is a diamond or an octagon.” (P7) They also struggled with the naming of the components, pointing out that “looking at the term ‘mechanism’ does not inform much about its meaning and functionality.” (P17) Thinking about the CPD framework distracted designers from the ideation process, as they felt like their brain was “split in half with one focusing on building shapes, the other on the design.” (P16) This burden of multitasking was alleviated by using the Components feature of the plugin. With an easy drag-and-drop feature where users can generate each component without thinking about its corresponding shape, the tool greatly “expedites the time” (P6) because participants were “less caught up by the framework itself to actually think about the problem.” (P5)\nParticipants also struggled with how CPD components should be interconnected, including “what follows after a mechanism,” or “whether it is a barrier or strategy that should come up next.” (P3) They constantly referred to the generation process before diving into the design details. But the step-by-step process of the Wizard feature helped participants “focus attention on the answer for each component and not worry about the order of them.” (P3) P19 also testified that “bypassing thinking about the ordering made me more empowered to keep searching for a clearer picture of what the design should be.” Since participants were able to “think through each component without the disturbance of the shapes or how they should be ordered,” using the plugin, they felt “more sure and more confident” (P13) of their design. Similarly, P9 said that “using the Wizard feature, I knew that I followed the right procedure,” and “I had more confidence in my design because I spent all my energy on it.”"
        },
        {
            "section_id": "5.2.3",
            "parent_section_id": "5.2",
            "section_name": "5.2.3. Increased creativity with the support of AI-generated recommendations",
            "text": "Utilizing LLM, our plugin offered suggestions of component content when prompted in the Wizard and the Brainstorming features. Details of the prompts used were discussed in section 3  ###reference_###. Generally, participants expressed positive attitudes toward using AI-generated content in designing CPD helped them clarify their ideas and sparked innovative thinking during brainstorming. However, they also expressed concerns about blindly using the suggested content.\nAs discussed in our quantitative findings, the use of the plugin increased the number of pathways designers were able to generate. Participants’ comments corroborated this observation and highlighted that some AI-generated content helped increase their creativity. For example, when given the same design sprints (Figure 5  ###reference_###  ###reference_###  ###reference_###), P13 (without tool) only generated one pathway, while P8 (with tool) not only generated a similar path as P13, but also generated a distinct second path.\nSpecifically, P8 commented that the brainstorming feature “prompted me to think about a new direction as I was thinking about what barriers there are in the problem space.” And P8 described that he would not have thought about “the idea of running an ad campaign in a short timeframe if I were just throwing out ideas by myself. But seeing the suggestions by the tool immediately clicked for me. So I also explored this path in the CPD.” Further, of the path that P13 and P8 generated that were similar, P8 also was able to consider a different mechanism. These differences would have allowed P8 a richer design space (that is still evidence-based) to explore. P9 shared a similar perspective: “having the AI on the side was like having lots of teammates with really different viewpoints.” Additionally, AI can be used to expand creativity by using it to weed out the wrong directions: “In any design, your first 50 ideas are going to be trashed, but you have to get them out to get to idea 51, which is how the AI can help.” (P14)\nAI did not always generate new ideas that the participants had not already thought of. When designers’ ideas overlapped with AI recommendations, designers found that how AI phrased these ideas was helpful. Participants noted that AI articulates these ideas in “effective, condensed phrasings,” or the AI “uses expressive terminologies (i.e. route optimization algorithms) to summarize” (P3). Reading the AI suggestions helped designers “build the idea firmly in the mind in a clear and direct way.” (P14) AI’s articulation and clarification of the concepts helped participants focus more of their energy on the “meaning and impact of the ideas” (P14), rather than “drilling on how to best describe them.” (P20). For example, when communicating the same barrier in their CPD (4(a)  ###reference_sf1###  ###reference_sf1###  ###reference_sf1### & 4(b)  ###reference_sf2###  ###reference_sf2###  ###reference_sf2###), P13 (without tool) had to use a full sentence to describe the barrier: “people are concerned that the metro does not follow the schedule” whereas P8 (using the tool) was able to describe it more succinctly “concerns about inconsistent schedule.”\nThough participants were generally positive about AI recommendations, they did point out that some of the AI recommendations were too generic and unhelpful, especially when users did not provide sufficient context information in existing components. For example, when P17 inputted (“improve bus schedule”) as a generic distal outcome in the Wizard, the plugin was not able to create specific and contextualized examples of barriers. Instead, the generated suggestions were “oversimplistic and did not seem to fit the problem context.” (P17) P14 had a similar issue, where the AI provided out-of-context suggestions when it was given non-descriptive component content to work with. Additionally, P6 said that in his previous encounters with AI recommendations, it is common for the AI to get repetitive, and it had the tendency to constantly resort to  “recommending designing an immersive VR experience” for any given design problem when he did not define it with excruciating detail.\nAnother challenge with using the AI recommendations is the lack of information about where the recommendations came from. Participants discussed the importance of determining whether the suggestions actually address the specific problem space. Making that determination requires that the designers “understand what is the background of this specific concept recommended.” (P12) For example, in our study, participants were careful about using AI-generated content and only chose to proceed if they had previously studied the concept or knew of its background research. But very often, designers do not know everything about the AI recommendations (e.g., “what is the meaning of the suggestions” (P2), “why is it being recommended” (P19), etc.). Participants expressed concerns about what designers may do in these situations. P3 highlighted that “not knowing the research behind these recommendations would sow doubt in my mind about my design, which is not a good sign.” P2 also emphasized that there could be significant consequences in product deployment if irresponsible designers just choose to “click through AI suggestions in Wizard without judging whether it actually fits the problem.” Participants noted that this could be addressed in the future by providing more context information for each recommendation. For instance, seeing “external links and research papers to explain the reasoning behind” (P18) would help them more easily understand and contextualize the AI recommendations. Plus, as the participants pointed out, seeing “the background research through external sources” (P20) would also validate that the AI is not hallucinating, addressing another common concern that participants shared when they were unfamiliar with the AI-generated content."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6. Discussion",
            "text": "In this work, we explored how CPD—originating in implementation science—may be used to support theory-driven design in the domain of HCD. We then conducted a user study with practitioners, where we found that CPD may be helpful in supporting divergent and convergent work within the early stages of design. Modern design practice is not purely idiosyncratic as Schön described, and CPD shows promise in making both divergent and convergent processes more predictable. Below we discuss our interpretations of the study findings in more detail.\n\nFirst, our work demonstrated that the use of CPD facilitated both divergent and convergent thinking through an evidence-based lens. During the divergent processes of addressing the design sprint (e.g., ideation), CPD allowed practitioners to easily diverge and expand their innovative thinking. In an ideation context, this can support the create activity as noted in Shneiderman’s framework. With the use of visual elements, designers found it easy to organize their ideas and branch off to explore new factors and new paths. Additionally, backward mapping enabled designers to start with the desired distal outcome and work backward to explore relevant factors in a step-by-step manner, specifying the causal, moderating, or mediating relationships. CPD helped designers reflect on relevant evidence related to the design problems, reflecting the support of the collecting activity. Instead of impeding creativity, these “guardrails” helped remind designers of the design objective and provided a clear structure for evidence-based thinking through the mapping of outcomes, barriers, mechanisms, and strategies.\n\nCPD can also support convergent processes in HCD. During our sprints, CPD helped designers with strategic prioritization, converging their ideas to select a solution for the next stage of HCD. After initial brainstorming, the generated CPD may have multiple branches, each suggesting potential solutions. To determine which ones to prototype, designers were able to examine across branches and contrast the effectiveness of each solution. Using the identified goals and constraints, they were able to strategically select the ones they believed to have more influence on the problem context and prioritize the implementation of that solution. In practice, we would expect designers to make these judgements by referring back to relevant user research and optimizing on the paths given their contexts.\n\nOur study also uncovered CPD’s potential as a communication tool. Within an ideation context, this is relevant for both the relating and donating activities, but this type of communication support is also critical throughout HCD. Since each designer often has their own language to describe a design idea and articulate how to approach that idea, it becomes difficult for them to brainstorm together in a team setting. Design professionals’ drawing practices serve to communicate their ideas instead of illustrating designs accurately. In our study, we observed how CPD supported such a process of visual representation of complex ideas. CPD could help provide an established and easy-to-understand framework. For instance, CPD can guide a team of designers together through the process, starting from the outcome of the design, to barriers, and then to strategy. Throughout the process, CPD’s procedure ensures that team members are brainstorming the same component. This suggests a promising future research direction–exploring the use of CPD during team ideation and iteration. Additionally, designers highlighted the potential of CPD as a tool to present their ideas to business stakeholders and product managers. They found that the questions a CPD is asking coincide with the questions the executive teams ask them. Future work could further investigate how product managers respond to CPD and how effective CPD may be in facilitating meetings between designers and product managers.\n\nFurther, based on our observations, it seems that CPD may also help support designers (and user researchers) to build and communicate their own theories more effectively. In this sense, CPD can support—as been noted in prior work—the theorizing, which is often done by practitioners in practice. Practice is a type of theorizing, and different concepts and relationships are uncovered and tested in practice and can be useful if bubble up to research. This makes CPD more than just a tool to help solve a design problem, but also supports the testing of novel theories from the bottom-up and is in itself a knowledge contribution.\n\nIn addition to studying CPD’s potential use in HCD, our research also explores the use of a dedicated tool to support CPD usage. We found that our plugin helped designers learn and apply CPD. In particular, the Components feature helped them easily generate components without thinking about which shape to use. The step-by-step CPD building Wizard feature also guided them through the process without being concerned about how the components should be linked. Participants reported higher perceived ease of use of CPD with our tool. By reducing their cognitive workload, the tool helped designers spend more of their energy on the design itself, and participants reported feeling more confident in the accuracy and usefulness of their CPDs created. One thing to note, however, is that while backward mapping through CPD provides"
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1. Supporting Ideation with AI-Assisted Tools",
            "text": "Overall, our study provided insights into AI-assisted ideation tools and their impact on design processes. Participants in our study reported that AI assistance offered suggestions from different viewpoints, similar to working with colleagues. These recommendations were seen as constructive and diverse, expanding their perspectives on the problem. Participants noted that AI helped rephrase and reframe ideas more directly and effectively, using succinct terminologies that clarified their thoughts on a conceptual level, reducing their mental workload.\n\nAnother observed benefit of using AI in ideation is its potential to mitigate design fixation, where designers converge on one idea rather than exploring multiple solutions. Our findings suggest that AI-assisted tools can increase the number of ideas generated, enhancing creativity and minimizing fixation. Participants appreciated the AI-generated recommendations, expressing a positive outlook on integrating such tools in future work. However, they also noted that some suggested factors were too generic and not always context-specific enough. This was often linked to the initial information provided, which could have been high-level. Improving the tool to offer more tailored recommendations could involve guiding users to generate more specific and informative outputs, possibly through tutorials on effective prompting or examples of desired specificity levels.\n\nDespite its usefulness, participants raised concerns about the AI’s tendency to propose inaccurate content, leading to hesitation in using some recommendations. This highlights the importance of offering AI-generated suggestions with data-backed support to enhance credibility. Ensuring users trust AI suggestions is crucial, especially when the information proposed is expected to be accurate and relevant. One way to address this might be providing information provenance, detailing where the ideas came from. This could help improve trust and help designers make informed decisions.\n\nWhile our study focused on a digital AI-assisted tool in remote settings, the tool could also support in-person design sessions. Facilitators might project the tool on a screen, prompting discussion and collaboration. Participants could use physical materials, like Post-Its, for brainstorming and idea selection, enhancing understanding through sketches or facilitating a voting process. Future research could explore the best ways to support these in-person activities to ensure effective design outcomes."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7. Limitation & Future Work",
            "text": "The design sprints we used for our work have both strengths and weaknesses. Although the sprints allowed us to study the use of CPD for HCD in a more controlled setting, these design sprints are stylized design tasks that are often used in the early stages of design. They did not allow us to examine the use of CPD to support design in-situ, and across later stages of design. Additional research is needed to further explore how CPD and our plugin can be integrated into the existing design process and be used to support different phases of design."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8. Conclusion",
            "text": "This paper explores the potential synergy between Human-Centered Design (HCD) and AI-assisted design tools. Designers benefited from AI-enhanced tools as a means to emphasize goal-oriented design by addressing root causes, particularly for brainstorming and strategic prioritization. To address the conceptual and practical challenges inherent in adopting these tools, we introduced a user-friendly plugin with generative AI capabilities. This tool helped streamline the design process and encouraged evidence-based thinking and creativity among designers. Our findings shed light on the opportunities and responsibilities associated with integrating AI assistance into creative, evidence-based design practices, offering valuable insights for both the HCD and implementation science communities."
        }
    ]
}