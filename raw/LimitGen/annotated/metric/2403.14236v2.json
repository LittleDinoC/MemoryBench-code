{
    "title": "A Unified Framework for Model Editing",
    "abstract": "We introduce a unifying framework that brings two leading \"locate-and-edit\" model editing techniques – ROME and MEMIT – under a single conceptual umbrella, optimizing for the same goal, which we call the preservation-memorization objective. ROME uses an equality constraint to perform one edit at a time, whereas MEMIT employs a more flexible least-square constraint that allows for batched edits. Following the preservation-memorization objective, we present Equality-constrained Mass Model Editing algorithm for Transformers or EMMET, a new batched memory-editing algorithm that uses a closed-form solution for the equality-constrained version of the preservation-memorization objective. EMMET is a batched version of ROME and is able to perform batched edits up to a batch size of 10,000 with very similar performance to MEMIT across multiple dimensions. With EMMET, we unify and achieve symmetry within the \"locate-and-edit\" algorithms, allowing batched-editing using both objectives.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "As new facts emerge constantly, it’s crucial to keep models up-to-date with the latest knowledge. Model editing Yao et al. (2023  ###reference_b30###) gives us the ability to edit facts stored inside a model as well as update incorrectly stored facts. In this paper, we focus on two popular parameter modifying model editing methods which infuse knowledge within models without needing an additional hypernetwork Chauhan et al. (2023  ###reference_b3###). These methods are ROME (Rank-One Model Editing) (Meng et al., 2022a  ###reference_b17###) and MEMIT (Mass Editing Memory in Transformer) (Meng et al., 2022b  ###reference_b18###). These methods directly update specific \"knowledge-containing\" parts of the model without requiring the need to train additional models and can be applied to any transformer based large language model (LLMs). MEMIT also uniquely allows for batched edits (appendix A.1  ###reference_###).\n\nIn this paper, we present a unifying conceptual framework for ROME and MEMIT and show that both methods optimize the same objective. We call this the preservation-memorization objective of model editing, where new knowledge is injected or memorized such that representations of certain vectors are preserved through the editing process. We show that ROME optimizes an equality-constrained version of the objective whereas MEMIT optimizes a more relaxed least-squares version of the objective, which allows for a simple closed-form solution for making batched edits. We then highlight that MEMIT consists of two separate steps - an optimization objective and an algorithm that distributes the edits into multiple layers. The power of MEMIT in many cases comes from these edit-distribution algorithms.\n\nFinally, we present a closed-form solution for making batched edits with the equality-constraint under the preservation-memorization objective in the form of EMMET - an Equality-constrained Mass Model Editing algorithm for Transformers. With EMMET, batched edits can be performed for batch sizes upto 10,000 with its performance matching MEMIT across multiple dimensions. We evaluate EMMET on three models - GPT2-XL Radford et al. (2019  ###reference_b21###), GPT-J Wang and Komatsuzaki (2021  ###reference_b28###) and Llama-2-7b Touvron et al. (2023  ###reference_b25###) on standard model editing datasets - CounterFact Meng et al. (2022a  ###reference_b17###, b  ###reference_b18###) and zsRE Levy et al. (2017  ###reference_b16###). The code for EMMET can be found here111https://github.com/myanonymousrepo/unified_model_editing  ###reference__model_editing###.\n\nThe main contributions of our paper are:\nWe unify two popular model editing techniques (ROME and MEMIT) under the same conceptual framework called the preservation-memorization.\nWe disentangle the MEMIT objective from the MEMIT algorithm which distributes edits within multiple layers. We hope this sparks further research in edit-distribution algorithms.\nWe present a closed-form solution to equality-constrained memorization in the form of EMMET, a batched version of ROME. EMMET is a new batched-editing algorithm that achieves symmetry between the two objectives of \"locate-and-edit\" class of algorithms and shows that batched edits can be made using both objectives."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Background",
            "text": "Facts for model editing are usually represented in a key-value format where the key vector has maximal correspondence to retrieval of a fact and the value vector enables us to get the target output after editing (Meng et al., 2022a; Geva et al., 2020). As an example, let us say we are editing a new fact into the model - \"The president of USA is John Cena\". In this fact, the key is the vector representation of the phrase - \"The president of USA is,\" and the value is the vector representation of the output at the layer being edited such that \"John Cena\" is produced as output at the final layer of the model. This is pictorially represented in step 2 in Figure 1. For a more detailed explanation of the creation of key-value vectors, we refer readers to Meng et al. (2022a).\n\nThe success of model editing is measured using standard model editing metrics (Meng et al., 2022a; Yao et al., 2023) described below:\n\nParaphrase Score (PS) represents the generalization ability of a model under an edit. It is measured as the percentage of edits where the edited fact remains accurate under paraphrases of the query prompt.\n\nNeighborhood Score (NS) represents the locality of model editing. It measures if the editing of a fact affects other facts stored inside a model. NS represents the percentage of facts in the neighborhood of the edited fact that remain unaltered post-edit.\n\nGeneration Entropy (GE) represents the fluency of a model post-edit. It is calculated by measuring the weighted average of bi-gram and tri-gram entropies of text generated by an edited model. This quantity drops if the generated text is repetitive, a common failure case of model editing (Meng et al., 2022a; Gupta and Anumanchipalli, 2024).\n\nScore (S) is a metric defined by Meng et al. (2022a) to represent a combination of edit success, generalization, and locality. It is the harmonic mean of PS and NS."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Preservation-Memorization : A Unifying Framework for ROME and MEMIT",
            "text": "Both ROME and MEMIT base their work on viewing the weights of the feed-forward layer in a transformer as linear associative memories (Kohonen, 1972  ###reference_b15###; Anderson, 1972  ###reference_b1###). Under this paradigm, linear operations in a transformer (feed-forward layers) are viewed as a key-value store for information. In this section, we re-introduce both ROME and MEMIT in a new light - a unifying conceptual framework of the preservation-memorization objective.\nLet  represent the weights of the feed-forward layer we want to edit222These layers are found by causal tracing methods (Meng et al., 2022a  ###reference_b17###, b  ###reference_b18###), and let  be a key-vector representative of a fact that we are either editing or preserving, and is the input vector to . The layers being edited are shown in an expanded diagram of a transformer layer Vaswani et al. (2017  ###reference_b26###) in Figure 2  ###reference_###. The output of a single transformer layer for a general decoder-only LLM can be written as:\nHere, Att is the multi-head attention function, NL refers to the non-linearity used in the MLP module of the model and LN refers to layer normalization. The keys are outputs of the first linear layer, or , whereas . A detailed explanation on creation of key-vectors and value-vectors is given in Appendix A.3  ###reference_###.\nIn the model editing process, the weights of an intermediate layer of the model are changed from  to , where  is used to indicate a key-vector representing facts we want to preserve from the original model, and  being key-vectors representing facts we want to insert into the model. Let  be the desired output at the layer being edited corresponding to input  such that the correct fact is recalled by the model when finally generating text.\nOur objective is then to preserve the representations of selected input vectors before and after editing, or in other words, minimize the error between  and , while forcing the output representation of the vector  to be , or in other words - memorizing the fact represented by (, ). This process is shown pictorially in Figure 1  ###reference_###.\nIn ROME-style, this objective of model editing is optimized by the following equation:\nwhere  is a matrix containing all the vectors whose representations we want to preserve in a row.\nWe call this the preservation-memorization objective of model editing because it allows us to retain existing knowledge or skills of a model by keeping the same representations of selected key-vectors before and after editing, while memorizing a new fact , whose representation are forced to be , where  is by definition the output representation for  that generates the target answer at final layer.\nThe solution for ROME can then be written as:\nHere,  is assumed to be an invertible matrix and the denominator  is a scalar.\nMEMIT on the other hand optimizes a relaxed version of the same objective:\nwhere  is a matrix containing a row of vectors representing the edits we are making and  represents their target representations.\nThe above optimization objective aims to modify the output representations of vectors in  to  by minimizing the least square error between them instead of requiring them to be equal with an equality constraint. This is the major difference between the objectives of ROME and MEMIT, where ROME poses the memorization part of the objective as an equality constraint whereas MEMIT relaxes the equality constraint to a least-square objective. This allows Meng et al. (2022b  ###reference_b18###) to find a closed-form solution for making  edits to the model in a single update, represented by the matrix . The solution for the MEMIT objective is:\nWe deliberately write the first term in both solutions in a similar form. The first term in  represents the residual error (represented by ) of the new associations () when evaluated on the old weights .  is a vector in case of ROME since we are only able to make singular edits, whereas  is a matrix for MEMIT consisting of a row of vectors corresponding to each edit in the batch.\nTo summarize, in this section we show that ROME and MEMIT can be seen as two realizations of the preservation-memorization (PM) objective of model editing, where ROME enforces memorization using an equality constraint whereas MEMIT enforces memorization as a least square objective. The least-square constraint in MEMIT allows to reach a closed form solution for batch updates.\n###figure_3### ###figure_4### ###figure_5###"
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Edit-Distribution Algorithms",
            "text": "The difference in objectives is not the only difference between ROME and MEMIT. MEMIT (Meng et al., 2022b  ###reference_b18###) also additionally distributes its edits into multiple layers, which has been one of the reasons for success of MEMIT at large batch sizes. This distribution is done by using the formula:\nwhere  represents the change in weights at layer , where  represents one of the  layers being edited.  are the representations of the fact being edited at the final edit layer, which is represented by . All other representations of  and  are calculated at the layer  being edited. For , the formula reduces to equation 8  ###reference_###. We call this algorithm a type of edit-distribution algorithm, which is applied post-hoc after finding the closed-form solutions to the PM-objective.\nThe edit-distribution algorithm is separate from the solutions of the ROME and MEMIT objectives, therefore, we can apply the edit-distribution algorithm when using ROME, as well as use MEMIT without distributing the edits into multiple layers. The formula for using the MEMIT edit-distribution algorithm on ROME is as follows:\nPrior works on model editing do not differentiate between the MEMIT-objective and the edit-distribution algorithm, and as a consequence we never see edits using ROME being distributed to multiple layers or MEMIT being used on only a single layer."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Impact of edit-distribution Algorithms",
            "text": "The key advantage of the edit-distribution algorithm is apparent when making batched edits. In this section, we perform two experiments to analyze this. First, we compare single edits in ROME and MEMIT with and without edit distribution on 1k randomly selected facts from the CounterFact dataset. Following that, we compare batched editing in MEMIT with and without edit distribution. Both experiments are performed on three different models - GPT2-XL (1.5B), GPT-J (6B) and Llama2-7B.\nThe results are shown in Table 1  ###reference_### for edits without distribution and Table 3  ###reference_### for edits with distribution. We use the more stable version of ROME called r-ROME as presented in (Gupta and Anumanchipalli, 2024  ###reference_b12###) that does not lead to model collapse and improves generalization. We see that solutions to both ROME and MEMIT objectives perform equally well at making singular edits across different metrics, without needing to distribute the edits to multiple layers.\nTo highlight the usefulness of edit-distribution algorithms, we compare MEMIT when making batched edits. The results are shown in Figure 3  ###reference_###. When only editing a single layer, we see that MEMIT is able to successfully make batched edits up to a batch size of 1024 for GPT2-XL, 256 for Llama-2-7b and a batch-size as large as 4096 for GPT-J333In our experiments we find GPT-J to be an easier model to edit compared to other models. This is both intriguing but also not the best model to evaluate model editing success.. After this point, the performance of model editing increases when making edits on multiple layers, except for Llama-2-7b. All hyperparameters for all models were chosen as is from prior work (Meng et al., 2022a  ###reference_b17###, b  ###reference_b18###; Yao et al., 2023  ###reference_b30###; Zhang et al., 2024  ###reference_b31###) (appendix A.2  ###reference_###).\nWith these experiments, we want to highlight two key points - firstly, when comparing the effectiveness of two optimization objectives, the evaluation should not be conflated with the edit distribution algorithms. Secondly, the MEMIT edit-distribution algorithm is not perfect and currently is the only way to distribute edits into multiple layers, where the residual in the update is distributed with specific ratios through different layers. We hope these experiments will bring more focus to edit distribution algorithms and boost further research in these methods.\n###figure_6### ###figure_7### ###figure_8### ###figure_9### ###figure_10###"
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Introducing EMMET",
            "text": "In section 3, we show that ROME and MEMIT are both algorithms optimizing the preservation-memorization objective of model editing, where ROME does memorization using an equality constraint whereas MEMIT uses a least-square objective for memorization. Thus, we ask the question - can we perform batched-editing under an equality constraint for memorization? In this section, we provide a closed-form solution for batched-editing where memorization is done with equality constraints under the preservation-memorization objective, and thus present a batched-version of ROME, a method we call EMMET - Equality-constrained Mass Model Editing in a Transformer.\n\nLet represent key-vectors whose representations we want to preserve. Additionally, let represent key-vectors for facts we want to edit in the model at the same time. Then according to the preservation-memorization objective, we want to find new weights for a weight matrix such that: \n\nAs can be seen in the above equation, the preservation of representations happens in the first term whereas memorization of all the new facts is forced using an equality constraint in the second term. The above equation is solved using Lagrange multipliers. The Lagrangian for the above equation for multiple equality constraints requires a summation of Lagrange multipliers and equals:\n\nTo solve the system of equations, we put to get: \n\nwhich is same as:\n\nwhere and . Here, and are matrices created using a row of vectors. We set (assuming that is invertible) to get the update equation of EMMET:\n\nwhere , and .\n\nThe unknown matrix of Lagrange multipliers () can be found using the constraint in the previous equation. It comes out to be:\n\nReplacing the above equation in equation gives us the update equation for EMMET:\n\nWe write the update equation of EMMET in a familiar form, where the residual is modified by some matrix operations to update the models with new edits. Additionally, when we put , the matrix reduces to a single vector and the equation reduces to the ROME update equation. With EMMET, we complete the unification of ROME and MEMIT under the preservation-memorization objective and achieve a symmetry with the usage of these algorithms. EMMET allows for making batched-edits as well as singular when using equality constraints for memorization, much similar to MEMIT with least-square based memorization."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Stabilizing EMMET",
            "text": "There are two important matrices that are being inverted in EMMET and MEMIT. The first one is , which is defined identically in both algorithms, whereas  is only inverted in EMMET. While the invertibility of both matrices are assumed, they are not always guaranteed. Each of the matrices  or  can be written as a row of column vectors as explained in section 3 ###reference_###, and thus  can be written as a sum of outer products:\nwhere  represent a key-vector we want to preserve. For an LLM of dimension , the dimensionality of a key-vector is usually  (Figure 2 ###reference_###), which is the dimensionality of the square matrix . If  is a -dimensional square matrix which is a summation of rank-1 matrices, it is invertible as long as there are at least -independent vectors in the summation, or -independent vectors in . For example, for Llama-2-7b with hidden dimension of 4096, the dimensionality of key vectors is 16384. So as long as representations of at least 16384 independent key-vectors are being preserved while editing,  will be an invertible matrix. In practice, we preserve representations of a much larger number of vectors, and hence this condition is almost always satisfied.\n\nThe matrix  is a square matrix of dimensionality equal to the number of edits. If given that  is invertible,  is invertible as long as  is full-rank, which means all key-vectors corresponding to facts being memorized are independent of each other. While this is not guaranteed, it can be verified before editing and facts corresponding to non-independent keys can be removed from a batch. In practice, we do not find invertibility of D being an issue. However, we find that  is often ill-conditioned, which means that the ratio of the largest and smallest eigenvalues of  explodes. This doesn’t necessarily mean that the matrix is singular (non-invertible), but it does mean that numerical computations involving the matrix inverse are unstable and can lead to large numerical errors. To counter this, we set , where  is set to 0.1 after an ablation over multiple batch sizes. This allows for stable batched edits using EMMET."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Batch Editing with EMMET",
            "text": "We begin by experimenting with EMMET for model editing with varied batch sizes on GPT2-XL, GPT-J, and Llama-2-7b on the CounterFact and zsRE datasets. The exact implementation details can be found in section A.2. We compare the performance of EMMET and MEMIT on batch sizes up to 10,000 while editing both single (to directly compare the optimization objectives) and multiple layers. The single layer editing comparison between EMMET and MEMIT can be found in Figure 4. We see that both methods have almost identical performance in practice across different metrics. MEMIT performs slightly better than EMMET for Llama-2-7b, as indicated by PS and S metrics. We then apply the MEMIT edit-distribution on EMMET and compare it with MEMIT. The results are shown in Figure 5. We see that in this case, EMMET performs slightly better than MEMIT for Llama-2-7b. The results on the zsRE dataset tell a similar story and can be seen in Figure 7 and 8. These results present EMMET as a viable new batched-editing algorithm.\n\nPrevious work has shown that model editing is often accompanied by model degradation. Gupta et al. show this by evaluating the edited model on downstream tasks from the popular GLUE benchmark. We adopt their evaluation setting and evaluate both EMMET and MEMIT on four downstream tasks - sentiment analysis (SST2), paraphrase detection (MRPC), natural language inference (NLI), and linguistic acceptability classification for doing downstream evaluation. The results are shown in Figure 6 for a batch size of 256. The results for other batch sizes can be found in Appendix A.2. We find that both EMMET and MEMIT also degrade the model similarly.\n\nAlthough EMMET is unable to outperform MEMIT, it is an important piece in unifying model editing under the preservation-memorization framework. Both algorithms are able to make successful batched edits up to a batch size of 10,000 and lead to similar model degradation. EMMET imposes a \"theoretically\" stronger memorization constraint, yet we do not see an improvement in editing efficacy. This indicates that we may be reaching the limit of model editing capabilities under the preservation-memorization objective."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper we unite two popular model editing techniques, ROME and MEMIT, under the preservation-memorization objective, with ROME performing equality-constrained edits and MEMIT operating under a least-square constraint. We disentangle the edit-distribution algorithm proposed in MEMIT from the optimization objective, presenting them as separate entities, emphasizing that a fair comparison of future model editing techniques with MEMIT should be based on the objective of MEMIT rather than conflating it with the edit-distribution algorithm.\n\nFinally, we present EMMET - Equality-constrained Mass Model Editing in a Transformer, a new batched-editing algorithm based on the preservation-memorization objective where batched-memorization happens under an equality constraint. Our experiments show that EMMET performs similarly to MEMIT across multiple dimensions and metrics. EMMET completes batched editing using both types of objectives and truly unifies model editing under the preservation memorization framework. We hope that this unifying framework improves the intuitive understanding of these algorithms and fuels future research based on both intuition and mathematics."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "While our technique may streamline error correction processes, it does not address deeper structural limitations within models, such as edited models inadvertently amplifying existing errors or introducing new inaccuracies. Furthermore, the effectiveness of our method varies depending on the complexity of the model architecture and the nature of the edited knowledge as evidenced by our experiments. Despite having a theoretically ‘stronger’ memorization objective, EMMET is not able to outperform MEMIT, which also indicates that we might have reached a saturation point for model editing using naive implementations of the preservation-memorization objective, underscoring the fact that significant progress is yet to be made in understanding edit distribution and its implications. Thus, while our work contributes to a deeper understanding of model behavior, it is essential to recognize and account for these limitations in the interpretation and application of our findings."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "Ethical Considerations",
            "text": "While our model editing method allows users to effectively correct for errors or update facts in models, caution is warranted. Our technique also introduces concerns for potential misuse such as malicious actors inserting harmful or false knowledge in LLMs that is absent from the original training data. As such, we warn readers that LLMs should not be considered reliable knowledge bases."
        }
    ]
}