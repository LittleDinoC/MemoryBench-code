{
    "title": "Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification",
    "abstract": "Intent classifiers must be able to distinguish when a user’s utterance does not belong to any supported intent to avoid producing incorrect and unrelated system responses. Although out-of-scope (OOS) detection for intent classifiers has been studied, previous work has not yet studied changes in classifier performance against hard-negative out-of-scope utterances (i.e., inputs that share common features with in-scope data, but are actually out-of-scope).\n\nWe present an automated technique to generate hard-negative OOS data using ChatGPT. We use our technique to build five new hard-negative OOS datasets and evaluate each against three benchmark intent classifiers. We show that classifiers struggle to correctly identify hard-negative OOS utterances more than general OOS utterances. Finally, we show that incorporating hard-negative OOS data for training improves model robustness when detecting hard-negative OOS data and general OOS data. Our technique, datasets, and evaluation address an important void in the field, offering a straightforward and inexpensive way to collect hard-negative OOS data and improve intent classifiers’ robustness.\n\nKeywords: intent classification, out-of-scope, hard-negative data, data generation",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Task-oriented dialog systems rely on robust intent classification models to produce appropriate responses based on the user utterances. During deployment, the intent classifiers need to not only accurately classify the user utterances, but also must identify if user utterances do not belong to any supported intents. Brittle intent classifiers that fail to reliably distinguish OOS (out-of-scope) utterances from the INS (in-scope) utterances ultimately lead to poor user experiences, wasted time and resources, and potential safety concerns. Thus, it is imperative to develop techniques to ensure robustness against OOS utterances.\n\nWhen developing intent classifiers, developers typically begin by collecting and labelling a large amount of INS training data often acquired through crowd-sourcing. Collecting OOS datasets to improve the classifier’s OOS detection capability is not a common practice. Currently, there is a dearth of large public OOS datasets, and the difficulty posed to intent classifiers has not been rigorously examined. General OOS datasets typically contain mostly samples that exhibit minimal similarity with the INS samples. While many models can distinguish such OOS samples and the INS samples during testing, using such OOS samples to evaluate models’ OOS detection capabilities can produce misleading results.\n\nDuring deployment, the model may encounter OOS utterances that closely resemble the INS utterances but convey entirely different meanings. Due to the high similarity that those hard-negative out-of-scope utterances share with the INS data, the models are more susceptible to misclassifying them into a supported intent with high confidence. Therefore, collecting hard-negative OOS data is pivotal to ensure that the intent classifiers can reliably distinguish all OOS utterances, regardless of their resemblance to the INS samples.\n\nObtaining OOS data that sufficiently challenges the intent classifiers is difficult. Often, this is done through crowd-sourcing with platforms like Amazon Mechanical Turk. However, this approach is costly and time-consuming, and it requires careful verification to make sure that the samples are indeed out-of-scope and challenging. Furthermore, data collection via crowd-sourcing introduces quality control problems as the collected data are often error prone. In datasets containing a large number of intents, verifying each utterance to be irrelevant from all the intents poses significant difficulty for human crowd-sourcing workers. For example, the Clinc-150 dataset encompasses 150 intents; relying on the crowd-workers to verify all sentences to be OOS may be challenging and could lead to erroneous results.\n\nA cost-effective alternative is to generate hard-negative OOS data using Large Language Models such as ChatGPT. In comparison, the GPT-3.5 turbo API costs $0.0015 per 1K tokens in the prompt and $0.003 per 1K tokens for the output, a substantial potential savings. In this paper, we aim to investigate the following research questions: Can ChatGPT generate OOS utterances that do not fall into any of the system-supported INS intents? Do the generated hard-negative OOS utterances lead to high-confidence predictions from intent classifiers? Can the generated hard-negative OOS utterances be used in training to improve the intent classifiers’ OOS detection ability and decrease the models’ confidence on the supported intents when encountering OOS utterances?\n\nTo answer these questions, we select five large public datasets and introduce a method to generate 3,732 hard-negative OOS utterances — that is, utterances intended to closely resemble the in-scope data for a given intent. Our method works by analyzing important words that are likely to have the biggest influence on the intent classifiers’ predictions for each intent from the INS training data. Then, the method prompts ChatGPT to generate OOS utterances that include specific important words for each intent. Since the generated OOS utterances contain the important words from supported intents, they are more likely to confuse the model and produce high confidence. In doing so, we can increase the rigor and challenge of a given dataset by partially automating the creation of hard negative inputs.\n\nWe evaluate the performance of three benchmark transformer models for intent classification on our generated datasets. The hard-negative OOS utterances produced using our method consistently resulted in high confidence (but incorrect) predictions across all five datasets. Notably, intent classifiers struggled to distinguish the hard-negative OOS utterances from the INS utterances. In particular for Clinc-150 and Banking77, model confidence scores are substantially higher for our generated hard-negative OOS datasets compared to the general OOS dataset.\n\nWe see various improvements in model performance when incorporating hard-negative OOS data in training. Our study shows that more attention must be given to curating hard-negative OOS datasets to enhance model robustness in deployment."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": "In this section, we discuss prior work related to data collection for intent classification tasks and ChatGPT’s data generation capabilities."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Hard-Negative Data",
            "text": "Several studies have highlighted the significance of using hard-negative samples during training to improve model robustness. For instance, Zhan et al. (2021) and Nguyen et al. (2023) used hard-negative examples during training to aid retrieval models to better discriminate between relevant and irrelevant documents. Hard-negatives can also facilitate contrastive learning for image classification (e.g., Kalantidis et al. (2020)) and image retrieval (e.g., Melekhov et al. (2016); Hughes et al. (2018)). However, the use of hard-negatives for intent classification remains understudied. In this paper, we use our generated hard-negative OOS datasets to improve model robustness for intent classification."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Data Collection for Intent Classification",
            "text": "General Data Collection. Prior strategies for data collection for constructing training and evaluation data for intent classifiers include the use of crowd-sourcing to generate queries by either (1) paraphrasing input query prompts or (2) responding to scenarios with queries. This prior work includes Coucke et al. (2018); Larson et al. (2019b); Gupta et al. (2018); Liu et al. (2019a); Kang et al. (2018). Recently, prior work has investigated using large language models (LLMs) to generate this type of training data. This work includes Rosenbaum et al. (2022), who used AlexaTM, and Sahu et al. (2022), who used GPT-3, and Cegin et al. (2023), who used ChatGPT to generate paraphrases.\n\nOut-of-Scope and Challenging Data Collection. Most prior work on data collection for intent classification does not consider the production of OOS queries for evaluating a model’s ability to distinguish between in- and out-of-scope inputs. Exceptions to this include Larson et al. (2019b), whose Clinc-150 dataset includes out-of-scope utterances that were generated via crowd-sourcing. Other work in this space includes Larson and Leach (2022a), whose out-of-scope data is constructed by sampling from other datasets, and Zhang et al. (2022), who constructed “in-domain, out-of-scope” splits of Clinc-150 and Banking77 where training data includes a set of intents from the original dataset, but evaluation data includes a set of intents that are in the same domain. Here, a domain is a semantically meaningful group of intents like “banking”, “travel”, etc. Similarly, Khosla and Gangadharaiah (2022) created challenging datasets for testing model robustness to “covariate shifted” data. In that work, covariate shifted data means data that was generated from a different distribution with respect to some other original data distribution, but where both data distributions generate data for the same intent category. Considering the weather intent from Clinc-150, covariate shifted data includes data that was originally generated for the Snips or HWU64 datasets (i.e., the get_weather intent from Snips, and HWU64’s weather_query intent). Other work that focuses on directly generating new challenge data includes techniques from Larson et al. (2019a), which prompted crowd workers to paraphrase only unique queries from a dataset, and Larson et al. (2020b), who prompted crowd workers to paraphrase seed phrases but constrained the crowd workers from using certain keywords that were found to be indicative of certain intents. The techniques from both of these works can be seen as ways to generate covariate shifted in-scope data."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3.   Adversarial Examples",
            "text": "Our work on generating hard-negative data has similarities to prior work on generating adversarial examples. Motivated by adversarial example generation work in computer vision that applies “imperceptible” perturbations to images to provoke incorrect model classification (e.g., Goodfellow et al. (2015  ###reference_b14###)), prior work in natural language processing on adversarial example generation has revolved around perturbing texts using character-level alterations (e.g., Ebrahimi et al. (2018  ###reference_b9###); Gao et al. (2018  ###reference_b11###)) and word synonym and phrase replacement (e.g., Alzantot et al. (2018  ###reference_b1###); Ren et al. (2019  ###reference_b41###); Garg and Ramakrishnan (2020  ###reference_b12###)). Similar work in dialog data has been done by Peng et al. (2021  ###reference_b40###); Liu et al. (2021  ###reference_b33###); Sengupta et al. (2021  ###reference_b45###), where utterances are modified (e.g., by introducing typos, word synonyms, ASR errors, etc.) in order to test the robustness of models. The method we present in this paper can be seen as a way to generate adversarial examples to test the robustness of intent classification models, but differs in that we do not apply perturbations to existing samples."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "2.4.   Data Collection and Annotation with ChatGPT",
            "text": "In a recent study, Cegin et al. (2023) showed that large language models such as ChatGPT can generate more lexically and syntactically diverse INS data by paraphrasing existing corpora. Cegin et al. (2023) also showed that ChatGPT can follow prompted restrictions and used ChatGPT in lieu of crowd-sourcing to generate “taboo” paraphrases in the manner of Larson et al. (2020b), where certain words are avoided in paraphrases in order to promote diversity. However, Cegin et al. (2023) also observed several issues with open-sourced models such as Falcon-40b: duplicated outputs, erroneous outputs, and lack of instruction following.\n\nAnother study showed ChatGPT’s performance varies for sentiment analysis on tweets depending on the topics. For tasks such as classifying the political affiliation of Twitter users, ChatGPT outperforms human crowd-source workers. ChatGPT’s performance for text-annotation tasks has also been found to exceed that of crowd workers.\n\nSahu et al. (2022) prompted GPT-3 to generate labeled training data, and the generated data significantly improves the intent classifiers when the intents are distinct. Using ChatGPT to rephrase sentences, models trained with AugGPT outperform state-of-the-art text data augmentation methods to generate data for scarce intents in a few-shot learning setting."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Methods",
            "text": "We introduce an automated method for generating hard-negative OOS utterances using ChatGPT’s API. In this study, we generate 3,732 hard-negative OOS queries for five benchmark datasets. Our objective is to generate hard-negative OOS utterances by producing utterances that are likely to contain words that heavily influence the intent classifiers’ predictions. The hard-negative OOS datasets are generated following these steps, which we discuss throughout this section. Example utterances produced with our approach are shown in Figure 2 ###reference_###. \n\nUse feature-mining to select keywords by analyzing the most frequently appearing words for each intent for every selected dataset. Select a combination of keywords from the keywords for an intent. Show ChatGPT the name of the intent and five in-scope utterances from. Prompt ChatGPT to generate questions (i.e., utterances) that must contain ... , and is not related to the intent. Prompt ChatGPT to verify that each of the generated questions is not related to the intent. Prompt ChatGPT to verify that each of the generated questions is not related to any of the intents in the entire dataset.\n\nIn this study, we select to be , to be , and to be . When the prompts include only one keyword, we noticed that the generated data shares less similarity to the INS data compared to when = . When prompts include three or more keywords, ChatGPT frequently struggles to include all the keywords or produce an OOS utterance. Larger and can be selected to generate more hard-negative OOS data."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Feature-Mining Keywords",
            "text": "To ensure that the generated OOS queries resemble INS queries for each intent, we need to identify important keywords that are likely to influence the intent classifiers’ prediction. Among our five selected datasets, we collect the most frequently occurring words in the INS training samples from each intent. We lemmatize all words using NLTK’s WordNetLemmatizer to prevent getting multiple versions of the same word. In addition, we discard the stop words and tokens that contain less than three characters.\n\nWe have also explored alternative methods to identify keywords. For instance, using the Python ELI5 package, we determined the words with the highest weights after training an SVM classification model on each of the datasets. For larger datasets such as Clinc-150 and HWU64, training multi-class SVM on a substantial number of intents is time consuming. We utilized the LinearSVC from Scikit-Learn which is implemented as One-vs-All, resulting in a model requiring classifiers for intents.\n\nAfter removing stopwords and lemmatizing the tokens, we are not able to obtain at least five keywords for many intents. For example, 65 of 150 intents from Clinc-150 produced less than 5 keywords using the ELI5 method. Therefore, we use the original token frequency-based approach for keywords collection."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Data Generation with ChatGPT",
            "text": "Recall that we prompt ChatGPT to produce hard-negative OOS samples. We use the GPT 3.5-turbo model through the chat completion API. (All experiments using ChatGPT were done June-August 2023.) For interaction with the API, we make use of three distinct “roles”: (1) The “system” role, which allows the developers to guide ChatGPT’s behavior throughout the conversation. (2) The “assistance” role, which grants ChatGPT’s API the access to previous conversations, enabling ChatGPT to recall previously generated hard-negative OOS utterances to avoid generating duplicates. ChatGPT can also retain the intent information, removing the need for us to repeatedly inform ChatGPT the intent in every prompt. (3) The “user” role, which lets the developers to prompt questions for ChatGPT’s API to answer. When generating hard-negative OOS utterances, we first set the role to “system” and guide ChatGPT to answer with only the hard-negative sentence. This approach prevents the API from padding the responses with unnecessary tokens like “Sure, I’d be happy to help.” Next, we set the role to “user” and show ChatGPT the name of each intent and five INS samples for that intent. This enables ChatGPT to understand the semantics of the intent, especially when the intent name alone does not provide sufficient context. Then, we use the “assistance” role to record the dialog between the developer and ChatGPT. Subsequently, we prompt ChatGPT to generate an utterance that must be unrelated to the intent (i.e., OOS) and must contain a combination of two keywords collected during feature-mining. Preliminary experiments revealed that ChatGPT will often output utterances with mostly the same tokens if prompted to generate multiple utterances at once. This process allows us to guide ChatGPT to produce an utterance that contains commonly used words associated with a given intent but that is not related to that intent — that is, a hard-negative OOS sample. Next, we discuss how we validate each such generated utterance is in fact OOS."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   OOS Verification with ChatGPT",
            "text": "To ensure that the hard-negative OOS data does not contain any INS samples, we use a two-step verification method using ChatGPT. After ChatGPT generates every hard-negative OOS utterance, we immediately prompt ChatGPT to assess whether each utterance belongs to the intent that the utterance should not relate to. For example, after prompting ChatGPT to generate a question containing “hello” and “french” that is not related to the translate intent, we subsequently prompt ChatGPT to determine whether the generated utterance is related to “translate”. If ChatGPT determines that the utterance is related to “translate”, then it is discarded. In the second step of verification, the remaining utterances are then checked to be OOS with respect to the entire dataset. To implement this step, we provide ChatGPT with the name of all INS intent categories using the “system” role and prompt ChatGPT to verify if each utterance is OOS with the ‘user’ role. We note that ChatGPT occasionally mislabels a small portion of the utterances during this two-step verification process. However, since our goal is to generate hard negative OOS data, discarding such inadvertently mislabeled data is not critical. Finally, we manually check the hard-negative OOS datasets collected after the two-step verification stage to ensure the label accuracy. For utterances that do not clearly fall into the INS or OOS categories, we compare the utterance with the INS samples and discuss amongst the research team to conclude the correct label. We discard the utterances if no consensus is reached regarding label opinions."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Evaluation",
            "text": "We design experiments to assess the level of difficulty that intent classifiers have when discerning between in-scope (INS) and hard-negative out-of-scope (OOS) data. As a baseline, we also measure models’ abilities to discern INS data from “general” (i.e., not hard-negative) OOS data. Additionally, we evaluate the improvements in models’ OOS detection abilities after including hard-negative OOS and general OOS data in training. We hypothesize that the hard negative OOS data we generate with our approach will lead to performance decreases because the model will confuse these samples as being INS. We use INS data from Clinc-150, Banking77, ATIS, Snips, and HWU64. Different from the other four datasets, HWU64 consists of two intents General_Quirky and QA_Factoid that span a wide spectrum of semantics. We excluded these two “catch-all” intents from HWU64 for training and testing to allow for sufficient samples that are considered OOS. We use our method to generate 3,732 hard-negative out-of-scope samples targeting intents from the five datasets listed above. Instead of hard-negative OOS data, the baseline approach uses “general” OOS data. We use the Clinc-150 companion OOS data as this general OOS data, which consists of 1,000 test utterances. We then filtered out any utterances that belonged to any of the in-scope intents from the other four datasets. We split the INS data into training and testing. Each selected model is trained on the training data and evaluated with the INS testing data, the generated hard-negative OOS data, the general OOS data from Clinc-150. To examine whether hard-negative OOS data can be used during training to improve the models’ OOS detection capability, we separated both hard-negative OOS data and general OOS data into 80% training and 20% testing splits and compared the models’ confidence for the OOS datasets when we included hard-negative OOS, general OOS, and both OOS corpora in training."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Data",
            "text": "We use INS data from Clinc-150 Larson et al. (2019b  ###reference_b31###  ###reference_b31###), Banking77 Casanueva et al. (2020  ###reference_b3###  ###reference_b3###), ATIS Hemphill et al. (1990  ###reference_b17###  ###reference_b17###); Hirschman et al. (1992  ###reference_b20###  ###reference_b20###, 1993  ###reference_b19###  ###reference_b19###); Dahl et al. (1994  ###reference_b6###  ###reference_b6###), Snips Coucke et al. (2018  ###reference_b5###  ###reference_b5###), and HWU64 Liu et al. (2019a  ###reference_b35###  ###reference_b35###). Different from the other four datasets, HWU64 consists of two intents General_Quirky and QA_Factoid that span a wide spectrum of semantics. We excluded these two “catch-all” intents from HWU64 for training and testing to allow for sufficient samples that are considered OOS. We use our method to generate 3,732 hard-negative out-of-scope samples targeting intents from the five datasets listed above. Section 5.1  ###reference_###  ###reference_### discusses the generated data in detail. Instead of hard-negative OOS data, the baseline approach uses “general” OOS data. We use the Clinc-150 companion OOS data as this general OOS data, which consists of 1,000 test utterances. We then filtered out any utterances that belonged to any of the in-scope intents from the other four datasets. We split the INS data into training and testing. Each selected model is trained on the training data and evaluated with the INS testing data, the generated hard-negative OOS data, the general OOS data from Clinc-150. To examine whether hard-negative OOS data can be used during training to improve the models’ OOS detection capability, we separated both hard-negative OOS data and general OOS data into 80% training and 20% testing splits and compared the models’ confidence for the OOS datasets when we included hard-negative OOS, general OOS, and both OOS corpora in training."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Intent Classification Models",
            "text": "We use the following intent classifiers in our experiments:  \nBERT, a neural network that uses a transformer model to capture the context of each word and fine-tuned on the training data for NLP tasks Devlin et al. (2019). In this study, we use bert-base-uncased.  \nRoBERTa, a variant of BERT that provides better contextual representation of text Liu et al. (2019b).  \nDistilBERT, a lightweight variant of BERT that uses fewer parameters than BERT and processes texts faster Sanh et al. (2019).  \nWe used the Hugging Face implementations of these models Wolf et al. (2020).\n\nCommon approaches to dealing with OOS inputs involve the use of confidence scores to differentiate between INS and OOS inputs.  \nNormally, a desirable model is one that assigns higher confidence to INS inputs, and lower confidence to OOS inputs.  \nWe use two functions to produce the confidence scores when evaluating our hard-negative OOS datasets:  \n(1) Softmax, where we use the highest softmax confidence score for each prediction Hendrycks and Gimpel (2016).  \n(2) Energy, where we compute the energy score Liu et al. (2020) for each prediction using .444 We considered alternative values for and the results are similar for different .\n\nThese two methods are commonly used in prior work on out-of-distribution detection (e.g., Larson et al. (2022))."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Metrics",
            "text": "We consider several performance metrics to evaluate the quality of our hard-negative OOS datasets, assigning the INS predictions as the positive class and OOS predictions as the negative class:\n\n(1) AUPR, the Area Under the Precision and Recall Curve. A higher AUPR indicates a more robust model.\n\n(2) FPR95, the false positive rate at 95% recall. A lower FPR95 indicates a more robust model.\n\n(3) F1 score with confidence thresholds, the F1 score for a range of confidence thresholds from 0.5 to 0.95 for softmax confidence scores. Predictions with higher confidence score than the confidence threshold are considered as positive predictions. Higher F1 captures the classifier’s ability to distinguish INS and OOS data at different confidence thresholds since most intent classifiers in deployment utilize a confidence threshold to determine whether an utterance is not understood."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Results",
            "text": "This section discusses the results of our data generation and experiments: Section 5.1 ###reference_### discusses the results of generating hard-negative OOS with our method. Section 5.2 ###reference_### discusses results of experiments determining the effectiveness of hard-negative OOS data vis-à-vis general OOS data. Section 5.3 ###reference_### discusses results of experiments on determining the effectiveness of training with hard-negative OOS data."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Generation Results",
            "text": "In this study, we prompted ChatGPT to generate a total of 11,080 hard-negative OOS utterances from five different datasets. Roughly 74% (8,172 samples) of the generated hard-negative passed the first round of OOS verification. Then, 3,779 (34%) remained to be valid after the second round of OOS verification where each utterance is prompted to ChatGPT to determine whether it is related to any known in-scope intent of the dataset. Finally, when we manually examined the hard-negative OOS datasets after the two-step verification method, we found that 47 (1.2% of the hard-negative OOS after the two-step verification) are INS and mislabelled by ChatGPT, resulting in 3,732 valid hard-negative OOS samples. Examples of generated hard-negative data are shown in Table 1 ###reference_###. Precise counts of verified hard-negative OOS data for each dataset is shown in Table 2 ###reference_###."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Classifier Performance",
            "text": "We evaluate our five generated hard-negative OOS datasets with BERT, RoBERTa, and DistilBERT trained on only INS data. \n\nFor Banking77 and Clinc-150, the softmax and energy confidence scores for the INS predictions are substantially closer to the hard-negative OOS predictions than the general OOS predictions for all three models. For instance, when evaluated with BERT, Figure 3 (a) shows that the distribution of the softmax confidence scores for the hard-negative OOS is much closer to the INS data compared to the general OOS data. Figure 3 (b) demonstrates that the distribution of energy confidence scores for the INS data is also more similar to that of the hard-negative OOS data compared to the general OOS data. Figure 3 (c) displays the F1 score for the INS vs hard-negative OOS data is lower than that for the INS vs. general OOS data at all confidence thresholds, indicating the model is worse at distinguishing hard-negative OOS than general OOS from the INS data.\n\nRoBERTa and DistilBERT resulted in distributions of confidence scores comparable to BERT. Figure 4 displays the distribution of softmax confidence score for RoBERTa after training on the in-scope data from Clinc-150. During the evaluation for ATIS, Snips, and HWU64, all three models predict both hard-negative OOS data and general OOS data with a substantial number of high softmax confidence scores.\n\nThe FPR95 for both softmax and energy confidence for hard-negative OOS with INS are higher than those for general OOS with INS across all models and datasets, highlighting that the confidence scores can more effectively differentiate the INS data from the general OOS data than our hard-negative OOS data.\n\nOur results suggest that the hard-negative OOS utterances generated with our approach are, at minimum, as challenging as the general OOS dataset and frequently result in high-confidence, incorrect predictions from intent classifiers. Specifically for Clinc-150 and Banking77, the hard-negative OOS utterances are substantially more difficult to differentiate as be OOS in comparison to the general OOS utterances.\n\nTherefore, our proposed hard-negative OOS datasets and other hard-negative OOS datasets generated following our approach will challenge intent classifiers and scrutinize classifiers’ robustness against such data."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "5.3.   Using Hard-Negative OOS in training",
            "text": "When we train transformer-based intent classifiers only on INS data (Section 5.2 ###reference_###), the models predicted high confidence for hard-negative OOS utterances and varying general OOS confidence across all five benchmark datasets. To determine if using hard-negative OOS in training can improve model robustness, we compare the model confidence after training BERT with (1) INS and general OOS data, (2) INS and hard-negative OOS data, (3) INS, general OOS, and hard-negative OOS data, using an 80/20 train test split for the datasets that are used in training.\n\nSince OOS data are included in training, we consider “oos” to be a new label. We calculate the confidence score for each prediction by taking the highest softmax score for any in-scope intent. This confidence score indicates how confident the classifier models are in predicting that utterance belongs to a known intent and is in-scope.\n\nFor Clinc-150, Banking77, and ATIS, when the intent classifiers are trained on OOS data, the confidence scores for general OOS utterances drop substantially compared to models trained only on in-scope data, but the confidence score for hard-negative OOS utterances remains high. In comparison, when we add hard-negative OOS in the training corpora, the models produce low confidence predictions for both hard-negative OOS and OOS utterances. For Snips and HWU64, incorporating general OOS in training results in high confidence predictions for hard-negative OOS, and using hard-negative OOS in training results in high confidence predictions for the general OOS. In this case, incorporating only hard-negative OOS in training is not enough to ensure model robustness. When using both hard-negative OOS and general OOS in training, the model predicts OOS utterances with low confidence to be INS.\n\nThis result indicates that models trained solely with INS and general OOS data are still prone to predicting hard-negative OOS data with high confidence. When the generated hard-negative OOS datasets are incorporated in the training data, the models are much less likely to produce high confidence scores for hard-negative OOS utterances and display varying improvements for detecting general OOS utterances.\n\nAlthough our experiments demonstrate that training with both hard-negative OOS and general OOS greatly reduces confidence on OOS utterances, we note that there is no way to guarantee that every OOS intent can be covered. That is, in deployment, we cannot guarantee that the distribution of inputs will follow the OOS data generated with our approach. Nonetheless, our approach can be used to help improve model robustness and to improve benchmarking and data quality."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Conclusion",
            "text": "We present a new approach to generating hard-negative OOS data using ChatGPT. After manually reviewing and verifying generated data, we show our approach can generate data that are OOS data with infrequent mislabels. Our evaluation shows that models trained only on INS data are brittle when tested against hard-negative OOS utterances generated with our approach and often result in overconfident but incorrect predictions. Our results indicate that the hard-negative OOS utterances are more challenging to differentiate from the INS utterances when compared to the general OOS utterances. Furthermore, we show that using hard-negative OOS data in training improves model robustness against hard-negative OOS utterances substantially and general OOS utterances to varying degrees. Models trained on general OOS data still struggle with hard-negative OOS utterances to a noticeable extent across all five datasets. Since collecting hard-negative OOS data with ChatGPT is substantially less costly than traditional crowd-sourcing methods, we hope that our technique and analysis will lead to more robust intent classifiers. All code used for generating and verifying hard-negative OOS data with ChatGPT, datasets generated and used, results, and additional figures are available at github.com/frank7li/Generating-Hard-Negative-Out-of-Scope-Data-with-ChatGPT-for-Intent-Classification."
        }
    ]
}