{
    "title": "Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin",
    "abstract": "Nigerian Pidgin is an English-derived contact language and is traditionally an oral language, spoken by approximately 100 million people. No orthographic standard has yet been adopted, and thus the few available Pidgin datasets that exist are characterised by noise in the form of orthographic variations. This contributes to under-performance of models in critical NLP tasks.\n\nThe current work is the first to describe various types of orthographic variations commonly found in Nigerian Pidgin texts, and model this orthographic variation.\n\nWe test the effect of this data augmentation on two critical NLP tasks: machine translation and sentiment analysis.\n\nThe proposed variation generation framework augments the training data with new orthographic variants which are relevant for the test set but did not occur in the training set originally. Our results demonstrate the positive effect of augmenting the training data with a combination of real texts from other corpora as well as synthesized orthographic variation, resulting in performance improvements of 2.1 points in sentiment analysis and 1.4 BLEU points in translation to English.\n\nKeywords: Nigerian Pidgin, orthographic variation, sentiment analysis, machine translation",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Models developed for a variety of NLP tasks can give high-quality performance for resource-rich languages, such as English and French. However, for under-resourced languages such as many African and South-East Asian languages, NLP models show poor performance due to a lack of high-quality, sufficiently sized, publicly available datasets. The Masakhane community aims to address this by strengthening and spurring NLP research in African languages.\n\nIn such cases, models might be particularly sensitive to noise in the data. One source of “noise” is orthographic variation – that is, variations in the spelling of words in the data. Orthographic variation can be detrimental to the performance of NLP models, which are typically trained on curated datasets and tend to break when faced with noisy data.\n\nThe issue of orthographic variation is especially present for languages that do not have a standardized and normalized orthography yet, which is the case for many creoles and pidgins. The current work addresses the orthographic variation in one such language, namely Nigerian Pidgin. This language has 100 million speakers, but is still largely absent from NLP research. Nigerian Pidgin is a predominantly spoken language, without a normalized orthography in place. Consequently, written Nigerian Pidgin texts are characterized by a large proportion of orthographic variations. These diverse orthographic variations contribute to significant under-performance in critical tasks, such as sentiment analysis and machine translation.\n\nWe address this by synthesizing the orthographic variation at the phonological level, and subsequently training language models on data augmented with these variations. Our contributions are as follows: We are the first to provide an analysis of the various types of orthographic variations that occur in a variety of Nigerian Pidgin texts (the Bible, magazine texts and transcriptions of spoken conversations). These orthographic variations are found to be of a phonetic nature. We propose a phonetic-theoretic framework for word editing, which can be used to generate orthographic variations to augment training data for language models. We show performance improvement on two NLP tasks (machine translation and sentiment analysis) when including the augmented training data."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related work",
            "text": "Pidgins and creole languages have various unique features (e.g., grammar, morphology, lexicon) that make them interesting to study for various linguistic topics. Nevertheless, linguistic research and resources on these languages are limited. Nigerian Pidgin is no exception to this, although it has received more attention in recent years.\n\nA few datasets now exist for Nigerian Pidgin, focusing on newspaper text, text from several magazines written by a religious society, and task-specific data for named entity recognition, sentiment analysis, speech recognition, and transcribed spoken data.\n\nAn orthography is a set of rules or conventions that is used to represent language in a standardized system of writing.\n\nWhen a language does not have a commonly used orthography, writers make decisions about orthography based on various criteria. The most dominant criterion is phonology: writers try to match the pronunciation of the word in the writing system, given (language-specific) assumptions about grapheme-to-phoneme mapping. Often, these assumptions come from other languages known to the writer; in the case of Nigerian Pidgin, this might be English or local Nigerian languages.\n\nDeuber and Hinrichs present an analysis of orthographic choices in Nigerian Pidgin computer-mediated communication. They report that for Pidgin lexical items that have English origins and mean the same as the origin, the English spelling is commonly adopted for Pidgin. In such cases, non-English spellings are used mainly for the symbolic purpose of indicating distance from English. For example, English ‘thing’ is often written as Pidgin thing, although a non-English spelling (tin) is also possible. For Pidgin lexical items which have roots in English, but have developed distinct meanings in Pidgin, writers are more likely to adopt non-English spellings. For example, ‘done’ has adopted a new meaning in Pidgin and is thus usually written as don. For Pidgin lexical items of non-English origin (e.g., pikin meaning ‘child’), writers tend to adopt the phonemic orthographies of local African languages.\n\nData augmentation is a method used to increase the amount of training data for NLP systems by adding slightly modified copies of already existing data or newly created synthetic data. In particular, it has been shown to improve performance when a limited amount of labeled samples are available.\n\nDifferent data augmentation methods exist; most relevant to the current work are noising-based methods such as inserting and changing words. These methods not only expand the amount of training data but also improve model robustness.\n\nBergmanis et al. used an augmentation approach to improve machine translation systems’ performance when faced with orthographic variations (such as unintentional misspellings and deliberate spelling alternations) of Latvian, Estonian, and Lithuanian words. Their results show that, when tested on noisy data, systems trained using adversarial examples performed almost as well as when translating clean data, achieving an improvement of 2-3 BLEU points over the baseline. The current study follows a similar approach, but applies it to two NLP tasks for Nigerian Pidgin."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Nigerian Pidgin orthography",
            "text": "Nigerian Pidgin (commonly referred to simply as ‘Pidgin’ and otherwise known as ‘Naija’) is an English-based contact language that developed as a result of European contact with West African languages. Pidgin incorporates syntax and vocabulary primarily from English, Portuguese and Nigeria’s indigenous languages, as well as new vocabulary that is unique to Nigerian Pidgin.\n\nLike many other pidgin and creole languages, Nigerian Pidgin is a predominantly spoken language. Attempts to write the language go back to the late 18th century; nevertheless, it is considered to be fairly young as a written language, since it is still in the process of orthographic standardization and normalization. In 2009, the Naijá Langwej Akedemi (NLA) proposed a harmonized orthography; more recently, Mensah et al. (2021) published a new proposal for a working orthography of Nigerian Pidgin.\n\nNevertheless, these orthographies have not yet been adopted by non-linguist Pidgin speakers. Rather, they have developed their own ways of representing their unstandardized language. A gap has thus developed between experts and users, and this may widen in the coming years, given that orthographic standardization on the basis of linguists’ proposals is not in sight, and that Nigerian Pidgin is not being taught in school. Instead, Nigerian Pidgin speakers are taught in English in school, which likely also influences how these speakers write in Pidgin.\n\nNigerian Pidgin typically uses a Latin-based alphabet similar to English. Crucially, orthographies tend to be phonetically based with varying degrees of anglicized spellings; that is, words are typically spelled and written as pronounced according to the sound patterns of Nigerian Pidgin. However, as we will see in Section 3.1, variations can still occur in phonetic-based orthographies, resulting in both inter-textual (between texts written by different authors) and intra-textual (within texts written by single authors) orthographic variation. Such inconsistencies in the orthography increase data sparseness and noise, which affect language models.\n\nIn the approach outlined in this paper, we generate “adversarial” training data to be able to train the model to deal with orthographic variation. This effort requires a deeper understanding of the types of variations that occur. Section 3.1 presents a qualitative analysis of common orthographic variations in Nigerian Pidgin.\n\nThe remaining subsections then present our approach to create synthetic data with more orthographic variation. Most orthographies stem from changes at the phonetic level. Correctly identifying the character corresponding to the phonetic sound is a crucial step toward accurate word synthesis, as direct substitution based on subwords itself often results in variations that do not exist. To stimulate the process of creating variation, our framework edits the lexicon by considering acoustic features.\n\nWe first access the sound of a word by using the phonemization tool ‘phonemizer‘, which transcribes written words into a series of phonemes that are consistent with English pronunciation rules – we found that this works well also for Pidgin words.\n\nGiven a word, appearing at the i-th of a sentence, we obtain the transcription for the Pidgin word. This is illustrated with the word ’anything’, which is transcribed phonetically. \n\nWe adopt GIZA++ to align the acoustic symbols and the corresponding characters of each word in the given corpus. We trained the aligner for 10 iterations using the IBM4 model. We utilized the character and phoneme as the training examples. Due to errors related to missed one-to-many and many-to-one alignments, we first conducted a preprocessing step to merge certain symbols that belong together as a unit.\n\nThe aligned pairs of word and phoneme sequence serve as input for Step 3. To generate orthographic variation candidates of words found in our Pidgin dataset, we created a set of variation rules. These rules were based on the qualitative analysis of the data.\n\nWhen multiple rules could apply to a single word, we synthesized variations with different combinations of the rules. We note that the rules overgenerate in some cases; that is, they might in some cases strongly change the pronunciation of a word. This variant is however very implausible to occur in Pidgin writing, as the resulting pronunciation in this case would deviate quite a lot from the original pronunciation. This is addressed in Step 4.\n\nAs a result of Steps 1-3, we now have a set of generated variation candidates for each seed word, including some variants that may be implausible as their pronunciation might not fit well with the original words’ pronunciation. To filter out such poor orthographic variation candidates, we automatically transcribe each generated variant to its phonetic transcription using again the ‘phonemizer’ tool. We then analyze the similarity between the seed word’s"
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Types of orthographic variation in Nigerian Pidgin",
            "text": "We analysed texts from three parallel datasets: the Bible, JW300 (Agić and Vulić, 2019) and the Naija Treebank (Caron et al., 2019). Table 1 presents the types of orthographic variation patterns that were found in this dataset. Throughout the development of our framework, the generated variations and examples incorporating Pidgin were evaluated by native Pidgin speakers. Note that this list is not exhaustive but rather represents the most common or remarkable variations encountered in the dataset. See also Appendix A for details on the construction of the variation types.\n\nWe identify four main classes of systematic variations that occur in the data: (i) alternation between similar sounds; (ii) conversion of digraphs into a single letter or alternate digraphs; (iii) phonetic transcription of (blended) letter pairings; and (iv) deletion of silent letters. Table 1 presents examples of each of these classes. The variations often occur at a specific position within a word. For instance, the syllable ble can be transcribed as bol only when it occurs at the end of a word, as in trouble. Oftentimes a word is characterized by more than one orthographic change occurring. For example, because-bikos is characterized by alternation (e/i; c/k), conversion (au/o), and deletion (e/-).\n\nCrucially, it should be noted that the variations all have phonetic origins. For example, the alternation between /c/ (as in “carry”) and /k/ (as in “kid”) can be attributed to both sounding as voiceless velar plosives, and the conversion of the front vowel spelling /ee/ to /i/ can be attributed to these having similar sounds in the Pidgin pronunciation of certain words. The data is characterized by both intra-textual variation (i.e. within texts written by single authors) and inter-textual variation (i.e. between different sources).\n\nThis is illustrated in Table 2: in the Bible, the connective ‘because’ is spelled as either because or bikos (intra-textual variation), whereas in the Naija Treebank, we encounter new variants of the same word (inter-textual variation). It is important to note that these variations are not strict rules; different writers might adhere to different rules and thus one word can be written in different ways. For example, the word “thing” might be written by one writer as tin and by another as ting (thus not applying the ‘ng/n‘ conversion). Due to a lack of standardized orthography, there is often not one right variant of a word; rather, we should think of variation candidates as being more, or less, plausible."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Synthesizing variation via phonological distance",
            "text": "The key to synthesizing variants of the words found in the Pidgin dataset is to consider the phonetics of these words. This is because the orthographic variations of Pidgin words tend to originate from those words being written as they are pronounced according to the sound patterns of Nigerian Pidgin. Based on this insight, we designed an approach that considers the phonemes of the words to generate variants that sound near-identical, but are spelled differently. Generating orthographic variations could be done in various ways. One option is to convert phoneme sequences into spelling variants generatively. However, phoneme-to-grapheme models usually also rely on already having a model of acceptable word spellings, which is not available in our setting. We therefore take a different approach: we observe what variation exists at the level of orthography, then generate rules based on the orthographic forms, and check the generated variants via pronunciation distance (relying on a grapheme-to-phoneme conversion tool for English). These variation rules were based on the qualitative analysis of the dataset described in Section 3.1. In what follows we describe how the framework generates variations. Figure 1 depicts the pipeline for this process. Note that, although this framework was designed for Nigerian Pidgin, it likely can be adapted for other Pidgin-based languages as well, as long as these languages also exploit the phonetic writing system of their lexifier. Most orthographies stem from changes at the phonetic level. Correctly identifying the character corresponding to the phonetic sound is a crucial step toward accurate word synthesis, as direct substitution based on subwords itself often results in variations that do not exist. To stimulate the process of creating variation, our framework edits the lexicon by considering acoustic features. We first access the sound of a word by using the phonemization tool ‘phonemizer‘ Bernard and Titeux (2021), which transcribes written words into a series of phonemes that are consistent with English pronunciation rules – we found that this works well also for Pidgin words. Given a word, appearing at i-th of a sentence, we obtain the transcription for the Pidgin word, denoted as . In Figure 1, this is illustrated with the word ’anything’, which is transcribed as /\\textipaeniTIN’/. We adopt GIZA++ Och and Ney (2003) to align the acoustic symbols and the corresponding characters of each word in the given corpus. We trained the aligner for 10 iterations using the IBM4 model. We utilized the character and phoneme as the training examples. Due to errors related to missed one-to-many and many-to-one alignments, we first conducted a preprocessing step to merge certain symbols that belong together as a unit, such as /\\textipao:/ on the phonetic side, or ‘th’, ‘ng’ on the spelling side, as these would have to be aligned to single symbols such as /\\textipaT/ or /\\textipat/ and /\\textipaN/ or /\\textipan/, respectively, see also Figure 1 for an example. The aligned pairs of word and phoneme sequence serve as input for Step 3. To generate orthographic variation candidates of words found in our Pidgin dataset, we created a set of variation rules. These rules were based on the qualitative analysis of the data, as shown in Table 1. When multiple rules could apply to a single word (e.g., in the case of ‘anything’ four rules could apply; see Table 1), we synthesized variations with different combinations of the rules, see Table 3. We note that the rules overgenerate in some cases; that is, they might in some cases strongly change the pronunciation of a word, e.g., ‘anything’ would result in the alternative spelling ‘onytin’ after the application of several rewriting rules. This variant is however very implausible to occur in Pidgin writing, as the resulting pronunciation in this case would deviate quite a lot from the original pronunciation. This is addressed in Step 4. As a result of Steps 1-3, we now have a set of generated variation candidates for each seed word, including some variants that may be implausible as their pronunciation might not fit well with the original words’ pronunciation. To filter out such poor orthographic variation candidates, we automatically transcribe each generated variant to its phonetic transcription using again the ‘phonemizer’ tool Bernard and Titeux (2021). We then measure the distance between the seed word’s pronunciation and the candidate’s pronunciation."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   Orthographic variation augmentation",
            "text": "We introduce an orthographic variation augmentation approach, which adds sentences with synthesized spellings to the training data. Consider a corpus with a total of samples, denoted as . We generate the corresponding variation-enhanced versions by randomly selecting sentences and generating a spelling variant for all words in that sentence. This results in variation-augmented sentences forming the augmented data. This augmented data complements the training data, creating . Table 4 presents an example of our approach to generating variations in the context of sentences. It is worth noting that a single word can have different generated variants in as these variants are sampled from the distance-normalized probability distribution. Our proposed framework is not restricted to a particular task but is applicable to any NLP task that involves Pidgin data. In the next two sections, we explore the utilization of augmented data in two critical NLP tasks: sentiment analysis and machine translation."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Sentiment analysis experiment",
            "text": "To determine the optimal size of augmented samples  for the sentiment analysis task, we adopt RoBERTa and test various sizes of extra data points within a range from =50 to =8,000.\nFigure 2  ###reference_### presents the results in comparison to the fine-tuned baseline ( size=0).\nFigure 2  ###reference_### shows that appending 100 augmented samples leads to a substantial performance boost of  points over the baseline.\nHowever, as more augmented samples are introduced, we see a gradual decline in performance to .\nWe attribute the observed fluctuations to the explanation that, while additional generated variations enrich the diversity of the training data, a relatively small test set does not present such high variability of the real variation distribution, and thus the additional augmentation introduces disproportionally much noise.\nFigure 3  ###reference_### shows the potential reason for the fluctuation: an increasing number of new variants is introduced as more augmented data is appended to the training dataset.\nNevertheless, even with 8K samples, the improvement in performance compared to the baseline is close to  point in F1 score (as shown in Figure 2  ###reference_###).\nIn sum, we find that controlling the size of the synthesized data influences the level of generalization achieved, but regardless of the size , adding orthographic variants to the dataset improved the baseline model performance on NaijaSenti.\n###figure_2### We further explore training stability by examining the cross-entropy of the model’s prediction , in the context of sentiment analysis.\nTable 7  ###reference_### demonstrates the cross-entropy in the training epochs, as a crucial metric under cross-validation to gauge the effectiveness of our classification model.\nCross-entropy informs us on how well the model’s predictions match the ground-truth class labels.\nMeasuring cross-entropy is done as an alternative to accuracy, which is less applicable to smaller datasets.\nThe results in Table 7  ###reference_### show that models trained using samples with orthographic variations are characterised by lower cross-entropy compared to the counterpart models that are not trained with appended orthographic variation samples.\nThis indicates that our orthographic variation augmentation approach leads to more accurate sentiment analysis results.\n###figure_3###"
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Dataset, network and training details",
            "text": "Table 5  ###reference_### describes the datasets used in our experiments.\nFor the task of sentiment analysis, we use the NaijaSenti dataset (Muhammad et al., 2022  ###reference_b23###), which comprises a three-way data split (6.7K/0.6K/1.2K).\nWe use RoBERTa Liu et al. (2019  ###reference_b19###) and BERT Devlin et al. (2019  ###reference_b11###) in base versions. We employed AdamW optimization Loshchilov and Hutter (2019  ###reference_b20###) with a learning rate of 0.0001, and we found that a smaller learning rate helped prevent overfitting in the downstream task.\nWe compare three models.\nThe first model, PgOnly, is trained on NaijaSenti for 5 epochs with a mini-batch of 32.\nThe second model is a fine-tuned model (FT), which is trained on English and fine-tuned on Nigerian Pidgin. Finally, the third model is an orthographically augmented model (Orth-Augm) which, like FT, is trained on English and fine-tuned on Nigerian Pidgin, but the fine-tuning now also includes orthographic variations, which are appended to the training data.\nOur orthographic variation augmentation approach samples K=100 variants. We re-ran the model 6 times with different random seeds and present averaged results.\nAll models are evaluated using the F1 score."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Main results",
            "text": "Table 6  ###reference_### presents the results on the sentiment analysis task.\nBoth BERT and RoBERTa models, when trained with orthographic variation augmented data, demonstrated improvements in F1 scores, gaining  and  points over the fine-tuned model (FT), respectively.\nWe notice the higher improvement between FT and our approach when using RoBERTa in comparison to BERT.\nEven though RoBERTa leverages more pre-training data over BERT, the model still shows more improvements when trained with the augmented variations.\nThe model variant PgOnly is only trained on NaijaSenti and has not seen any English data. PgOnly shows significant gaps compared to models with fine-tuned and variation-augmented training.\nThis result emphasizes the importance of fine-tuning language models and how such models can be further improved with our generated variations."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Ablation study",
            "text": "This section provides further results on the augmentation effectiveness and shows the advantage of our augmentation approach.\nTo determine the optimal size of augmented samples  for the sentiment analysis task, we adopt RoBERTa and test various sizes of extra data points within a range from =50 to =8,000.\nFigure 2  ###reference_###  ###reference_### presents the results in comparison to the fine-tuned baseline ( size=0).\nFigure 2  ###reference_###  ###reference_### shows that appending 100 augmented samples leads to a substantial performance boost of  points over the baseline.\nHowever, as more augmented samples are introduced, we see a gradual decline in performance to .\nWe attribute the observed fluctuations to the explanation that, while additional generated variations enrich the diversity of the training data, a relatively small test set does not present such high variability of the real variation distribution, and thus the additional augmentation introduces disproportionally much noise.\nFigure 3  ###reference_###  ###reference_### shows the potential reason for the fluctuation: an increasing number of new variants is introduced as more augmented data is appended to the training dataset.\nNevertheless, even with 8K samples, the improvement in performance compared to the baseline is close to  point in F1 score (as shown in Figure 2  ###reference_###  ###reference_###).\nIn sum, we find that controlling the size of the synthesized data influences the level of generalization achieved, but regardless of the size , adding orthographic variants to the dataset improved the baseline model performance on NaijaSenti.\n###figure_4### We further explore training stability by examining the cross-entropy of the model’s prediction , in the context of sentiment analysis.\nTable 7  ###reference_###  ###reference_### demonstrates the cross-entropy in the training epochs, as a crucial metric under cross-validation to gauge the effectiveness of our classification model.\nCross-entropy informs us on how well the model’s predictions match the ground-truth class labels.\nMeasuring cross-entropy is done as an alternative to accuracy, which is less applicable to smaller datasets.\nThe results in Table 7  ###reference_###  ###reference_### show that models trained using samples with orthographic variations are characterised by lower cross-entropy compared to the counterpart models that are not trained with appended orthographic variation samples.\nThis indicates that our orthographic variation augmentation approach leads to more accurate sentiment analysis results.\n###figure_5###"
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Machine translation experiment",
            "text": "Given that orthographic variation is even more likely to occur between texts than within texts, we test the effect of orthographic variation augmentation on a test set from an unseen corpus. Specifically, we investigate the cross domain transfer of a model trained on the JW300 (with and without orthographic variations) and tested on the Naija Treebank test set.\nFigure 4  ###reference_### shows that our augmentation approach improves the performance of the machine translation model, on the unseen Naija Treebank during training, leading to an zero-shot generalization along with more augmented samples.\nIn fact, the results show that the higher the , the higher the model performance over the baseline  where no variation-enhanced sentences are used, further supporting the effectiveness of the variation augmentation.\n###figure_6### ###figure_7### The data augmentation approach introduces new word variants to the training data; naturally, the number of new variants introduced increases when the size of the augmented data increases.\nTo understand how these new variants affect the generalization of the model, we correlate the number of new variants for various  sizes with the performance improvement in the domain shifting setting.\nTable 9  ###reference_### shows that with a higher number of new variants, the results also show a performance improvement on the Naija Treebank’s test set.\nWe attribute this phenomenon to two factors: (1) certain newly created variations are absent in the current test split but are indeed found in real Pidgin corpora, as exemplified by ‘everytin’; (2) in other cases, such as ‘piple’ and ‘pipl’, these variants feature minor lexical alterations compared to the variant ‘pipol’ that is actually found in the dataset.\nEven though certain generated variants, such as ‘piple’ and ‘pipl’, are classified as new variants, parts of these created variants are indeed present in the original text (e.g. ‘pip’ in the three variants ‘piple’, ‘pipl’, and ‘pipol’) and the model might capture nearly identical semantics due to their lexical overlap.\nThis could lead to the model being able to generalize to previously unseen tokens when conducting inference on the test splits."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Dataset, networks and training details",
            "text": "We leverage T5 Base Raffel et al. (2020  ###reference_b31###) for the JW300 translation benchmark, which consists of 29K training samples. We perform bi-directional translation for the parallel English-Pidgin datasets, which are the Bible, JW300 (Agić and Vulić, 2019  ###reference_b5###) and the Naija Treebank (Caron et al., 2019  ###reference_b9###).\nAll model variants are evaluated on the test set using BLEU scores.\nWe fine-tuned the T5-base model with additional real data samples (DataAug) for 20 epochs with a batch size of 64.\nWe configured the sequence length to be 196 characters and used the AdamW optimizer Loshchilov and Hutter (2019  ###reference_b20###) with a learning rate of 0.0001.\nWe appended the orthographic variation samples as augmentation, using =20,000 samples. Depending on the model type (only JW300 or a combination of JW300 and the Bible or Treebank), the augmentation samples were drawn from either a single source or from multiple sources."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Main results",
            "text": "Table 8  ###reference_### shows that our orthographic variation augmentation approach leads to improvements in BLEU scores in both translation directions.\nThe results show that this also surpasses the standard data augmentation technique in performance.\nFor DataAug (including real samples of additional datasets), the model’s performance benefits from injecting more accurately labeled real training samples, leading to an improvement in BLEU points.\nWe observe further improvement by using our orthographic variant generation approach, suggesting that the augmented samples are an effective augmentation approach to\nenrich the dataset."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "5.3.   Ablation study",
            "text": "Given that orthographic variation is even more likely to occur between texts than within texts, we test the effect of orthographic variation augmentation on a test set from an unseen corpus. Specifically, we investigate the cross domain transfer of a model trained on the JW300 (with and without orthographic variations) and tested on the Naija Treebank test set.\nFigure 4  ###reference_###  ###reference_### shows that our augmentation approach improves the performance of the machine translation model, on the unseen Naija Treebank during training, leading to an zero-shot generalization along with more augmented samples.\nIn fact, the results show that the higher the , the higher the model performance over the baseline  where no variation-enhanced sentences are used, further supporting the effectiveness of the variation augmentation.\n###figure_8### ###figure_9### The data augmentation approach introduces new word variants to the training data; naturally, the number of new variants introduced increases when the size of the augmented data increases.\nTo understand how these new variants affect the generalization of the model, we correlate the number of new variants for various  sizes with the performance improvement in the domain shifting setting.\nTable 9  ###reference_###  ###reference_### shows that with a higher number of new variants, the results also show a performance improvement on the Naija Treebank’s test set.\nWe attribute this phenomenon to two factors: (1) certain newly created variations are absent in the current test split but are indeed found in real Pidgin corpora, as exemplified by ‘everytin’; (2) in other cases, such as ‘piple’ and ‘pipl’, these variants feature minor lexical alterations compared to the variant ‘pipol’ that is actually found in the dataset.\nEven though certain generated variants, such as ‘piple’ and ‘pipl’, are classified as new variants, parts of these created variants are indeed present in the original text (e.g. ‘pip’ in the three variants ‘piple’, ‘pipl’, and ‘pipol’) and the model might capture nearly identical semantics due to their lexical overlap.\nThis could lead to the model being able to generalize to previously unseen tokens when conducting inference on the test splits."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Discussion",
            "text": ""
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1.   Overgeneration",
            "text": "Although Nigerian Pidgin does not have a standard orthography, there is still a degree of plausibility in the generations that can be found in natural language. Automatically generating orthographic variations can thus lead to implausible variations, which, in turn, can lead to a decrease in generalization. A manual analysis of the data indicated that many of the implausible variations generated by our approach were synthesized when multiple rules were applied on the seed word, and when the pronunciation of a word was strongly affected. For instance, ‘anything’ became ‘onytin’ by applying three different rules. Such candidates are less plausible variations than one that has higher phonological similarity (also see Appendix B  ###reference_### on generating irrelevant words). In our framework, we address the issue of overgeneration by sampling the variations through the phonological weighted Levenshtein distance."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "6.2.   Generalization to unseen domains",
            "text": "The dataset used to identify common orthographic variations consisted of texts from the bible, a religious magazine (JW300), and Nigerian Pidgin conversations (Naija Treebank). The variations observed within these sources appeared to be more author-specific than domain-specific – that is, the degree and variety of variations often involve specific authors instead of domains. An example of this can be seen in Table 2  ###reference_###: the Bible and JW300 are from the same domain, but the types of variations and the frequencies are very different.\n\nThe experiments reported in Sections 4 and 5 show that the proposed method can be applied across domains. For sentiment analysis and machine translation tasks, we created separate frameworks on two distinct domains; social media and religion, respectively. Our results showed positive correlations when the increase of the model performance and augmenting the variation-enhance examples (also see Tables 6  ###reference_### and 8  ###reference_###). Our proposed approach thus appears to be domain-agnostic and can be generalized to unseen domains."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "6.3.   Code-switching",
            "text": "Nigerian Pidgin is an English-lexified language that draws from other local languages as well. Code-switching between Pidgin, English, and local languages is motivated by factors such as formality, setting, interpersonal relations and audience (Agbo and Plag, 2020  ###reference_b4###).\nFor example, in a Hausa community, there might be more code-switching with Hausa words, but in a mixed community of Hausa and Yoruba speakers, there might be more code-switching with (Nigerian-)English words.\nTable 4  ###reference_### presents an example of how English and Pidgin words co-occur in one uttereance: ‘E come later dey serve as pioneer’ translates to English as ‘Later, he began serving as a pioneer.’ In this sentence, the speaker mixes Pidgin words (e.g., ‘dey’) with (Nigerian-)English words (e.g., ‘serve as pioneer’). This blend of English and Nigerian Pidgin is a form of code-switching commonly observed within the text (although it could be argued that there might not be a Pidgin equivalent of “pioneer” available in the lexicon).\n\nOur current work proposes a framework to describe various types of orthographic variations commonly found in Nigerian Pidgin texts, and model this orthographic variation. As a result, words like ‘they’ in the dataset might be generated as ‘dey’. Through this process, the original text is enhanced with more orthographic variations, which potentially creates the illusion of a higher rate of code-switching than is originally present in the data. \nHowever, note that this view on code-switching relies solely on orthographic choices made by the transcriber, whereas code-switching also pertains to vocabulary items that are not dependent on orthographic choices (such as the Pidgin word ‘wetin’ meaning what). We refer the reader to Agbo (2022  ###reference_b3###) for more information on code-switching in Nigerian Pidgin."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Conclusion",
            "text": "In this paper, we address the issue of orthographic variation in a mostly spoken language that does not have a standardized orthography in place: Nigerian Pidgin (Naija). We provide an analysis of the types of orthographic variations commonly found in Nigerian Pidgin writing. Based on this analysis, we propose a novel phonological-based word synthesizing framework to augment the corpus with orthographic variations. We examine the concept of synthesized variation on two main tasks: sentiment analysis and machine translation. The results demonstrate the effectiveness of adding synthesized orthographic variation to the dataset instead of collecting new samples."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Acknowledgement",
            "text": "This work was funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – Project-ID 232722074 – SFB 1102 Information Density and Linguistic Encoding."
        },
        {
            "section_id": "9",
            "parent_section_id": null,
            "section_name": "9.   Limitations",
            "text": "We acknowledge the inherent limitations in our work.\nDespite the effectiveness of our orthographic variation generation framework, we still observed the overgeneration of variations that are less likely to occur.\nWe face a challenge in precisely quantifying the correlation between the model’s performance and the extent of overgeneration. The absence of such measurement hinders a comprehensive assessment of the impact of overgeneration on model performance.\nMoreover, our evaluation of NaijaSenti is constrained to an in-domain context due to the lack of an out-of-domain corpus that represents stronger or novel variations, potentially resulting in an underestimation of the model’s capabilities.\nAdditionally, the exploration of alternative data-driven sampling methods is a important option; however, it requires additional non-annotated Pidgin data, which is currently unavailable.\nLastly, our research focuses on Nigerian Pidgin, which is an English-lexified language; this allowed us to exploit the availability of SOTA English-based tools. It is possible that our observations do not generalize well to other languages that are either not English-lexified (due to a less resources being available for other languages), or display more differences compared to their lexifier."
        }
    ]
}