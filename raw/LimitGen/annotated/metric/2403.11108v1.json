{
    "title": "HarmPot: An Annotation Framework for Evaluating Offline Harm Potential of Social Media Text",
    "abstract": "In this paper, we discuss the development of an annotation schema to build datasets for evaluating the socio-political contexts of social media texts. Understanding that real-world violence is often spurred by a web of triggers, often combining several online tactics and pre-existing intersectional fissures in the social milieu, we do not focus on any single divisive aspect (i.e., caste, gender, religion, or other identities of the victim and perpetrators) nor do we focus on just hate speech or mis/dis-information. Rather, our understanding of the intersectional causes of such triggers focuses our attempt at measuring the potential impact of online content, irrespective of whether it is hateful or not. In this paper, we discuss the development of a framework/annotation schema that allows annotating the data with different aspects of the text including its socio-political grounding and intent of the speaker (as expressed through mood and modality) that together contribute to it being a trigger for social tensions or conflict. We also give a comparative analysis and mapping of our framework with some of the existing frameworks.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Background and Rationale",
            "text": "India is a country with a rapidly proliferating social media presence with over 700 million users (including 81% of teens). However, despite massive levels of social media usage, digital media literacy remains low in India. A 2020 survey of a “highly educated online sample” of Indians found that roughly 50% of the fake news presented to them was judged as “accurate” or “very accurate” in their control group (Guess et al., 2020). The wide reach of social media content, the high prevalence of false or misleading information online, and the extreme communalism/groupthink on social media (for example, see Al-Zaman (2019) for a study on communalism in India and Mukherjee (2020) for a discussion on the impact of online groupthink on mob violence in India), coupled with low levels of media discernment skills, have exacerbated long-standing social divisions in India (Froerer, 2019; Banerjee and Ghosh, 2018).\n\nSeveral incidents of lynching have been triggered by misinformation around caste (Staff, 2020; Sajlan, 2021), love-jihad (Muslim men eloping with Hindu women) NewIndianXpress (2018), religious desecration, etc. There are additional contextual triggers that often cause increased levels of online content. This includes elections (Deka, 2019), where fake news, rumours, misleading and divisive content are typically spiked for political gains, and global crises like the COVID-19 pandemic (Al-Zaman, 2021), which create a context in which users want “someone to blame,” often unjustly.\n\nIn the last few years, over 60 datasets of various sizes and kinds, where a wide variety of abusive language has been annotated, have been released publicly (Vidgen and Derczynski, 2020; Poletto et al., 2021). Existing tools such as Hatebase.org, or the Twitter-backed Hate-Lab or a host of other recent studies have focused on identifying abusive language (Nobata et al., 2016; Waseem et al., 2017), toxic language (Kolhatkar et al., 2020; Kaggle, 2020), aggressive language (Haddad et al., 2019; Kumar et al., 2018b; Bhattacharya et al., 2020), offensive language (Chen et al., 2012; Mubarak et al., 2017; Nascimento et al., 2019; de Pelle and Moreira, 2016; Schäfer and Burtenshaw, 2019; Zampieri et al., 2019a, b, 2020; Kumar et al., 2021; Steinberger et al., 2017), hate speech (several including Akhtar et al. (2019); Albadi et al. (2018); Alfina et al. (2017); Bohra et al. (2018); Davidson et al. (2017); Malmasi and Zampieri (2017); Schmidt and Wiegand (2017); Del Vigna et al. (2017); Fernquist et al. (2019); Ishmam and Sharmin (2019); Sanguinetti et al. (2018)), threatening language (Hammer, 2017), or narrower, more specific dimensions such as sexism (Waseem, 2016; Waseem and Hovy, 2016)), misogyny, Islamophobia (Chung et al., 2019; Vidgen and Yasseri, 2020), and homophobia (Akhtar et al., 2019). Some datasets include a combination of these such as hate speech and offensive language (Martins et al., 2018; Mathur et al., 2018)), or sexism and aggressive language (Bhattacharya et al., 2020).\n\nIn this paper, we discuss the development of a framework that could be used for annotating the text with textual and contextual information such that the annotated dataset could be used for training models that could predict the offline impact of online content. In the following sections, we discuss the detailed annotation schema and annotation guidelines, a comparison with the other popular hate speech schema and finally some details of a new dataset annotated with the data."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   The HarmPot Framework",
            "text": "The analysis of online content focuses on understanding the dynamics of communication and its potential impact on real-world scenarios. This study emphasizes the importance of examining online interactions through a lens that considers various intersectional and contextual factors. Rather than concentrating exclusively on divisive elements like caste, gender, or religion, the approach takes a broader view to assess the implications of digital interactions.\n\nThe framework is designed to address a set of specific questions regarding any given text: Who is being addressed, when, how, why, and what consequences this communication might have for the addressee? These inquiries are approached by applying a series of parameters, which are systematically outlined in a predefined tag set.\n\nBy examining how online content functions within broader social narratives, the study seeks to understand the potential influence of digital communication. This comprehensive examination of textual interactions is an essential step in identifying the role of these dynamics in shaping offline realities.\n\nIn conclusion, this framework offers an in-depth analysis of online content by systematically examining the intersectional and contextual factors that contribute to its potential impact."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Magnitude of Harm Potential",
            "text": "A text will be marked as having ‘0’ potential in the following cases:\n\nTexts that are part of the dataset but do not actually relate to any specific incident of violence or larger narrative campaign.\n\nTexts that are blurbs accompanying links to news reports.\n\nTexts that criticize public figures and not protected identities.\n\nA text will be marked as having ‘1’ potential if it is likely to lead to offline issues in very few, specific contexts but more generally is not expected to trigger incidents. Instances include:\n\nTexts that target communities by using slurs and pejorative terms.\n\nTexts that reinforce negative stereotypes regarding a particular community.\n\nA text that is likely to trigger issues in most contexts—only in very specific contexts it may not be interpreted as a call to action—is marked as ‘2’. Instances include:\n\nExplicit cases of attack or accusations against communities.\n\nJustifying discrimination against communities.\n\nAny text with a high potential of triggering offline issues, irrespective of the context it occurs in, is marked as ‘3’. Instances include:\n\nExplicit and clear calls to action against communities or people.\n\nExplicit and clear attempts to incite action against communities or people.\n\nThe magnitude of potential is marked at two levels:\n\nText Span: It is marked in conjunction with specific spans of text that are used to refer to specific identities.\n\nDocument: It is the overall potential of the document, generally calculated based on the potential of individual spans. In cases where none of the spans refer to specific identities, an overall potential of the document is independently ascertained."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Who is being talked to?",
            "text": "This parameter is used to identify the specific types of identities that are ‘mentioned/referred’ (and not necessarily targeted) in a particular ‘span of text’. We discuss the various ontological types of identities that can be potentially targeted in a text.\n\nThere are three broad annotation instructions that are for this parameter -\n\nIntersectionality:  If more than one identity of the same individual is referred to (viz. Female Dalit or Pakistani Hindu) then the same span is marked with all the identities. If different identities are mentioned in different spans then also different spans will carry the same consideration of intersectionality.\n\nMultiple Identities:  If different identities of different individuals are referred to then they might have different evaluations.\n\nMultiple Spans:  If more than one span refers to the same identity of the same or different persons, each span could possibly have different assessments.\n\nThe framework itself does not enforce a specific set of identities to be marked. However, for the current project, the following non-exhaustive set of identities have been marked in the dataset. If needed, more, less or different kinds of specific subtypes of these categories may also be marked in the text.\n\nCaste: A span is annotated as targeting this identity if there are threats of violence, justification for caste-based discrimination, justification and support for untouchability and criticism of reservation (affirmative action) policy that questions the intellectual capability of these groups.\n\nReligion: A span is annotated as targeting a member of a religious community if it calls for or justifies violence against them. Propounding or justifying conventional stereotypes associated with the members of such communities or using religious slurs. For example, Muslims being called terrorists or jihadis, Muslims and Christians being targeted for alleged forced conversions and Sikhs being called Khalistanis or secessionists.\n\nDescent:  For our specific case, descent encompasses all identities based on inherited status. This includes ethnicity, race, and place of origin (including linguistic or cultural minorities) of a victim (but not caste given its prevalence in the Indian context). Spans supporting or justifying attacks based on places of origin are annotated under this category.\n\nGender:  This label annotates spans attacking gender minorities (LGBTQIA+ community) and women. Spans propounding or justifying conventional stereotypes or using gendered slurs are also marked with non-zero assessments.\n\nPolitical Ideology:  Political violence including murder, lynching, thrashing, etc of opposing party members or people of different political ideologies happens regularly. Spans calling for or justifying violence, supporting discrimination or furthering stereotypes against the supporters of a political party or ideology. However, a criticism of the political ideologies, political leaders, policies, etc is noted separately."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3.   When is the discourse happening?",
            "text": "This parameter indicates if a text is posted online in relation to or during a major, public event or happening. The major categories that we marked under this parameter are discussed below. This parameter is marked at the text/document level and the same text could take multiple labels. Since generally the dates of the events are already well-known, these labels could be mostly assigned automatically and could be seen as a grouping of multiple dates in a single category.\n\nRiots: In general, violent public disorders are referred to as riots. In India, in the past few years, hate speeches in social media have made a significant contribution to the amplification of violence during the riots. \n\nElections: Elections in India often see violence by supporters of rival political parties, and they are adopted in various themes such as communalism, terrorism allegations, anti-national, systemized threats, and disruption of harmony.\n\nExtremist Attack: An extremist attack on state forces or the public may also lead to online hate against particular communities. The Pulwama suicide attack of February 2019 in India led to widespread hate speech and real-world violence against Kashmiri Muslims throughout India.\n\nFestivals: Religious festivals have recently become flashpoints for communal violence with different sides accusing each other of attacking processions or interfering with rituals. Online hate and disinformation often spike during these situations.\n\nGroup-Specific State Decisions: This context pertains to when the government introduces or implements legislation/decisions affecting a particular community. The government’s decisions may be criticized or protested against by the community followed by online and offline attacks by the government’s supporters. Recent examples in India have been the Citizenship Amendment Act, Farm Laws, and the abrogation of Article 370.\n\nGeneric: These refer to the posts related to the incidents that are recurring in nature but generally do not have a fixed or pre-determined start or end time. \n\nOthers: The posts that do not co-occur with any of the above-mentioned contextual factors - seemingly one-off incidents of hate and violence at no specific time - are marked as others."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "2.4.   How is it being said?",
            "text": "The methodology developed here is sensitive to the fact that the core objects of study are linguistic events themselves, making it essential to model the textual features such as lexical, syntactic, and semantic properties that co-occur with the contextual features discussed in earlier subsections. For the current project, we have defined a set of semantic features (specifically mood and modality) and lexical features (affective expressions) that are marked in the text. Since other morphosyntactic features could be marked automatically using earlier existing systems or are implicitly learned by modern transformers-based multilingual models, we have not marked those separately. The labels for this parameter are marked at the span level and generally overlap with the spans of the ‘who’ parameter.\n\nWe discuss the different subtypes of these two categories used for annotation below -\n\nMood Type: The category of mood is a “grammatical reflection of the speaker’s purpose in speaking” (Kroeger, 2005 ###reference_b62###) or an indication of “what the speaker wants to do with the proposition” in a particular discourse context (Bybee, 1985 ###reference_b19###). Depending on whether the speaker wants to talk about a situation that has or will actualize in their perspective or whether they want to talk about an event that has not actualized, the grammatical form of the construction changes. We annotate three broad kinds of mood types -\n\nRealis Mood: The Realis mood portrays situations as actualized, as having occurred or actually occurring, knowable through direct perception (Palmer, 2001 ###reference_b85###). Indicative mood (that expresses actions that actually did take place, are taking place, or will take place) is the canonical bearer of realis mood in a language.\n\nIrrealis Mood: The irrealis portrays situations as purely within the realm of thought, knowable only through imagination (Palmer, 2001 ###reference_b85###). It is used to denote situations or actions that are not known to have happened. Modality-marked constructions, conditionals, counterfactuals, optatives, hortatives, and subjunctives are all grouped under the label of irrealis modality.\n\nNeither: Imperatives, interrogatives, future-tense marked constructions, and negative constructions are marked as ‘neither’.\n\nIllocutionary Mood: Illocutionary mood draws upon Austin and Searle’s idea of illocution and encodes speaker intention as a category of mood. There is an expected correlation between a speech act and a sentence type since there is a language-independent tendency for certain illocutionary acts to be mapped onto specific grammatical forms. We have used the following subtypes of illocutionary mood -\n\nDeclaratives: Declaratives can be either ‘direct’ (indicative mood) or ‘indirect’ (mainly using rhetorical forms). A rhetorical question is an indirect speech act which involves the use of the interrogative form for some purpose other than asking questions (Kroeger, 2005 ###reference_b62###). It can be used to indirectly assert something and thereby is an indirect declarative.\n\nInterrogatives\n\nImperatives: It could be in the form of a command, a request, advice, a plea, permission, an offer, or an invitation.\n\nAdmonitive: Admonitives are the warnings that a speaker issues to the addressee(s).\n\nProhibitive: Prohibitives curtail the addressee’s actions and stop them from engaging with some situation or action.\n\nHortative: It is used for softened commands or exhortations and shares properties with imperatives (Puskás, 2018 ###reference_b87###). It is often used with first-person inclusive reference (‘let us…’).\n\nOptative: Sentences in an optative mood express a wish or desire of the speaker that some situation be brought about.\n\nImprecative: It indicates that the speaker wishes for an unfavourable proposition to come about.\n\nExclamative\n\nModality: Modality can be viewed as speaker modification of a state of affairs with respect to how the event/situation is construed. Modalities come in two flavors - whether the speech event is ‘possible’ or ‘necessary’ given a particular set of conditions. We have used the following modalities for marking the text spans -\n\nEpistemic: It deals with “an estimation, typically but not necessarily by the speaker, of the chances or likelihood that the state of affairs expressed in the clause applied in the world” (Nuyts and van der Auwera, 2016 ###reference_b83###). It is marked if the sentence concerns the speaker’s knowing or believing that the state of affairs described is possibly or certainly true.\n\nDeontic: Deontic modality can be defined as “an indication of the degree of moral desirability of the state of affairs expressed in the utterance, typically but not necessarily on behalf of the speaker” ("
        },
        {
            "section_id": "2.5",
            "parent_section_id": "2",
            "section_name": "2.5.   Why is it being said?",
            "text": "This parameter analyses the discursive role of the text placed within its context and checks for the reason or rationale behind posting the text. It is a direct induction of the ‘discursive roles’ by Kumar et al. (2022a). We discuss the five categories here -\n\nAttack: This label is used when any comment/post poses an attack on any individual or group based on any of their identities.\n\nDefend: This label is used when any comment/post defends or counter-attacks a previous comment/post.\n\nAbet: This label is used when any comment/post lends support and/or encourages an aggressive act.\n\nInstigate: This label is used when any comment/post encourages someone to perform an aggressive act. The comment itself may or may not be aggressive but the purpose must be to instigate an act.\n\nInstigation happens before the event and its purpose is to trigger or provoke an act unlike abet which occurs during or after the act and its purpose is to praise, support, and/or encourage that act as well as other such acts in the future.\n\nCounterspeech: Texts that diffuse the situation will be tagged as counterspeech. Just as influential speakers can make violence seem acceptable and necessary, they can also favourably influence discourse through counterspeech."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Data Collection and Annotation",
            "text": "The framework discussed in Section 2 is developed over several stages and iterations. In order to test the reliability and validity of the framework, we collected a dataset from different social media platforms and annotated those using the framework. As a first step towards data collection, we focussed on a few incidents that had a link to online disinformation and hate campaigns from 2016 – 2022. This time period was decided given the introduction of low-cost data and smartphones by Reliance Jio in 2016 which led to a manifold increase in per-capita data usage. Finding relevant government-published data related to hate crimes was a challenge as the Indian government stopped collecting data on hate crimes in 2017. Therefore, we decided to use databases from non-governmental organisations like Documentation of the Oppressed (DOTO). This database consisted of a list of over 1,100 incidents since 2016. Out of these, we sampled a little over 150 since they had a link to social media discourse. We extracted social media data related to these incidents from different social media platforms viz Twitter, YouTube, Facebook, Telegram and WhatsApp. We also ensured that we collected data both from before and after the incident separately. This approach ensured that we got data that had links to incidents so they could be considered as potential triggers for the incident; at the same time, we also got data that might be triggers for a related post-event incident. We collected a total of over 417,000 datapoints in Hindi and English using this methodology. The complete dataset, along with the incidents they were associated with will be released publicly for further research."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Inter-Annotator Agreement",
            "text": "Approximately 5 - 10 data points were selected from approximately 50 incidents for running the inter-annotator agreement experiments. Each of these was annotated by 3 annotators and Krippendorff’s Kappa was calculated. The first round of experiments with around 500 data points gave a rather dismal Kappa of 0.25. Following this, we made certain changes to the tagset such as merging different categories to reduce overlap across categories (for example, race, ethnicity and nationality under ‘Who’ were combined into a single category of ‘Descent’) and introducing new categories to better classify different kinds of categories (for example, several new categories under mood and modality were added for a better analysis). We also made changes to the annotation guidelines for clarity. These changes led to significant improvements in the alpha - the second round of experiments gave a final value of 0.53. \n\nWhile the Kappa value still remained low, for a highly subjective task, it was considered reasonably good. We started conducting focus group discussions to understand the reason behind disagreements. As it has been argued earlier (for example, Kumar et al. (2022b  ###reference_b67###) and also the Perspectivist Data Manifesto 444 http://pdai.info/ ###reference_dai.info/###), most of these disagreements seemed reasonable. As such, we decided not to push for further agreement - instead, we will be making the disaggregated annotations by different annotators publicly available."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Data Annotation",
            "text": "We have annotated a total dataset of approximately 2,000 data points (taking around 15 - 20 data points from over 100 incidents) to demonstrate the validity of the presented framework. We made use of an online app - LiFE App (Singh et al., 2022) - for data annotation since it allowed us to annotate the data simultaneously at the document and the span level. Each data point was annotated by 3 annotators working independently."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   HarmPot and Other Frameworks: A Comparison",
            "text": "As we mentioned earlier, most of the existing frameworks attempt to only model hateful, aggressive, offensive (or one of the other similar flavours) speech. Moreover, prior studies have also pointed out the need to flesh out the interrelationship between different frameworks so as to ensure interoperability and cross-use of datasets annotated with different hate speech frameworks (Poletto et al., 2021; Kumar et al., 2022b). In order to understand this relationship, we carried out a comparative study between our framework and three of the other popular frameworks. We took 500 texts annotated with each of these different frameworks and carried out a comparative study."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   HarmPot and HASOC",
            "text": "Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC) is a series of workshops/shared tasks that have been held since 2019 and that makes data available for Indo-European languages, marked with hate and offensive labels (Modha et al., 2019; Mandl et al., 2020, 2021; Amjad et al., 2021; Mandl et al., 2022).\n\nThe first level of the schema distinguishes between Hate and Offensive (HOF) and Not hate and offensive (NOT). The second level of the schema classified HOF into three classes - Hate, Offensive and Profane. In the 2022 and 2023 editions, the second level of the schema was a multiclass annotation indicating Standalone Hate (hate by itself), Contextual Hate (hate in the context of its parent), and Non-hate (not hate by itself).\n\nIn the 2023 edition, the task of identifying spans of hate was also introduced in the HateNorm track. We took a total of 500 texts each from the 2019 and 2023 editions of the task. Level 2 of 2022 and 2023 editions, which mark whether it is contextual or standalone hate do not have a direct relationship to our framework - the main reason being that our definition of ‘context’ is more rooted in how it is defined in discourse analysis and pragmatics as different socio-cultural factors affecting the interpretation of the text."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   HarmPot and OLID",
            "text": "The Offensive Language Identification Dataset (OLID) contains a collection of over 14k annotated English tweets using a three-level annotation framework. Level A distinguishes between Offensive and Non-offensive texts. At Level B offensive texts are further classified into targeted and untargeted insults. Level C categorises targeted insults into Individual, Group and Other targets (Zampieri et al., 2019a  ###reference_b125###). It’s a comparatively coarse-grained tagset but unlike the HASOC tagset, it addresses the two questions of ‘who’ is being targeted and ‘magnitude’ of the attack. For level A, the results of the comparative study were similar to the HASOC dataset."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   HarmPot and ComMA",
            "text": "The top level of the framework distinguishes between overtly, covertly, and non-aggressive texts. At the second level, the aggression intensity of the aggressive texts—physical threat, sexual threat, non-threatening aggression, and curse/abuse—are marked. Parallel to this, bias and threats of four kinds—religious, caste/class, gender, and racial/ethnic—are marked. It also marks the discursive roles—attack, defend, counterspeech, abet and instigate, and gaslighting—of the text. These discursive roles are already borrowed and incorporated in the HarmPot framework. Besides this, there are several parallels between the ComMA and HarmPot frameworks and also since social or physical ‘harm’ is inherent to the idea of aggression, we expected a good mapping between the notion of verbal aggression and the harm potential of a text."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Conclusion",
            "text": "In this paper, we have presented a new framework for annotating social media text using contextual information such as the identity of the victim, the socio-political situation, and the role that the text assumes in the discourse. We have proposed using mood and modality as relevant categories for marking the speaker’s intention, intended goal, and their evaluation of whether what they are saying is ‘necessary’ or ‘possible’. These semantic categories have been rarely utilised in NLP but could prove to be extremely useful in the identification of subjective phenomena. We have annotated a total dataset of 4,000 texts, with datasets available for aggressive and hateful language identification. We are currently annotating some more data and conducting experiments for the automatic identification of subjective phenomena to understand the practical efficacy of the framework."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Ethical Considerations",
            "text": "The nature of the task - the creation of datasets with high harm potential and its annotation - in itself raises several ethical issues of bias and psychological impact on the annotators working with the data. In order to reduce the impact of working with such data, we took 3 steps - (a) a ‘maximum’ limit of 200 texts per week was set for the annotators - the annotators were barred from going through more than this number of texts in a week; (b) we had made arrangements for psychological counselling of the annotators working on the data; (c) a compulsory weekly ‘venting out’ meeting was organised to enable annotators to talk to each other and other members of the project that allowed them to talk about, discuss and (hopefully) figure out the ridiculousness of the data that they were going through. We made a very conscious decision not to use crowdsourcing or even third-party annotators for data annotation and collection so as to ensure that these mechanisms are put in place.\nIn order to minimise the bias in the annotations and also make different perspectives on the data public, we have decided to release the disaggregated dataset with the annotations of all the annotators (with their disagreements). We were very conscious not to push for an agreement where it was not possible. Moreover, our in-house annotators were from mutually distinct socio-political, religious, cultural, and educational backgrounds, providing an innate cancelling out of any one type of bias overpowering the data analysis and interpretation - we have tried to annotate the data in such a way as to reflect different perspectives on the data (and not propound a single, homogeneous view)."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Limitations",
            "text": "One of the primary limitations of the framework and the dataset is the lack of multimodal information being included in it. A large number of hateful and abusive language used on social media, with a high potential for harm, is expected to be accompanied by visuals including images and video. We are working on expanding the dataset to include multimodal data and see how well the framework adapts to that and also what kind of modifications would be needed for handling those cases. The second limitation is the pipeline-based workflow that the framework enforces, which has a greater chance of error propagation - if, for example, the system makes an error in recognising mood and modality, that might ultimately lead to an error in the prediction of harm potential itself. This is a general limitation of the hierarchical frameworks."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Bibliographical References",
            "text": ""
        }
    ]
}