{
    "title": "Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram",
    "abstract": "Objective —\nTo (1) identify health-related terms used on social media posts that do not precisely match the health-related meaning of terms in a biomedical dictionary, (2) decide which terms need to be removed in order to improve the quality of the dictionary in the scope of biomedical text mining tasks, (3) evaluate the effect of removing imprecise terms on such tasks, and (4) discuss how human-centered annotation complements automated annotation in social media mining for biomedical purposes.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Social media data, such as text, hashtags, or images in posts, allow researchers to gain unprecedented access to study human cohorts. It is now possible to quantitatively measure very large populations for their individual or collective experiences, behaviors, perceptions, and emotions.\n\nSocial media is more than a source of information or a valuable communication tool for its users—it is also a valuable resource of information about human health and well-being. It has been used to track and predict various public health issues, such as mental health disorders, adverse drug reaction (ADR), drug-drug interactions (DDI), and substance abuse.\n\nInstagram is one of the most popular social network services in the world; in 2021, Instagram reached more than 1 billion users worldwide. Through an application for smartphones or tablets, users can share photos and videos, often accompanied by long captions. Although most research on social media has been focused on data from Twitter or Facebook, Instagram has great potential for social media research given its increasing number of users. It has already shown its potential for large-scale social media analysis and monitoring of public health issues, such as DDI and ADR, uncovering behavioral pathology and associations between drugs and symptoms in depression. It can even be used as a tool for communication and support between patients and healthcare providers, and other health-related applications. For these reasons, the work described here is focused on data from Instagram, but our methodology and results are applicable to other social media from Twitter to Reddit.\n\nDespite the benefits of social media analysis for public health, social media research has not focused much on people with epilepsy (PWE), a chronic noncommunicable brain disorder and one of the most common neurological diseases. In the U.S., more than three million adults have epilepsy, and about 470,000 children were diagnosed with active epilepsy in 2015. Epilepsy-relevant Facebook pages and Twitter accounts play an essential role in providing information about drugs or correcting misconceptions or epilepsy stigma on online platforms. Furthermore, our team has shown that even small cohorts of epilepsy patients on Facebook can inform experts about relevant behaviors involved in rare outcomes, such as sudden death in epilepsy.\n\nTherefore, more research on PWE and their caregivers’ online behaviors on social media, from epilepsy-specific online groups to general-purpose platforms, is needed—especially to better understand their complex symptoms and medication schedules, including DDI and ADR. To support such a research agenda, it is essential to develop automated annotation pipelines to mine and detect biomedical signals from large-scale social media data in general. At the core of such pipelines is the construction of biomedical dictionaries to tag relevant terminology in social media posts. Typically these are produced from databases and named entity recognition tools that were developed for scientific discourse, such as papers with experimental evidence available on PubMed.\n\nHowever, it is unclear whether biomedical dictionaries built from scientific discourse and evidence are fit for the informal discourse and particularities of discussions on Instagram and other social media that are relevant for epilepsy (or other conditions of medical interest). To address that question, here we present a human-centered dictionary refinement methodology and analysis tailored to tag clinically relevant terminology for the study of epilepsy cohorts on Instagram. For comparison, OpenAI’s GPT series models, as representatives of Large Language Model (LLMs), were also used as an alternative annotation process, though leading to worse results than human annotators in our analysis.\n\nIn addition to producing a focused biomedical dictionary for social media, our manual annotation effort demonstrates the importance of human annotation to improve the quality of cohort-specific social media analysis."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Data and Methods",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Dictionary Construction",
            "text": "Our dictionary includes terms related to drugs, allergens, medical terms, and natural products, including cannabis. We construct this dictionary following [15, 29]. We recall the details of that construction below.\n\nWe obtained these terms from a variety of existing medical ontologies and data sources. Drug, allergen, and food terms are retrieved from Drugbank (v.5.1.0) [30]. Medical terms including, but not limited to, disease symptoms and drug side effects are obtained from MedDRA (v.15) [31]. Natural products are retrieved from MedlinePlus [32] and TCMGeneDIT [33]. For cannabis, we manually added commonly referred terms and slang, such as ‘Mary Jane’ and ‘420’, to our dictionary, as detailed in [15]. In addition, epilepsy terms commonly used by patients on Internet forums were manually added using a C-value [34] tokenizer on the Epilepsy.com discussion forums. These epilepsy-related terms include mentions such as ‘VNS’ (i.e. Vagus Nerve Stimulator) and were validated by an epilepsy specialist and matched to MedDRA codes.\n\nWe distinguish dictionary terms into four categories: Allergens, Drugs, Medical Terms, and Natural Products. Allergens include food names, ingredients, and animals (e.g., Orange, Duck); Drugs include medicine and chemical compounds (e.g., Diazepam); Medical Terms include status and conditions of putative medical relevance, such as physical, psychological, or physiological features (e.g., Headache, Feeling hot); Natural Products consist of plants and their extracted elements (e.g., Rose).\n\nImportantly, synonyms are possible for each term. Therefore, all those are matched—as child terms—to a unique parent (preferred) term. For instance, Weed, Mary jane, 420, and Cannabis are all synonyms of the parent term Cannabis. The parent term is also included as a child term for completeness of synonym lists. Drug names are treated similarly, whereby we keep the chemical name as parent terms (e.g. Diazepam), and all known commercial names (as extracted from DrugBank [30]) as child terms (e.g. Valium). Some data sources of our dictionary already have term hierarchy, and we used it as the base of our parent term mapping (for example, the “preferred term” in MedDRA is mapped to the parent term in our dictionary).\n\nTable 1 lists examples of the extracted posts, terms, and their parent term. After this collection and initial automatic curation procedure, our dictionary contains 176,278 terms, of which 105,345 are Drugs, 66,961 are Medical Terms, 2,797 are Allergens, and 1,175 are Natural Products."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Data Collection and Post Tagging",
            "text": "Since June 2016, the collection of Instagram data via the platform’s API has been limited due to a company policy change. Here we use publicly available data from Instagram posts ranging from 2011 to early 2016 when they were collected and securely stored according to the platform’s terms on our servers. The data is comprised of the entire timelines (all time-stamped public posts) of Instagram users who produced at least one post mentioning a hashtag with a drug name (or synonym) known to treat epilepsy. The drug names we used to retrieve timelines include carbamazepine, clobazam, diazepam, lacosamide, lamotrigine, levetiracetam, oxcarbazepine, as well as all their brand name synonyms (e.g., Valium). In addition, we added all user timelines that mentioned the epilepsy-associated hashtag ‘#seizuremeds’ which is commonly used among people with epilepsy (PWE) on discussion forums such as Epilepsy.com. This resulted in the collection of the entire timelines of a cohort of 9,890 users, comprising 8,496,124 posts. Duplicate posts from regrams were removed. In order to protect user privacy, we did not extract demographic information from the collected accounts. The caption field of all collected posts was subsequently tagged with the dictionary terms according to an automatic multi-word lexical matching pipeline, resulting in a total of 979,683 dictionary term matches on the more than 8 million Instagram posts in the dataset."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Results",
            "text": ""
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Human-centered Annotation",
            "text": "Automatic lexical matching with biomedical dictionaries built from scientific discourse and evidence is not necessarily contextually accurate when tagging social media posts. Indeed, dictionary terms used in social media discourse may refer to alternate meanings without any putative clinical relevance. For instance, the term ‘hot’ has multiple meanings depending on context, ranging from ‘having a fever’ to ‘sexual appeal’. Naturally, we are only interested in the potential clinical relevance of dictionary term usage. Therefore, we need to refine the dictionary terms to improve the accuracy of term matches in biomedical social media analytics.\n\nTo do this we designed and pursued a manual annotation workflow to identify the dictionary terms most likely to be irrelevant in the context of Instagram discourse related to epilepsy. Because it was unfeasible for our team to manually annotate over 8 million posts, a sample was randomly selected to provide a reasonable amount of posts for human annotators. This resulted in a set of 1,771 posts containing at least one matched term, for a total of 2,947 matches, associated with 466 unique parent terms.\n\nThe number and proportion of matches per dictionary category is:  = 874 (29.7%; 108 parent terms),  = 204 (6.9%; 64 parent terms),   = 1,647 (55.9%; 268 parent terms), and   = 222 (7.5%; 26 parent terms). Table 1  ###reference_### shows examples of posts and respective matched child terms (in red), their parent terms and categories. Each human annotator was given our annotation guidelines to understand the goal of the study and criteria to determine whether a matched term is used in the expected or correct sense (‘true-positive’). Also, they were provided with instructions with examples to learn how to annotate through our annotation tool.\n\nThis sample was subsequently used in our annotation workflow which comprises two rounds (See Figure 1  ###reference_### & SI: Figure S1  ###reference_###): ###figure_1###.\n\nInitial annotation & guideline refinement. 292 posts with 499 dictionary matches were used to test the annotation workflow and to refine our annotation guidelines, establishing a standard for deciding whether a matched term was used as intended by the biomedical dictionary (true positive) in the context of the post. For instance, in the context of medical terms, if a matched term “A” is expressed as signifying a medical term, health condition, drug, food, or (potential) allergen (‘A’), an annotator is instructed to label it as ‘True.’ Each sampled post was assigned to two annotators, with disagreements being collectively discussed to reach a consensus that triggered a revision to the guidelines.\n\nFull annotation review. Using the refined annotation guidelines obtained from the first step of the workflow (See Table 2  ###reference_###), all 1,771 posts in the sample and their 2,947 matches were reviewed independently by two annotators. Data scientists in training as well as epilepsy researchers participated in the annotation. They decided whether terms were appropriately matched (true-positive) or unclear to determine (e.g., a term with unclear meaning). Annotations were compared, achieving a good inter-rater reliability rating (Cohen’s Kappa=0.634) [36  ###reference_b36###].\n\n###figure_2### An example of the interface used by annotators is provided in Figure S2  ###reference_### in SI. In this interface, each row displays a complete Instagram post with a dictionary term match highlighted in red. An annotator can review the context of each post and determine whether the meaning of the red-highlighted word is expressed with the intended use of the biomedical dictionary term, following the criteria provided in the guidelines. Notice that annotators are not shown the photos that accompany the post text on Instagram. They are only shown the text, which makes this a difficult task for human annotators and more so for LLMs used below."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Identifying Ambiguous Terms",
            "text": "After the full annotation review step of the human-centered annotation process, annotators considered and inferred the context of the post where the match occurred from text alone. In one case, from context, annotators infer that the dictionary term for Orange (as fruit it is in the allergen category) is actually used to mean the color orange. Similarly, in another post, rose was actually identified as a typo for rosé (wine), thus assigned to an incorrect parent dictionary term. Focusing on each of the four term categories, the human-centered annotation revealed occurrences in various contexts: \n\nAllergen: These include Orange, Apple and Ginger which were frequently found to indicate a color, name (brand, pet, place, etc.), or toys, respectively.\n\nDrug: Since this drug brand name is frequently used as a metaphor on social media (unlike in the scientific literature), a discourse feature human annotators can easily infer (unlike most automatic methods).\n\nMedical term: This category showed broad meanings in which these terms were frequently used. For instance, Hot resolves to the Feeling hot parent term, which clinically means to be “having or feeling a relatively high temperature” (fever). However, in the sampled posts, Hot often meant “sexually excited” or “newly made”—another case of very distinct usage between social media and scientific discourse.\n\nNatural product: Examples include Rose, Rosa, and Daphne, where the inferred context often indicated one’s name or color.\n\nThe next step is to identify which terms are most ambiguous and should be removed from the dictionary in order to refine and tailor it to epilepsy discourse on social media, our problem domain. The most concerning terms are naturally those that occur very frequently in our data. Table 4 lists the top 8 such child terms, as well as their respective parent terms. For instance, the terms Hot, Cold, and Euphoria are frequent matches in posts, but most of the time without any putative medical significance since they typically occur in contexts without any relationship to the intended meaning of the term in the biomedical dictionary.\n\nIn contrast, while the term Cannabis appears very frequently in our samples, it is most often used in relevant contexts. In Figure 2, we show two of the synonyms of Cannabis: 420 and weed.\n\nTo obtain a new refined dictionary, we established a criterion to remove terms that maximize this ambiguity and occur frequently enough in the human-annotated post sample. We first selected terms with a high ambiguity and frequency, subsequently ranking them by frequency. This resulted in the removal of 8 terms listed in Table 4: Hot, Cold, Euphoria, Valium, Death, Rose, Orange, and Ginger. Among the 8 terms, we found that most occurrences of Hot were not about feeling elevated temperature but about feeling excitement or describing something as popular. On the contrary, Cold was mostly used as a term about temperature, not about the illness known as the Common Cold. Likewise, the meaning of Euphoria was often not related to one’s feeling of joy, since it was frequently used in club music-relevant contexts that may indicate a musical genre, a music album, or a brand.\n\nAs for Valium, if the word was mentioned with other terms related to drugs, it was easier to determine meaning. However, almost half of the posts that mentioned it did not provide enough context. In the remaining half, it was often used as a metaphor for something boring (e.g. example on the second row of table 3). Finally, Rose, Orange, and Ginger in the posts were frequently used as proper nouns, such as a person, an area, or a pet."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Impact of Removing Ambiguous Terms",
            "text": "After dictionary refinement, we evaluate the impact of term removal on the eigenvector-centrality of networks whose edge weights are obtained by tallying dictionary co-mentions in posts (their construction, especially how we dealt with parent terms and child terms, is detailed in SI Section B.1). These co-mention networks can be seen as associative knowledge structures that characterize the discourse of social media cohorts. The co-mention networks are built on the level of parent terms in the sense that each node is a parent term covering several synonyms in the dictionary. In such associative knowledge networks, removing terms from the dictionary potentially reduces the set of nodes that comprise them (each parent term is represented as a node and the term removal is done at the level of the child term). More importantly, removing terms also affects the edge weights between nodes, as co-mention counts are altered. Since the structure of connections is altered, all inferences one can make from these networks—such as information retrieval, link prediction, community structure, shortest paths—can be affected. We chose eigenvector centrality because it is a popular measurement of node importance that accounts for indirect influence between nodes on undirected graphs, thus allowing us to assess the network-level impact of term removal. Another popular node centrality is PageRank centrality. Although it is powerful on directed graphs, it is highly correlated with (or almost exactly the same as) node degree when applied to undirected networks. Therefore, since our co-mention networks are undirected, we choose eigenvector centrality rather than PageRank to assess the effect of removing terms. The top 20 terms ranked by eigenvector centrality, before and after dictionary refinement, are shown in Table 5. Top eigenvector centrality terms before the refinement include terms not particularly relevant to epilepsy, such as Cocoa or Tattoo. However, after dictionary refinement, not only do parent terms like Feeling hot disappear from the top, since their main child terms were no longer present in the dictionary, but we see that all the top 10 terms are associated with epilepsy, as attested by our epilepsy specialists. For instance, Depression, a clinical diagnosis often co-morbid with epilepsy, jumps from 9th (0.040) to the top-ranked centrality score term (0.599), closely followed by Anxiety. This suggests that our dictionary refinement improved the quality of the top eigenvector centrality terms, bringing epilepsy-related terms to a more central role in the knowledge network."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Comparing Social Media with Medical and Scientific Discourse",
            "text": "At the onset, the hypothesis behind our study is that while there is much discourse on general-purpose social media platforms that is of biomedical relevance, it is expressed differently than scientific discourse and unfolds simultaneously with many other contexts that are not relevant to health. Thus, human-centered dictionary refinement is needed to remove ambiguous terms in such platforms. \n\nTo emphasize this need, and how different general-purpose social media discourse is, we go beyond Instagram and deploy both the original and the refined version of our dictionary in other data sources: epilepsy-related abstracts from PubMed, epilepsy-related clinical trials from clinicaltrials.gov, Twitter (now named X) posts from users who have mentioned epilepsy related terms, and discussion forums from Epilepsy.com. Detailed descriptions of data harvesting and network construction of additional data sources are available in SI Appendix B under each data source section.\n\nThe first two additional data sources pertain to scientific discourse. Both Instagram and Twitter data sources represent epilepsy related users’ speech on a general-purpose social media. The last data source is a form of social media that is focused on a single topic of medical relevance—epilepsy, in this case.\n\nThis suggests that general-purpose social media platforms such as Instagram are much noisier for biomedical surveillance, and for epilepsy research in particular, since users tend to post about many distinct aspects of their lives. In contrast, in the Epilepsy Foundation (EF) forums users center discourse around their condition, which naturally makes it a rich resource for epilepsy research.\n\nThe same can be said for the chosen PubMed articles or Clinical Trials, where the scientific context is focused on epilepsy. Therefore, the impact of removing the same 8 terms from the knowledge networks of both the EF forums and the PubMed abstracts is much less pronounced in comparison to Instagram."
        },
        {
            "section_id": "3.5",
            "parent_section_id": "3",
            "section_name": "The disagreement between GPT-4 and human annotators is significant",
            "text": "Complementary to our human annotation efforts, we tested the feasibility of using a large language model instead of human annotators in the labeling process of our proposed dictionary refinement workflow. We assigned the same labeling task to OpenAI’s latest and most advanced model, GPT-4 (version 1106 in 2023) and its predecessor GPT-3.5 via OpenAI’s API, using the same guidelines we provided to human annotators.\n\nWe find significant disagreement between GPT-4 and the decisions of human annotators. We use OpenAI’s API to ask OpenAI’s GPT-3.5 (version gpt-3.5-turbo-1106) and GPT-4 (version gpt-4-1106-preview) to do the same labeling task as our human annotators. We converted the human annotation guidelines, initially designed for humans and presented to them in slides, into a text-based prompt for the AI, undergoing several rounds of refinement for optimization. For human annotators, the term matches to be annotated are highlighted in color, while for the LLM’s task, these terms are marked with asterisks (*) on both sides. This method serves as a text-based alternative to visual highlighting, and is commonly used in prompting LLMs.\n\nFor each term tagged on a post, we query the LLM using two prompts: one system prompt based on the annotation guidelines, and one user prompt containing the entire text of the post with the highlighted term. The LLM was instructed to provide a response in json format, with both the decision label and justification for the classification. The model’s response was then collected and parsed. For term matches that the LLM returned a different label than human annotators, we used the justification text generated by the model to suggest possible causes for the disagreement.\n\nFor each round of our prompt iteration, we used 200 tagged terms to test the performance. During those tests, GPT-3.5 consistently showed inferior performance compared to GPT-4, so we did not run a full-scale evaluation for GPT-3.5, choosing to focus on GPT-4 only. For the final full-scale test, we sent 1,500 term matches to GPT-4 (corresponding to 1,500 rows in the tables for human annotators), using our final version of the prompt.\n\nIn particular, GPT-4 tended to label correctly matched terms (“True Positive” in the annotation guideline and “match” for short in the following tables) as incorrectly matched (“mismatch” for short in the tables). In other words, it is more strict in designating a term as being used in a putatively clinically relevant way. As shown in Table 8, for the same set of 1,500 term matches, there are only 29 cases where the master annotator determined it as “mismatch” while the annotator 2 thought it was a “match”; in comparison, there are 285 cases where GPT-4 thought it was “mismatch” and the annotator 2 thought it was a “match”."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Discussion",
            "text": "In this paper, we show the importance of manual curation in developing a biomedical dictionary to study epilepsy-related discussions on social media. Despite its cultural importance and global reach, Instagram, the social media we study, has not been a focus of social media research. In general, most biomedical research on social media focuses on platforms with freely and easily accessible data, such as Twitter (now named X). \n\nVery few studies so far have analyzed the social media discourse of people with epilepsy and their caregivers [6  ###reference_b6###] using biomedical dictionaries. The use of dictionary-based methods to study biomedical discourse is not new. In general, they have been used for knowledge discovery and applied to large corpus of clinician-written notes and more recently extracted from electronic health records. Our goal here using human annotation is to refine the dictionary by removing inappropriate terms for social media data analysis.\n\nHuman annotation has been widely used to analyze and understand sentiments, behaviors, perceptions, languages, or relations of people in social media. Although automated annotation techniques can process data faster than human annotation, our results support prior literature showing human annotation is necessary when extracting term meaning from social media posts. Balancing between the speed of automated annotation and the reliability and validity of human annotation can lead to optimal results.\n\nWe identified what kinds of terms tend to mean differently than their biomedical meaning through human annotation and how often they have been used in social media posts. Proper nouns were one of the most common cases of misinterpretation, along with words used as metaphors. These results imply that future research on social media with biomedical dictionaries should be cautious about terms with multiple meanings for more precise analysis.\n\nAnother source of noise in term tagging on social media is the lack of context information. Annotators sometimes found it difficult to determine the true meaning of the words due to this lack of context. Machine-based methods may struggle to accurately tag terms in such ambiguous contexts. Our results show that dictionary refinement via human annotation has a significant impact on downstream data analysis and suggest the importance of this practice in ensuring accurate term tagging.\n\nWe found that the impact of the refined dictionary affected not only the terms removed but also had broader implications on the analysis, such as network analysis. It suggests potential network-based methods for identifying low-quality terms in the dictionary. These low-quality terms could either be ambiguous or inappropriate for inclusion. The structure and connections generated by these terms differ from the majority knowledge structure, indicating possible approaches for identifying them.\n\nWe also found that different data corpus benefits more from dictionary refinement than others, suggesting the need for dictionary refinement tailored to each individual research topic and data corpus. The Instagram posts' manual annotation suggests that a similar approach could be useful for refining dictionaries specific to other platforms like EF forums, PubMed abstracts, Clinical Trials, and Twitter. The variation in ambiguous terms across datasets could be due to the inherent differences in language usage and richness levels between social media, online health communities, and medical resources.\n\nIn Section 3, we have shown that GPT-4 could not replace human annotators in this task. GPT-4 often stayed within the narrow definitions of terms according to guidelines. Human annotators, however, could interpret terms in broader contexts and understand why certain terms were included or excluded, labeling them appropriately. GPT-3.5 exhibited more bias than GPT-4, further emphasizing the need for human involvement.\n\nEven with current LLMs, their operational costs prohibit large-scale applications. Nonetheless, the evolving field of LLM research holds potential for enhanced term tagging and dictionary refinement, potentially leading to better data coverage and improved analysis outcomes. In the future, hybrid approaches or more advanced LLMs could be used to refine dictionaries and analyze social media data with greater accuracy and efficiency."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "This research identified the terms in our dictionaries with higher frequencies in an epilepsy cohort on Instagram by using the human annotation method. On comparison, GPT series models cannot replace human annotation in the annotation process. We also identified which terms should be removed from our dictionary to obtain more epilepsy-relevant results from network analysis. Additionally, we identify the fundamental cause of incorrect term matches—having different meanings that are often used—and specific cases. Finally, through validation of the impact of the refined dictionary on eigenvector centrality analysis of the co-mention networks, we demonstrated the impacts and complementary role of the human annotation method to the automated annotation technique. Our results demonstrate that human-centered dictionary refinement should be performed when conducting social media mining of biomedical relevance, and epilepsy in particular. It remains to be determined if this approach is also necessary for analyzing other types of scientific or patient-centered textual resources. Our study has utilized a large number of terms in medical dictionaries and focused on Instagram, which may have significant potentials for large-scale social media analysis. Other social media studies on medical corpus have more focused on Twitter and Facebook, and most of them have selected a few specific medical terms in their analyses. Our results and implications may help future research in our research communities, including the areas of bioinformatics and health informatics, by improving analysis of medical topics on social media speeches. Ultimately, this research would contribute to developing knowledge graphs that more truthfully represent the underlying knowledge structure, which can be used for personalized information systems that can support PWE, PWEC. And the workflow could also be applied to other diseases and support other disease cohorts."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Acknowledgement",
            "text": "This work was partially funded by National Institutes of Health, National Library of Medicine Program, grant 01LM011945-01 (LMR, AM, XW, RBC, and WRM), a Fulbright Commission fellowship (LMR), the NSF-NRT grant 1735095 “Interdisciplinary Training in Complex Networks and Systems” (LMR, AM, XW and RBC), and Fundação para a Ciência e a Tecnologia, grant PTDC-MEC-AND-30221-2017 (RBC)\nThe funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript."
        }
    ]
}