{
    "title": "CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling",
    "abstract": "Using large language models (LLMs) to assist psychological counseling is a significant but challenging task at present. Attempts have been made on improving empathetic conversations or acting as effective assistants in the treatment with LLMs. However, the existing datasets lack consulting knowledge, resulting in LLMs lacking professional consulting competence. Moreover, how to automatically evaluate multi-turn dialogues within the counseling process remains an understudied area. To bridge the gap, we propose CPsyCoun, a report-based multi-turn dialogue reconstruction and evaluation framework for Chinese psychological counseling. A two-phase approach is devised to construct high-quality dialogues for psychological counseling. Competitive experimental results demonstrate the effectiveness of our proposed framework in psychological counseling. We open-source the datasets and model for future research. 111https://github.com/CAS-SIAT-XinHai/CPsyCoun",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "\"No health without mental health\" is becoming more than a slogan, with approximately 14% of the global disease burden attributed to neuropsychiatric disorders Prince et al. (2007 ###reference_b16###). Despite the affordability and effectiveness of many mental health treatments, a significant gap persists between those in need and those able to access care Freeman (2022 ###reference_b7###). The World Health Organization (WHO) continually advocates for increased investment to augment understanding and dispel the stigma associated with mental health disorders. Yet, the challenge of ensuring quality, affordable care for mental health conditions remains formidable. Consequently, the identification of novel treatments and enhancement of existing therapies for all mental diseases are key objectives in the research domain.\n\nThe Natural Language Processing (NLP) community is actively contributing to the advancement of AI-assisted psychological counseling and treatment. Various research topics have been proposed to conduct mental disease counseling Orr et al. (2022 ###reference_b14###); Toleubay et al. (2023 ###reference_b23###), improve emotional support ability Buechel et al. (2018 ###reference_b3###); Rashkin et al. (2019 ###reference_b19###); Liu et al. (2021 ###reference_b12###); Cheng et al. (2023 ###reference_b6###), and provide online psychological consultation Sun et al. (2021 ###reference_b21###).\n\nThe advent of large language models (LLMs) such as ChatGPT and LLaMA Touvron et al. (2023 ###reference_b24###) has spurred more research efforts on generating not just empathetic conversations but also serving as therapeutic aids and effective assistants in treatment. For instance, Psy-LLM Lai et al. (2023 ###reference_b9###) is a psychological consultation model that leverages the LLM PanGu and is trained with Q&A from professional psychologists and large-scale Chinese psychological articles from public databases. This model demonstrates proficiency in psychological knowledge and counseling services. Parallel to this, other LLM-based psychological models such as MeChat Qiu et al. (2023 ###reference_b18###), SoulChat Chen et al. (2023b ###reference_b5###), and MindChat Yan and Xue (2023 ###reference_b27###) are also available online. Recent trends in adopting LLMs for psychological counseling focus on generating more interpretable mental health analyses Yang et al. (2023 ###reference_b28###) and simulating psychiatrist-patient interactions Chen et al. (2023a ###reference_b4###). This shift in focus from generating responses to diagnosing mental health issues as an expert signifies a trend change in research. \n\nDespite these advancements, there remains a dearth of authentic counseling datasets from psychological counseling sessions, which include symptom descriptions of the consultant and treatment methodologies employed by the counselor. Such data could offset issues arising from doctor-patient simulations being template-based and lacking control. However, it’s noteworthy that these diagnoses are generally sensitive, warranting careful attention to potential privacy issues.\n\nIn this paper, we propose a new framework CPsyCoun for Chinese Psychological Counseling, which consists of a dialogue reconstruction method based on psychological counseling reports.\n\nSpecifically, we first collect anonymized psychological counseling reports from publicly accessible websites and further propose a privacy shadowing method to postprocess these reports into a dataset CPsyCounR. CPsyCounR includes nine types of psychological consultation and seven classic schools of psychological counseling. Through our proposed Memo2Demo dialogue reconstruction method, we construct another dataset CPsyCounD, which contains 3,134 high-quality multi-turn consultation dialogues. Further, we propose a psychological counseling benchmark for automatic evaluation on multi-turn dialogues and fine-tune an open-sourced LLM on CPsyCounD, named CPsyCounX.\n\nFigure 1 ###reference_### illustrates the general framework of our proposed CPsyCoun.\n\nOur contributions are the following: \nTo the best of our knowledge, our work is the first to generate psychological consultation dialogues based on psychological counseling reports, which effectively expands the source of psychological consultation dialogue data. For efficient dialogue reconstruction, we specifically introduce a two-phase method named Memo2Demo.\n\nWith the help of Memo2Demo, we construct CPsyCounD, a dataset containing 3,134 high-quality multi-turn consultation dialogues. The model CPsyCounX fine-tuned on this dataset outperforms other models in the benchmark, validating the effectiveness of our proposed framework in psychological counseling."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Dialogue Generation and Reconstruction using LLMs",
            "text": "Dialogue generation and reconstruction using LLMs have been proven to be effective in data augmentation and conversation denoising. For example, SAFARI Wang et al. (2023a) harnesses the planning and understanding capabilities of LLMs to generate persona-consistent and knowledge-enhanced responses. In the medical domain, DISC-MedLLM Bao et al. (2023) undertakes real-world dialogue reconstruction for consultation records sourced from medical forums. This process addresses issues of informal language usage and unregulated expressive styles. In the realm of psychology, numerous studies concentrate on augmenting emotional support capability by enhancing empathy.Qian et al. (2023) amplifies empathetic responses by enriching the dialogue context with a commonsense knowledge graph, thereby stimulating the relevant knowledge encoded by LLMs. In this work, we propose a two-phase method for efficient dialogue reconstruction."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Evaluation of Generated Dialogues using LLMs",
            "text": "The search for better automatic evaluation metrics in natural language generation (NLG) has been a hot topic for the natural language processing (NLP) community. Compared to conventional lexicon-based metrics like BLEU Papineni et al. (2002 ###reference_b15###) and Rouge Lin (2004 ###reference_b10###), these new metrics capture deeper semantic meaning and usually have better alignment with human judgments. There have been a series of transformer-based evaluation metrics available in the community, such as BERTScore Zhang et al. (2020 ###reference_b31###), BARTScore Yuan et al. (2021 ###reference_b29###) and GPTScore Fu et al. (2023 ###reference_b8###). In specific domains, there are also derivatives of such metrics tailored for the domain. For example, CodeBERTScore Zhou et al. (2023 ###reference_b32###) is proposed to achieve a higher correlation with human preference and with functional correctness. CBERTScore Shor et al. (2023 ###reference_b20###) can penalize clinically-relevant mistakes more than others. The same trend continues with LLMs. Wang et al. (2023b ###reference_b26###) shows that ChatGPT achieves state-of-the-art or competitive correlation with human judgments in most cases. A new framework constructed over GPT-4 called G-Eval Liu et al. (2023b ###reference_b13###) makes use of LLMs with chain-of-thoughts (CoT) and a form-filling paradigm to assess the quality of NLG outputs, outperforming all previous methods by a large margin. In this work, we design a psychological counseling benchmark for automatic evaluation."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "CPsyCoun",
            "text": "Considering the differences in data sources of our collection, we need to reformat these collected reports according to a uniform standard. We combine the case format of China’s National Class 2 Psychological Counselor Examination and other psychological counseling literature to regularize collected reports, where the following 6 components are included: Title, Type, Method, Case Brief, Consultation Process and Experience Thoughts. Note that the consultation process is written from a third-person perspective and does not contain specific dialog. For a detailed description of components and examples of psychological counseling report, please refer to Appendix A  ###reference_###. According to statistics, there are about 230 types of psychological counseling cases and more than 250 counseling methods used in psychological counseling. Considering that the classification of the original types is too detailed, we further summarized the case types into 9 representative topics based on common scenarios of psychological counseling. The distribution of counseling topics is shown in Figure 2a  ###reference_sf1###. Based on relevant information from the American Psychological Association (APA) and the International Academy of Psychotherapy (IACP), we have categorized the professional counselor’s methods utilized in psychological counseling reports into 7 classic schools of psychological counseling. The distribution of methods is shown in Figure 2b  ###reference_sf2###. Direct role-play prompting is utilized as our baseline method for generating multiple rounds of dialogue from a single round, which has been successfully used in previous work on dialogue generation Qiu et al. (2023  ###reference_b18###); Chen et al. (2023b  ###reference_b5###). However, we believe that there are still aspects for improvement when applying direct role-play prompting to multi-round dialogue generation in the field of psychological counseling: (2) Professionalism: Role-playing prompted dialogues merely reference psychological methods in generated dialogues. We hope that language models could integrate these methods into the problem-solving process, thereby obtaining reconstructed dialogue with professionalism. (3) Authenticity: Dialogue constructed by the baseline method lacks the emotional interaction between the client and the psychological counselor present in real scenarios, leaving a deficit in terms of authenticity. We present the detailed prompt of role-play method in Figure 6  ###reference_### in the appendix. To address the aforementioned issues of the baseline method, we propose a two-phase framework named Memo2Demo to generate high-quality psychological consultation dialogue from counseling reports. Mirroring real-life scenarios, we incorporate two key roles into this framework: a psychological supervisor together with a psychological counselor. The psychological supervisor guides the psychological counselor on counseling techniques while ensuring the privacy of the clients during the counseling process. Meanwhile, the psychological counselor engages in direct dialogue with the clients to conduct specific psychological counseling. Figure 3  ###reference_### illustrates the general framework of our proposed method Memo2Demo, where a psychological counseling report is first converted into a counseling note by the psychological supervisor, then the psychological counselor generates the multi-turn consultation dialogue based on both the report and the note. We present detailed prompts used for Memo2Demo in Figure 7  ###reference_### and 8  ###reference_### in the appendix. In psychological counseling, the evaluation metrics remain diverse and not universally standardized. For instance, SoulChat Chen et al. (2023b  ###reference_b5###) proposes evaluation metrics: Content, Empathy, Helpfulness and Safety. Some of these metrics hinge on expert evaluations and lack specific scoring criteria, favoring manual rather than objective and automatic evaluations. Similarly, ChatCounselor Liu et al. (2023a  ###reference_b11###) introduces the Counseling Bench, encompassing seven different perspectives. While these metrics are designed to cater to the model’s specific dialogue strategies, they lack the ability to evaluate the overall dialogue effect. They are more adapted to single-round dialogue evaluations and are not suitable for multi-turn dialogues. We propose a turn-based dialogue evaluation approach to effectively evaluate multi-turn consultation dialogues. Denote a -turn dialogue as a set of paired elements , where each  represents a query from the client, and each corresponding  represents the counselor’s reply. We first split it into  single-turn dialogue, then prompt the model with query together with its dialogue history in each single-turn dialogue, resulting in the corresponding single-turn response: where  signifies the dialogue history before -th turn, and  denotes the inference process of LLMs. To automatically obtain reliable evaluation results, We employ GPT-4 Achiam et al. (2023  ###reference_b1###) to assess these responses, utilizing the evaluation metrics we previously proposed. Concretely, we ask the model to assign an evaluation score  for a single-turn response . Then we average them to yield the total evaluation score of the current -turn dialogue: For detailed prompts of single-turn response generation, please refer to Figure 11  ###reference_### in the appendix. SMILECHAT Qiu et al. (2023  ###reference_b18###), a richly"
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Data Collection",
            "text": "We conduct a survey of publicly available psychological counseling cases online and collect data from well-known Chinese psychological communities. The online communities used in this work are: (1) Yidianling, a top-tier mental health platform in China, serving approximately 39 million users, backed by a robust network of over 6,000 professional counselors. (2) Psy525, another prominent mental health platform in China, catering to over 1 million users and supported by nearly 30,000 professional counselors. As the data are anonymized by the websites, there’s a low privacy risk. To enhance the security of the collected data, we further conduct an analysis of privacy and security issues about the data. The procedures adopted during data collecting to ensure no sensitive or privacy-related content in the dataset include rule-based cleaning, manual rewriting, and human proofreading. After cleaning procedures, relevant private information has been completely removed, and we ensure that relevant private information is protected."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Data Processing",
            "text": "To construct a high-quality dataset, we carefully selected 3,134 psychological counseling reports. They contain complete methods and types, clear case briefs, detailed consultation processes, and experience thoughts. In the selection process, we found that some of the collected reports contained several counseling cases in one report. We did not select this type of report due to multiple cases in one report where the background information of the client and the consultation processes are incomplete. Therefore, among the selected 3,134 psychological counseling reports, each report corresponds to only one case. This high-quality report dataset is named CPsyCounR.\n\nConsidering the differences in data sources of our collection, we need to reformat these collected reports according to a uniform standard. We combine the case format of China’s National Class 2 Psychological Counselor Examination and other psychological counseling literature to regularize collected reports, where the following 6 components are included: Title, Type, Method, Case Brief, Consultation Process, and Experience Thoughts. Note that the consultation process is written from a third-person perspective and does not contain specific dialogue.\n\nAccording to statistics, there are about 230 types of psychological counseling cases and more than 250 counseling methods used in psychological counseling. Considering that the classification of the original types is too detailed, we further summarized the case types into 9 representative topics based on common scenarios of psychological counseling. The distribution of counseling topics is shown in Figure 2a.\n\nBased on relevant information from the American Psychological Association (APA) and the International Academy of Psychotherapy (IACP), we have categorized the professional counselor’s methods utilized in psychological counseling reports into 7 classic schools of psychological counseling. The distribution of methods is shown in Figure 2b."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Dialogue Generation Method for Psychological Counseling",
            "text": "Direct role-play prompting is utilized as our baseline method for generating multiple rounds of dialogue from a single round, which has been successfully used in previous work on dialogue generation Qiu et al. (2023); Chen et al. (2023b). However, we believe that there are still aspects for improvement when applying direct role-play prompting to multi-round dialogue generation in the field of psychological counseling:\n\n(1) Professionalism: Role-playing prompted dialogues merely reference psychological methods in generated dialogues. We hope that language models could integrate these methods into the problem-solving process, thereby obtaining reconstructed dialogue with professionalism.\n\n(2) Authenticity: Dialogue constructed by the baseline method lacks the emotional interaction between the client and the psychological counselor present in real scenarios, leaving a deficit in terms of authenticity.\n\nWe present the detailed prompt of role-play method in Figure 6 in the appendix.\n\nTo address the aforementioned issues of the baseline method, we propose a two-phase framework named Memo2Demo to generate high-quality psychological consultation dialogue from counseling reports. Mirroring real-life scenarios, we incorporate two key roles into this framework: a psychological supervisor together with a psychological counselor. The psychological supervisor guides the psychological counselor on counseling techniques while ensuring the privacy of the clients during the counseling process. Meanwhile, the psychological counselor engages in direct dialogue with the clients to conduct specific psychological counseling. Figure 3 illustrates the general framework of our proposed method Memo2Demo, where a psychological counseling report is first converted into a counseling note by the psychological supervisor, then the psychological counselor generates the multi-turn consultation dialogue based on both the report and the note. We present detailed prompts used for Memo2Demo in Figures 7 and 8 in the appendix."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Automatic Evaluation of LLM-based Psychological Counseling",
            "text": "In the field of psychological counseling, assessing the quality of multi-turn consultation dialogues has always been a challenging task. Despite having successfully generated high-quality counseling dialogues from case reports using Memo2Demo, we still need to verify the impact of these dialogues on subsequent tasks. To this end, we elect to utilize CPsyCounD for supervised fine-tuning on publicly accessible LLMs. This allows us to assess the changes in the psychological counseling competency before and after the use of data.\n\nNonetheless, the multi-turn consultation dialogue that characterizes the psychological counseling process is complex to evaluate without the input of human experts. To address this, we first introduce evaluation metrics tailored for multi-turn consultation dialogue. Then a turn-based dialogue evaluation method is proposed for automatic evaluation of the psychological counseling process.\n\nIn psychological counseling, the evaluation metrics remain diverse and not universally standardized. For instance, SoulChat Chen et al. proposes evaluation metrics: Content, Empathy, Helpfulness and Safety. Some of these metrics hinge on expert evaluations and lack specific scoring criteria, favoring manual rather than objective and automatic evaluations. Similarly, ChatCounselor Liu et al. introduces the Counseling Bench, encompassing seven different perspectives. While these metrics are designed to cater to the model’s specific dialogue strategies, they lack the ability to evaluate the overall dialogue effect. They are more adapted to single-round dialogue evaluations and are not suitable for multi-turn dialogues.\n\nRecognizing the aforementioned limitations in evaluating consultation dialogues, and in order to analyze the counseling case used for dialogue generation, we propose new evaluation metrics for multi-turn consultation dialogues in psychological counseling. These metrics encompass different perspectives: Professionalism, Authenticity, and Safety, which are used for automatic evaluation in the rest of this paper. For each perspective, we give its description and corresponding score criterion in Appendix C.\n\nWe propose a turn-based dialogue evaluation approach to effectively evaluate multi-turn consultation dialogues. Denote a -turn dialogue as a set of paired elements, where each represents a query from the client, and each corresponding represents the counselor’s reply. We first split it into single-turn dialogue, then prompt the model with query together with its dialogue history in each single-turn dialogue, resulting in the corresponding single-turn response: where signifies the dialogue history before -th turn, and denotes the inference process of LLMs. To automatically obtain reliable evaluation results, we employ GPT-4 to assess these responses, utilizing the evaluation metrics we previously proposed. Concretely, we ask the model to assign an evaluation score for a single-turn response. Then we average them to yield the total evaluation score of the current -turn dialogue. For detailed prompts of single-turn response generation, please refer to Figure 11 in the appendix.\n\nSMILECHAT, a richly diverse and realistic multi-turn dialogue dataset, comprises 56k multi-turn counseling dialogues, averaging 6.36 rounds per dialogue. Given its wide range of dialogue types, we choose it as our base dataset. However, the open-source data of this dataset is not classified by topic type.\n\nTo address this limitation and conduct a more explainable evaluation of models’ capabilities, we construct a general multi-turn dialogue evaluation dataset with clear topic classification - CPsyCounE. Leveraging the nine common counseling topics we introduce in CPsyCounR, we manually select the five most representative dialogues from SMILECHAT for each topic, resulting in an evaluation dataset of 45 cases."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "To delve deeper into whether the proposed dataset can effectively enhance the psychological counseling capabilities of LLMs, we further fine-tune InternLM2-7B-Chat Team (2023) on CPsyCounD and derive a chat model CPsyCounX tailored specifically for psychological counseling. CPsyCounX is fine-tuning for 9 epochs with the batch size set to 448, and the learning rate set to. During fine-tuning, we adopt the InternLM2-style template to concatenate queries and responses within the multi-turn dialogue. The turn-based dialogue evaluation method is adopted on CPsyCounE for the following extrinsic evaluation. We include InternLM2-7B-Chat Team (2023), SoulChat Chen et al. (2023b), ChatGPT, and GLM-4 Zeng et al. (2023) as major baseline models. The evaluation standard refers to the evaluation metrics in Table 4 in the appendix. To accommodate multi-turn dialogues, we adjust the authenticity criterion accordingly. For detailed evaluation prompts, please refer to Figure 10 in the appendix. We present the overall results of extrinsic evaluation on CPsyCoun in Table 3, where CPsyCounX surpasses other models in terms of Professionalism and Authenticity. Figure 4 further shows detailed scores of CPsyCounX and other baselines, where CPsyCounX significantly outperforms nearly all other baselines on Professionalism, demonstrating the efficacy of the proposed method Memo2Demo. While judging by the topic distribution, CPsyCounX leads in all metrics in the topic \"Mental Disease,\" demonstrating its high usability in the field of psychological counseling. For full results, please refer to Appendix E. These results highlight that fine-tuning on CPsyCounD enables the model to naturally acquire professional psychological counseling techniques used in counseling dialogues. Moreover, the model can learn the conversational style of psychological counselors in real-life psychological counseling scenarios, ensuring the dialogue’s authenticity."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "CPsyCounD",
            "text": "To validate the effectiveness of our proposed dialogue reconstruction approach, we adopt direct role-play prompting and Memo2Demo to generate dialogues from CPsyCounR respectively. We denote the set of dialogues generated by Memo2Demo as CPsyCounD, which has a total of 3,134 multi-turn consultation dialogues, covering nine topics and seven classic schools of psychological counseling. For statistical information, please refer to Table 1."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Intrinsic Evaluation of CPsyCoun",
            "text": "Then we adopt direct role-play prompting and Memo2Demo method respectively for dialogue generation, and instruct GPT-4 Achiam et al. (2023) to conduct a comparative evaluation of the above two multi-turn consultation dialogues. The evaluation standard refers to the evaluation metrics shows in Table 4. For detailed evaluation prompts, please refer to Figure 9 in the appendix. Table 2 illustrates the results of intrinsic evaluation on CPsyCoun. For each school, Memo2Demo method outperforms direct role-play prompting in terms of Professionalism and Authenticity. Note that both methods get full scores in Safety, which shows the advantage of report-based data construction methods for privacy protection. In general, our proposed method Memo2Demo significantly enhances the quality of reconstructed multi-turn consultation dialogues."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Extrinsic Evaluation of CPsyCoun",
            "text": "To delve deeper into whether the proposed dataset can effectively enhance the psychological counseling capabilities of LLMs, we further fine-tune InternLM2-7B-Chat Team (2023 ###reference_b22### ###reference_b22###) on CPsyCounD and derive a chat model CPsyCounX tailored specifically for psychological counseling. CPsyCounX is fine-tuning for 9 epochs with the batch size set to 448, and the learning rate set to . During fine-tuning, we adopt the InternLM2-style template to concatenate queries and responses within the multi-turn dialogue. ###figure_8### ###figure_9### ###figure_10### The turn-based dialogue evaluation method is adopted on CPsyCounE for the following extrinsic evaluation. We include InternLM2-7B-Chat Team (2023 ###reference_b22### ###reference_b22###), SoulChat Chen et al. (2023b ###reference_b5### ###reference_b5###), ChatGPT and GLM-4 Zeng et al. (2023 ###reference_b30### ###reference_b30###) as major baseline models. The evaluation standard refers to the evaluation metrics in Table 4 ###reference_### ###reference_### in the appendix. To accommodate multi-turn dialogues, we adjust the authenticity criterion accordingly. For detailed evaluation prompts, please refer to Figure 10 ###reference_### ###reference_### in the appendix. We present the overall results of extrinsic evaluation on CPsyCoun in Table 3 ###reference_### ###reference_###, where CPsyCounX surpasses other models in terms of Professionalism and Authenticity. Figure 4 ###reference_### ###reference_### further shows detailed scores of CPsyCounX and other baselines, where CPsyCounX significantly outperforms nearly all other baselines on Professionalism, demonstrating the efficacy of proposed method Memo2Demo. While judging by the topic distribution, CPsyCounX leads in all metrics in the topic \"Mental Disease\", demonstrating its high usability in the field of psychological counseling. For full results, please refer to Appendix E ###reference_### ###reference_###. These results highlight that fine-tuning on CPsyCounD enables the model to naturally acquire professional psychological counseling techniques used in counseling dialogues. Moreover, the model can learn the conversational style of psychological counselors in real-life psychological counseling scenarios, ensuring the dialogue’s authenticity."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we introduce CPsyCoun, an innovative framework for report-based multi-turn dialogue reconstruction and evaluation in Chinese psychological counseling. Our research encompasses data collection, effective data construction methods, and domain evaluation benchmarks.\n\nTo harness the full potential of psychological counseling reports, we design a two-phase approach to construct high-quality consultation dialogues. \n\nExperimental results validate the effectiveness of our proposed framework, demonstrating its superiority in building a professional and authentic psychological counseling assistant. All datasets and model weights developed in this paper are publicly available.\n\nFor future work, a more refined balance between authenticity and professional knowledge in dialogue generation needs to be achieved. We aspire this work will furnish fresh perspectives and references for the development of LLMs in the field of psychological counseling."
        }
    ]
}