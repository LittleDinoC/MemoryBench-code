{
    "title": "Uni-SMART: Universal Science Multimodal Analysis and Research Transformer",
    "abstract": "In scientific research and its application, scientific literature analysis is crucial as it allows researchers to build on the work of others. However, the fast growth of scientific knowledge has led to a massive increase in scholarly articles, making in-depth literature analysis increasingly challenging and time-consuming.\nThe emergence of Large Language Models (LLMs) has offered a new way to address this challenge. Known for their strong abilities in summarizing texts, LLMs are seen as a potential tool to improve the analysis of scientific literature. However, existing LLMs have their own limits. Scientific literature often includes a wide range of multimodal elements, such as tables, charts, and molecule, which are hard for text-focused LLMs to understand and analyze. This issue points to the urgent need for new solutions that can fully understand and analyze multimodal content in scientific literature. To answer this demand, we present Uni-SMART (Universal Science Multimodal Analysis and Research Transformer), an innovative model designed for in-depth understanding of multimodal scientific literature. Through rigorous quantitative evaluation across several domains, Uni-SMART demonstrates superior performance over other text-focused LLMs. Furthermore, our exploration extends to practical applications, including patent infringement detection and nuanced analysis of charts. These applications not only highlight Uni-SMART’s adaptability but also its potential to revolutionize how we interact with scientific literature.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Scientific literature, encompassing patents and academic papers, constitutes a rich science data resource, including but not limited to drug properties and activities, reaction pathways, and manufacturing processes.\nHowever, extracting target information from this extensive corpus is a laborious and time-intensive task.\nIt necessitates meticulous manual review, analysis, and extraction – processes that are inherently slow and prone to human error [1  ###reference_b1###, 2  ###reference_b2###].\nTo enhance the efficiency of information retrieval, specialized databases like Sci-Finder [3  ###reference_b3###] and Reaxys [4  ###reference_b4###] have been developed.\nHowever, their utility is constrained to document retrieval for molecule and reaction queries, lacking the capabilities of information extraction and knowledge comprehension to function as domain assistants.\nConsequently, users must still engage in the tedious tasks of reading and analyzing the retrieved documents to extract definitive answers.\nThis limitation poses a significant bottleneck in the utilization of scientific data, hindering research progress and the rapid application of discoveries.\nThus, researchers and practitioners require an intelligent navigator that can swiftly guide through the complexities of the latest scientific data, identify relevant information with precision, and present it in a digestible format.\n###figure_1### The emergence of Large Language Models (LLMs), represented by LLaMA [5  ###reference_b5###], Gemini [6  ###reference_b6###], and GPT [7  ###reference_b7###, 8  ###reference_b8###, 9  ###reference_b9###], has marked a significant milestone in the evolution of natural language processing.\nThese models have revolutionized the extraction of textual information from documents, enabling direct responses to queries using the extracted content.\nDespite their proficiency, current LLMs are primarily designed for text extraction and often struggle with the multimodal aspects inherent in scientific literature, which include a large number of tables, charts, and reactions.\nThe extraction and interpretation of such multimodal data require an understanding that beyond texts and delves into visual and structural contents.\nTo address these challenges, we developed Uni-SMART (Universal Science Multimodal Analysis and Research Transformer), which extends the capabilities of LLMs beyond text, allowing for the interpretation of the multimodal content that is crucial in scientific literature.\nAs illustrated in Figure 1  ###reference_###, it is designed to recognize and analyze multimodal data, such as molecule structures, chemical reactions, charts, and tables, alongside textual content, facilitating a comprehensive understanding of scientific literature.\nSuch ability not only augments automated and precise information extraction but also enriches the interaction between researchers and the vast expanse of scientific knowledge.\nTo rigorously assess the multimodal capabilities of Uni-SMART, a comparative analysis was conducted against several LLMs, such as GPT-4o, Gemini, and Claude3.\nOur assessment targets several data types critical to the comprehension of scientific documents: tables, charts, molecular structures, and chemical reactions.\nThe results demonstrate Uni-SMART’s superior performance in all tested areas, especially in understanding and analyzing complex multimodal contents, thus highlighting its potential as a helpful assistant for scientific literature analysis.\nIn the following sections, Section 2  ###reference_### details Uni-SMART’s data sources and iterative training approach.\nSubsequently, Section 3  ###reference_### – Evaluation, presents detailed comparisons of Uni-SMART with several LLMs across a variety of modalities, showcasing its advanced capabilities in multimodal data interpretation.\nThen, Section 4  ###reference_### – Application showcases some specific applications of Uni-SMART in the scientific domain.\nFinally, Section 5  ###reference_### discusses Uni-SMART’s limitations and future research avenues, along with its potential impact on scientific research and technological advancement."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Method",
            "text": "As depicted in Figure 2  ###reference_###, Uni-SMART sources training data from a wide range of scientific literature from global patents, news articles, scientific publications, and market reports.\nIn particular, It adopts a cyclical, iterative approach to enhance its multimodal understanding capabilities, comprising the following key components:\nMultimodal Learning: During the initialization phase, the parsing model is trained with a limited set of multimodal data to recognize and extract diverse information elements from scientific literature. The output is formatted in a custom text format, similar to html format, to effectively represent multimodal elements.\nLLM SFT: A series of valuable queries are constructed, particularly in multimodal scenarios. With Multimodal Retrieval-Augmented Generation (RAG), relevant content is recalled from the literature based on queries. Answers are built based on the queries and retrieved content. The query-answer data is then used to fine-tune the LLM. This process helps the LLM adapt to the custom input format and improves its ability to follow instructions.\nUser Feedback: The parsing model and SFT-enhanced LLM are deployed in real applications, facilitating the collection of user feedback.\nSamples receiving positive feedback are subsequently filtered and incorporated into the data enhancement, while those with negative feedback are subject to expert annotation before being integrated into the data enhancement process.\nExpert Annotation: Samples with negative feedback are carefully annotated by human experts. This step ensures that these models learns from their mistakes, with semi-automated tools assisting in this process to enhance efficiency.\nNegative feedback cases typically fall into the following categories:\nMultimodal element recognition errors;\nRecall content errors;\nPoor instruction-following.\nDetailed analysis of these error types facilitates targeted improvements.\nData Enhancement: Finally, the annotated data, along with partial samples that received positive feedback, are added to the training dataset for data enhancement. The pipeline is optimized based on different types of negative feedback:\nMultimodal element recognition errors: expand the training data for the parsing model;\nRecall content errors: optimize the Multimodal RAG scheme;\nPoor instruction-following: enlarge and refine the dataset used for LLM SFT.\nThis iterative process is repeated to continually optimize Uni-SMART’s overall performance. And significantly enhances Uni-SMART’s performance in a variety of challenging tasks, such as information extraction, complex element identification, scientific literature understanding/analysis, and multimodal understanding/reasoning.\n###figure_2###"
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Evaluation",
            "text": "In this section, we perform a detailed quantitative evaluation on the capabilities of Uni-SMART and various available LLMs across modalities.\nTable 1  ###reference_### presents the statistics of the benchmarks.\nFor details of the specific evaluation tasks, please refer to SciAssess [10  ###reference_b10###].\nFor our experiments, different methods are employed depending on the source of the models. Closed-source models are accessed via API calls, while open-source models are obtained from Hugging Face, deployed, and tested. Evaluation tasks that require an article as context involve converting the PDF content to text for input into the LLMs. If an LLM offers a built-in PDF parsing interface, we utilize this feature; otherwise, PyPDF2 is used for PDF parsing. Notably, Uni-SMART can directly read PDF files, allowing us to upload the original documents and pose questions directly to the model.\nDue to input length limitations of the LLMs, tasks that require the full text of an article as context are executed in a zero-shot manner, whereas tasks that do not require such extensive context are tested using few-shot approaches.\nThe final results of these experiments are systematically presented in Table 2  ###reference_###, illustrating the performance of each model across the evaluated tasks."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Table",
            "text": "Tables play a pivotal role in scientific literature, presenting complex data and findings in a highly structured manner and thereby contributing significantly to scientific discovery and the dissemination of knowledge [11  ###reference_b11###]. They facilitate the intuitive display of experimental data and enable the efficient summarization and comparison of research outcomes, becoming an indispensable component of scientific investigation. Consequently, enhancing the capability to understand tables is crucial for the automated processing and analysis of scientific documents. The utilization of table data spans a wide array of applications, such as trend analysis, which can reveal developmental trajectories in research fields, and comparative studies, which can elucidate differences in experimental outcomes under varying research methodologies or conditions [12  ###reference_b12###].\nTo assess the table understanding capabilities of our model, Uni-SMART, compared to other\nLLMs, we designed a diverse set of tasks across different domains. These tasks were specifically tailored to evaluate how well each model could interpret and extract information from tables.\nIn our thorough assessment, the Uni-SMART showcased its exceptional proficiency in understanding and extracting table data from the scientific literature.\nAmong six assessed tasks, it surpassed other models in five and delivered a competitive performance in the remainder.\nNotably, in the \"Composition Extraction\" and \"Solubility Extraction\" tasks, Uni-SMART achieved \"Table Recall\" of 0.511 and 0.468, respectively, significantly outperforming its counterparts.\nThe objectives of these two tasks are to extract necessary information from tables within articles and organize it into a specified format. These results indicate that Uni-SMART excels in handling and understanding tabular data, particularly in information extraction and formatting tasks.\nHowever, in the Electrolyte Table QA task, Uni-SMART’s performance was slightly below the state-of-the-art model (GPT-4o). In this task, LLMs are required to answer questions about details in the table with the question type of multiple-choice, indicating that Uni-SMART still has room for improvement in understanding the details within tables.\nMoreover, all models under-performed in the \"Affinity Extraction\" task, indicating the high complexity of these tasks.\nThis task requires LLMs to organize molecules and corresponding experimental result from articles. It necessitates the model’s ability to integrate molecules with table information and demands strong long-context understanding capabilities. To better address these issues in the future, a possible direction is to enhance LLMs’ abilities in long context comprehension and information matching."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Chart",
            "text": "Charts are essential tools in scientific literature, offering a visual representation of data that can significantly enhance the comprehension and communication of complex information. By succinctly illustrating trends, comparisons, and patterns, charts enable researchers to convey their findings more effectively and intuitively [13  ###reference_b13###]. Therefore, the ability to accurately interpret and analyze charts is vital for the automated processing and understanding of scientific documents.\nTo assess the chart interpretation capabilities of Uni-SMART, we conducted a series of ChartQA tasks spanning various scientific domains. These tasks rigorously evaluated models’ ability to analyze and clarify data presented in charts, with a particular focus on identifying trends and extracting meaningful insights.\nAnalysis of the results presented in Figure 3  ###reference_### indicates that Uni-SMART significantly outperforms existing models in Chart QA tasks across diverse scientific domains, particularly excelling in the tasks of Alloy Chart QA and Drug Chart QA, with leading scores of 0.933 and 0.600, respectively.\nHowever, both in the Biology Chart QA, where the Gemini model scored 0.616, and in the Polymer Chart QA task, where Qwen2 also achieved a top score of 0.933—matching Uni-SMART’s performance in both cases—it is evident that these models have strong capabilities in analyzing scientific charts.\nThese results underscore the intense competition among different models in the context of chart understanding. The future direction for development likely focuses on enhancing accuracy and applicability across various scientific domains."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Molecule",
            "text": "In scientific literature, molecule or molecular structures hold fundamental importance, especially within fields such as chemistry, pharmacology, and biology.\nComprehending molecular structures is crucial for analyzing research outcomes, predicting chemical behaviors, and innovating novel compounds [14  ###reference_b14###, 15  ###reference_b15###].\nDeciphering the molecular structure of a newly discovered drug compound, for instance, can provide essential insights into its therapeutic potential and biological interactions, which is crucial for enhancing our understanding of related scientific literature.\nTo evaluate our model’s ability to understand molecular structures, we carried out a series of tasks involving molecules, polymers, and Markush structures, which are common in chemistry and medicine studies.\nThese tasks were designed to assess the model’s capability in deciphering information from representations of molecular structures.\nThe Uni-SMART model showed outstanding performance in molecular structure understanding tasks, particularly in processing complex molecular structures within the scientific literature.\nFor example, in the \"Molecule in Document\" task, Uni-SMART achieved an accuracy of 0.720, significantly outperforming other models. This task requires LLMs to determine whether a molecular structure has appeared in the literature, demonstrating Uni-SMART’s strong capabilities in accurate molecule identification and information retrieval.\nSuch achievements highlight Uni-SMART’s considerable advantage in parsing molecular structure, potentially attributed to its access to richer, more specialized training data sources, effective preprocessing of molecular structure, and architecture designed specifically for multimodal data.\nDespite these strengths, there remains room for improvement in Uni-SMART’s comprehension of molecular structure.\nFuture enhancements may include strengthening the model’s understanding of molecule details and expanding the training dataset to encompass a broader range of molecule types.\nThese efforts are expected to further augment Uni-SMART’s applicability in reading and interpreting scientific literature, especially those involving molecular structure."
        },
        {
            "section_id": "3.4",
            "parent_section_id": "3",
            "section_name": "Chemical Reactions",
            "text": "Understanding chemical reactions is crucial in scientific literature, particularly within chemistry and its related disciplines [16  ###reference_b16###].\nThe ability to accurately parse and analyze the details of chemical reactions enhances readers’ grasp of complex material, enabling a deeper understanding of experimental results and theoretical discussions.\nTo assess Uni-SMART’s capability to comprehend chemical reactions, we designed two tasks aimed at challenging the model’s proficiency in interpreting chemical reactions.\nThese tasks focus on understanding the reactants, products, and conditions of chemical reactions, as well as grasping the underlying mechanisms and clarifying the significance of these reactions within a broader scientific context.\nUni-SMART exhibited outstanding performance in \"Reaction QA\" task, achieving an accuracy of 0.768.\nHowever, in the \"Reaction Mechanism QA\" task, Uni-SMART’s performance was slightly below that of the Gemini.\nThis task requires LLMs to accurately parse and interpret the step-by-step mechanisms of chemical reactions from the article, indicating that Uni-SMART still has room for improvement in understanding complex reactions.\n###figure_3###"
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Application",
            "text": "In today’s research and industrial domains, the correct understanding and application of patent information have become increasingly crucial, especially in the fields of physics and drug development."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Patent infringement analysis",
            "text": "In today’s research and industrial domains, the correct understanding and application of patent information have become increasingly crucial, especially in the fields of physics and drug development."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Chart analysis",
            "text": "In today’s research and industrial domains, the correct understanding and application of patent information have become increasingly crucial, especially in the fields of physics and drug development."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Discussion and Conclusion",
            "text": "In this report, we introduce Uni-SMART for in-depth understanding of multimodal information within the scientific literature. Through rigorous quantitative evaluation, Uni-SMART demonstrates significant performance gain in interpreting and analyzing multimodal contents in scientific documents, such as tables, charts, molecular structures, and chemical reactions, compared with other competitors.\nThe success of Uni-SMART lies in its innovative cyclic iterative process that continuously refines its multimodal understanding capabilities, leveraging a robust dataset and a combination of multimodal learning, supervised fine-tuning, user feedback, expert annotation, and data enhancement to achieve superior performance in scientific literature analysis.\nBeyond quantitative assessment, we are particularly excited about Uni-SMART’s potential to address scientific challenges through practical applications.\nFrom patent infringement analysis to complex material science chart interpretation, Uni-SMART’s cross-modal understanding capabilities offer new perspectives and tools for research and technological development, showcasing its potential to facilitate research processes and accelerate discovery phases.\nDespite Uni-SMART’s strong ability in multimodal scientific literature understanding, we acknowledge that there is still room for improvement.\nThis includes enhancing the model’s understanding of highly complex and specialized content, as well as reducing hallucinations.\nWe believe that through continuous research and development, these limitations will be addressed, making Uni-SMART an even more powerful and flexible tool for scientific research assistance.\nIn summary, the research and development of Uni-SMART mark a significant advancement in the field of multimodal scientific literature understanding.\nBy providing scientists and researchers with an efficient tool for deep understanding and analysis of scientific documents, Uni-SMART not only facilitates the accumulation and innovation of scientific knowledge but also paves the way for future scientific work, technological development, and potential commercial applications.\nAs we continue to improve and expand Uni-SMART, we look forward to its greater role in promoting scientific discovery and technological innovation."
        }
    ]
}