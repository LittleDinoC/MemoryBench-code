{
    "title": "Investigating LLM’s Value Inclination on the Perspective of Age",
    "abstract": "In this paper, we explore the alignment of values in Large Language Models (LLMs) with specific age groups, leveraging data from the World Value Survey across thirteen categories.\nThrough a diverse set of prompts tailored to ensure response robustness, we find a general inclination of LLM values towards younger demographics, especially in the US.\nAdditionally, we explore the impact of incorporating age identity information in prompts and observe challenges in mitigating value discrepancies with different age cohorts. Our findings highlight the age bias in LLMs and provide insights for future work. Materials for our analysis will be available via anonymous.github.com",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Widely used Large Language Models (LLMs) should be reflective of all age groups Dwivedi et al. (2021  ###reference_b9###); Wang et al. (2019  ###reference_b29###); Hong et al. (2023  ###reference_b12###).\nAge statistics estimate that by 2030, 44.8% of the US population will be over 45 years old Vespa et al. (2018  ###reference_b28###), and one in six people worldwide will be aged 60 years or over World Health Organization (2022  ###reference_b30###).\nAnalyzing how the values (e.g, religious values) in LLMs align with different age groups can enhance our understanding of the experience that users of different ages have with an LLM.\nFor instance, for an older group that may exhibit less inclination towards new technologies Czaja et al. (2006  ###reference_b6###); Colley and Comber (2003  ###reference_b5###), an LLM that embodies the values of a tech-savvy individual may lead to less empathetic interactions.\nMinimizing the value disparities between LLMs and the older population has the potential to lead to better communication between these demographics and the digital products they engage with.\n###figure_1### In this paper, we investigate whether and which values in LLMs are more aligned with specific age groups. Specifically, by using the World Value Survey Haerpfer et al. (2020  ###reference_b10###), we prompt various LLMs to elicit their values on thirteen categories, employing eight format variations in prompts for robust testing. We observe a general inclination of LLM values towards younger demographics, as shown in Fig 1  ###reference_###. We also demonstrate the specific categories of value and example inquiries where LLMs exhibit such age preferences (See Sec 4  ###reference_###).\nFurthermore, we study the effect of adding age identity information when prompting LLMs. Specifically, we instruct LLMs to use an age and country identity before requesting their responses. Surprisingly, we find that adding age identity fails to eliminate the value discrepancies with targeted age groups on eight out of thirteen categories (see Fig 4  ###reference_###), despite occasional success in specific instances (See Sec 5  ###reference_###).\nWe advocate for increased awareness within the research community regarding the potential age bias inherent in LLMs, particularly concerning their predisposition towards certain values. We also emphasize the complexities involved in calibrating prompts to effectively address this bias."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": "Despite extensive scrutiny on LLM bias Santurkar et al. (2023  ###reference_b23###); Sun et al. (2023  ###reference_b25###), the gender-related preferences of LLMs remain less explored."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Analytic Method",
            "text": "We derive human values utilizing the 7th wave of the World Values Survey (WVS) Haerpfer et al. (2020  ###reference_b10###).\nThe survey systematically probes 94k individuals globally on 13 categories, covering a range of social, political, economic, religious, and cultural values. See an introduction of WVS in Appx A  ###reference_###. Each inquiry is a single-choice question. Responses are numeric, quantifying the inclination on the options, e.g., “1:Strongly agree, 2:Agree, 3:Disagree, 4:Strongly disagree\". Negative number is possible for coding exceptions such as “I don’t know\".\nTo assess human values, we group the respondents by age group 111Age groups are recorded as 18-24, 25-34, 35-44, 45-54, 55-64, and 65+ and country. Subsequently, we compute the average values for each age group and country to represent their respective cohorts, ignoring the invalid negative numbers.\nWe conduct our analysis on six LLMs, as introduced in Tab 1  ###reference_###.\n* 0\n###figure_4### * 0\n###figure_5### * 0\n###figure_6### * 0\n###figure_7### * 0\n###figure_8### * 0\n###figure_9### * 0\n###figure_10### * 0\n###figure_11### * 0\n###figure_12### * 0\n###figure_13### * 0\n###figure_14### * 0\n###figure_15### * 0\n###figure_16### * 0\n###figure_17### * 0\n###figure_18### * 0\n###figure_19### * 0\n###figure_20### * 0\n###figure_21### * 0\n###figure_22### * 0\n###figure_23### * 0\n###figure_24### * 0\n###figure_25### * 0\n###figure_26### * 0\n###figure_27### We identify three key components for each inquiry in the survey: context, question ID&content, and options. To ensure robustness, we made several format variations for the prompt222Despite adopting format variations, we were cautious to not include major changes as the content and structure of WVS were carefully designed by sociologists and professionals. (e.g., alter wordings and change order of components), as previous research Shu et al. (2023  ###reference_b24###); Röttger et al. (2024  ###reference_b22###); Beck et al. (2023  ###reference_b2###) uncovered inconsistent performance in LLMs after receiving a minor prompt variation.\nEventually, we build a set of eight distinct prompts per inquiry. Please see prompt design details in Tab 3  ###reference_### in Appendix.\nThrough a careful analysis on the prompt responses (Appx B  ###reference_###), We observe unstableness of LLM’s responses to prompt variations.\nHowever, multiple prompt trials assists with achieving a convergence point.\nOn 95.5% of questions, more than half of the eight prompts led to responses centered on the same choice or adjacent options, and thus we believe it is acceptable to consider the average of the outcomes across the eight prompt variations as the LLM’s final responses to WVS.\nIn addition, due to the instability of LLMs in following instructions, we encountered seven types of unexpected reply and present our coping methods for each, as summarized in Tab 4  ###reference_###. In the process of averaging responses, we ignore the invalid negative numbers, as we did in calculating human values. For reproducing our work, parameter setting and prompting details are reported in Appendix D  ###reference_###."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Human Data Acquisition",
            "text": "We derive human values utilizing the 7th wave of the World Values Survey (WVS) Haerpfer et al. (2020  ###reference_b10###  ###reference_b10###).\nThe survey systematically probes 94k individuals globally on 13 categories, covering a range of social, political, economic, religious, and cultural values. See an introduction of WVS in Appx A  ###reference_###  ###reference_###. Each inquiry is a single-choice question. Responses are numeric, quantifying the inclination on the options, e.g., “1:Strongly agree, 2:Agree, 3:Disagree, 4:Strongly disagree\". Negative number is possible for coding exceptions such as “I don’t know\".\nTo assess human values, we group the respondents by age group 111Age groups are recorded as 18-24, 25-34, 35-44, 45-54, 55-64, and 65+ and country. Subsequently, we compute the average values for each age group and country to represent their respective cohorts, ignoring the invalid negative numbers."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Prompting",
            "text": "We conduct our analysis on six LLMs, as introduced in Tab 1  ###reference_###  ###reference_###.\n* 0\n###figure_28### * 0\n###figure_29### * 0\n###figure_30### * 0\n###figure_31### * 0\n###figure_32### * 0\n###figure_33### * 0\n###figure_34### * 0\n###figure_35### * 0\n###figure_36### * 0\n###figure_37### * 0\n###figure_38### * 0\n###figure_39### * 0\n###figure_40### * 0\n###figure_41### * 0\n###figure_42### * 0\n###figure_43### * 0\n###figure_44### * 0\n###figure_45### * 0\n###figure_46### * 0\n###figure_47### * 0\n###figure_48### * 0\n###figure_49### * 0\n###figure_50### * 0\n###figure_51### We identify three key components for each inquiry in the survey: context, question ID&content, and options. To ensure robustness, we made several format variations for the prompt222Despite adopting format variations, we were cautious to not include major changes as the content and structure of WVS were carefully designed by sociologists and professionals. (e.g., alter wordings and change order of components), as previous research Shu et al. (2023  ###reference_b24###  ###reference_b24###); Röttger et al. (2024  ###reference_b22###  ###reference_b22###); Beck et al. (2023  ###reference_b2###  ###reference_b2###) uncovered inconsistent performance in LLMs after receiving a minor prompt variation.\nEventually, we build a set of eight distinct prompts per inquiry. Please see prompt design details in Tab 3  ###reference_###  ###reference_### in Appendix.\nThrough a careful analysis on the prompt responses (Appx B  ###reference_###  ###reference_###), We observe unstableness of LLM’s responses to prompt variations.\nHowever, multiple prompt trials assists with achieving a convergence point.\nOn 95.5% of questions, more than half of the eight prompts led to responses centered on the same choice or adjacent options, and thus we believe it is acceptable to consider the average of the outcomes across the eight prompt variations as the LLM’s final responses to WVS.\nIn addition, due to the instability of LLMs in following instructions, we encountered seven types of unexpected reply and present our coping methods for each, as summarized in Tab 4  ###reference_###  ###reference_###. In the process of averaging responses, we ignore the invalid negative numbers, as we did in calculating human values. For reproducing our work, parameter setting and prompting details are reported in Appendix D  ###reference_###  ###reference_###."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "Measures",
            "text": "We use vector  to represent values belonging to a certain category . Each question in the WVS questionnaire is treated as a dimension:\nwhere  is a numeric response to the th question in the section of , and  denotes the total question number.\nNote the acquisition of numeric responses for human groups and LLM has been illustrated in Sec 3.1  ###reference_### and 3.2  ###reference_###.\nBy collecting 372 value vectors that represent people across 62 countries and 6 age groups, along with a value vector for the LLM to compare, we utilize principle component analysis (PCA) Tipping and Bishop (1999  ###reference_b27###) on totally 373 value vectors for representation learning. We acquire value representations for all groups with the dimensionality of three. Our consideration of using PCA is added in Appx C  ###reference_###.\nLet  be the index of age group in [18-24, 25-34, 35-44, 45-54, 55-64, 65+] and the value representation for the th age group be . We derive three metrics below for our further analyses:\nEuclidean Distance, the distance between two value representations.\nwhere  represents values of LLM on category .\nAlignment Rank, the ascending rank of distances between LLM values and people across six age groups.\nTrend Coefficient, the slope of the value gap between LLM and humans across six age groups.  is the slope we would like to fit by linear regression."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Aligning with Which Age on Which Values?",
            "text": "As shown in Fig 1  ###reference_###, we observe a general inclination of popular LLMs favoring the values of younger demographics in the US on different value categories, indicated by the trend coefficient.\nFig 2  ###reference_### exemplifies the bias for LMMs across six age groups in several countries. Due to the limited paper pages, results on other LLMs and countries can be found in Appx E  ###reference_### and F  ###reference_###. Significant testing procedure is available in Appx G  ###reference_###. We observe that in the US and China, as countries of large population, the models tend to have a higher alignment rank on younger groups on the most categories, despite few exceptions (e.g., happiness and well-being). However, in Ethiopia and Nigeria (Tab 8  ###reference_###), the inclination is less evident. We leave this phenomenon for future study.\n###figure_52### In Fig 3  ###reference_###, we show two representative prompts and their responses from ChatGPT and human groups, to illustrate sample values where ChatGPT exhibits a clear bias toward a specific age group."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "The Effect of Adding Identity in Prompts",
            "text": "To analyze if adding age identity in the prompt helps to align values of LLM with the targeted age groups, we adjust our prompts by adding a sentence like “Suppose you are from [country] and your age is between [lowerbound] and [upperbound].” at the beginning of the required component of the original prompt and get responses that corresponds with six age groups.\nWe illustrate the change of Euclidean distance between values of LLM and different age groups after adding identity information. As is presented in Fig 4  ###reference_###, in eight out of thirteen categories (No.1,2,4,5,7,8,9,12) no improvement is observed.\n###figure_53### We also showcase a successful calibration example for a question about the source of acquiring information in Fig 5  ###reference_###. The value pyramid illustrates LLMs’ responses for different age ranges compares to the answers from the U.S. population. When age is factored into the LLM prompt, the LLM’s views are more aligned with the U.S. population of that respective age group, as it reports higher frequency using radio news for the older group.\n###figure_54###"
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Recommendations for Future Work",
            "text": "We have observed that simply including an age in prompts fails to eliminate the value disparity for the targeted age groups. Out of the thirteen categories inquired upon, eight have shown no improvement.\nTo this end, we recommend a careful data curation during pretraining. Doing so involves a deliberate and thoughtful selection of data sources that are diverse and representative of various age groups. By doing so, we can ensure that the model’s training material reflects a wide range of perspectives and experiences, thereby reducing biases and disparities in the model’s responses. We also recommend a consideration of human feedback optimization (e.g., RLHF). Through this iterative process, LLMs can learn to generate responses that fit better with the needs of different age groups. These strategies help mitigate the value disparities associated with targeted age groups, enhancing the LLM’s abilities to be more equitable and inclusive."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we investigated the alignment of values in LLMs with specific age groups using data from the World Value Survey. Our findings suggest a general inclination of LLM values towards younger demographics. Our study contributes to raising attention to the potential age bias in LLMs and advocate continued efforts from the community to address this issue. Moving forward, efforts to calibrate value inclinations in LLMs should consider the complexities involved in prompting engineering and strive for equitable representation across diverse age cohorts."
        }
    ]
}