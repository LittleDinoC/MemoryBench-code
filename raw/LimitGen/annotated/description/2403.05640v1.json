{
    "title": "Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent Classification",
    "abstract": "Intent classifiers must be able to distinguish when a user’s utterance does not belong to any supported intent to avoid producing incorrect and unrelated system responses.\nAlthough out-of-scope (OOS) detection for intent classifiers has been studied,\nprevious work has not yet studied changes in classifier performance against hard-negative out-of-scope utterances (i.e., inputs that share common features with in-scope data, but are actually out-of-scope).\nWe present an automated technique to generate hard-negative OOS data using ChatGPT.\nWe use our technique to build five new hard-negative OOS datasets, and evaluate each against three benchmark intent classifiers.\nWe show that classifiers struggle to correctly identify hard-negative OOS utterances more than general OOS utterances.\nFinally, we show that incorporating hard-negative OOS data for training improves model robustness when detecting hard-negative OOS data and general OOS data.\nOur technique, datasets, and evaluation address an important void in the field, offering a straightforward and inexpensive way to collect hard-negative OOS data and improve intent classifiers’ robustness.\n\n\n\nKeywords: intent classification, out-of-scope, hard-negative data, data generation",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Task-oriented dialog systems rely on robust intent classification models to produce appropriate responses based on the user utterances.\nDuring deployment, the intent classifiers need to not only accurately classify the user utterances, but also must identify if user utterances do not belong to any supported intents.\nBrittle intent classifiers that fail to reliably distinguish OOS (out-of-scope) utterances from the INS (in-scope) utterances ultimately lead to poor user experiences, wasted time and resources, and potential safety concerns.\nThus, it is imperative to develop techniques to ensure robustness against OOS utterances.\n###figure_1### When developing intent classifiers, developers typically begin by collecting and labelling a large amount of INS training data often acquired through crowd-sourcing Kang et al. (2018  ###reference_b23###); Larson and Leach (2022b  ###reference_b28###).\nCollecting OOS datasets to improve the classifier’s OOS detection capability is not a common practice Larson et al. (2019b  ###reference_b31###).\nCurrently, there is a dearth of large public OOS datasets, and the difficulty posed to intent classifiers has not been rigorously examined.\nGeneral OOS datasets typically contain mostly samples that exhibit minimal similarity with the INS samples.\nWhile many models can distinguish such OOS samples and the INS samples during testing, using such OOS samples to evaluate models’ OOS detection capabilities can produce misleading results.\nDuring deployment, the model may encounter OOS utterances that closely resemble the INS utterances but convey entirely different meanings.\nDue to the high similarity that those hard-negative out-of-scope utterances share with the INS data, the models are more susceptible to misclassifying them into a supported intent with high confidence.\nTherefore, collecting hard-negative OOS data is pivotal to ensure that the intent classifiers can reliably distinguish all OOS utterances, regardless of their resemblance to the INS samples.\nFigure 1  ###reference_### shows example utterances and responses of a task-oriented dialog system driven by an intent classifier trained only on utterances for personal finance.\nIn the first user-system exchange, the system correctly categorizes the user utterance as an in-scope balance utterance with appropriately high confidence.\nIn the second exchange, the user provides a general OOS utterance, and the system successfully identifies that the user utterance cannot be understood because the confidence score for all the intents are low.\nIn the third exchange, the user presents a hard-negative OOS utterance.\nSince the utterance includes the words “balance” and “bank”, and appears similar to the in-scope training data for the balance intent, the system incorrectly classifies the utterance as in-scope for balance and produces an incorrect response.\nObtaining OOS data that sufficiently challenges the intent classifiers is difficult.\nOften, this is done through crowd-sourcing with platforms like Amazon Mechanical Turk (e.g., Larson et al. (2019b  ###reference_b31###)).\nHowever, this approach is costly and time-consuming, and it requires careful verification to make sure that the samples are indeed out-of-scope and challenging.\nFurthermore, data collection via crowd-sourcing introduces quality control problems as the the collected data are often error prone Shah and Zhou (2016  ###reference_b46###); Larson et al. (2020a  ###reference_b26###).\nIn datasets containing a large number of intents, verifying each utterance to be irrelevant from all the intents poses significant difficulty for human crowd-sourcing workers.\nFor example, the Clinc-150 dataset Larson et al. (2019b  ###reference_b31###) encompasses 150 intents;\nrelying on the crowd-workers to verify all sentences to be OOS may be challenging and could lead to erroneous results.\nA cost-effective alternative is to generate hard-negative OOS data using Large Language Models such as ChatGPT. Larson et al. (2019b  ###reference_b31###) paid crowd workers $0.20 US to produce three paraphrases of an utterance, and current best practices involve payment that extrapolates to a fair wage Kummerfeld (2021  ###reference_b25###).\nIn comparison, the GPT-3.5 turbo API costs $0.0015 per 1K tokens in the prompt and $0.003 per 1K tokens for the output, a substantial potential savings.\nIn this paper, we aim to investigate the following research questions:\nCan ChatGPT generate OOS utterances that do not fall into any of the system-supported INS intents?\nDo the generated hard-negative OOS utterances lead to high-confidence predictions from intent classifiers?\nCan the generated hard-negative OOS utterances be used in training to improve the intent classifiers’ OOS detection ability and decrease the models’ confidence on the supported intents when encountering OOS utterances?\nTo answer these questions, we select five large public datasets and introduce a method to generate 3,732 hard-negative OOS utterances — that is, utterances intended to closely resemble the in-scope data for a given intent.\nOur method works by analyzing important words that are likely to have the biggest influence on the intent classifiers’ predictions for each intent from the INS training data.\nThen, the method prompts ChatGPT to generate OOS utterances that include specific important words for each intent.\nSince the generated OOS utterances contain the important words from supported intents, they are more likely to confuse the model and produce high confidence.\nIn doing so, we can increase the rigor and challenge of a given dataset by partially automating the creation of hard negative inputs.\nWe evaluate the performance of three benchmark transformer models for intent classification on our generated datasets.\nThe hard-negative OOS utterances produced using our method consistently resulted in high confidence (but incorrect) predictions across all five datasets.\nNotably, intent classifiers struggled to distinguish the hard-negative OOS utterances from the INS utterances.\nIn particular for Clinc-150 and Banking77, model confidence scores are substantially higher for our generated hard-negative OOS datasets compared to the general OOS dataset.\nWe see various improvements in model performance when incorporating hard-negative OOS data in training.\nFor instance, for Banking77 evaluated with BERT, the AUROC for hard-negative OOS and INS improved to 0.996 and the AUROC for general OOS and INS improved to 0.989 when the model is trained on both INS and hard-negative OOS data.\nOur study shows that more attention must be given to curating hard-negative OOS datasets to enhance model robustness in deployment."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Related Work",
            "text": "In this section, we discuss prior work related to data collection for intent classification tasks and ChatGPT’s data generation capabilities."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Hard-Negative Data",
            "text": "Several studies have downplayed the significance of using hard-negative samples during training to improve model robustness. For instance, Zhan et al. (2021  ###reference_b49###) and Nguyen et al. (2023  ###reference_b38###) used hard-negative examples during training to aid retrieval models to better discriminate between relevant and irrelevant documents. Hard-negatives can also facilitate contrastive learning for image classification (e.g., Kalantidis et al. (2020  ###reference_b22###)) and image retrieval (e.g., Melekhov et al. (2016  ###reference_b37###); Hughes et al. (2018  ###reference_b21###)). However, the use of hard-negatives for intent classification remains understudied. In this paper, we use our generated hard-negative OOS datasets to improve model robustness for intent classification."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Data Collection for Intent Classification",
            "text": "General Data Collection. Prior strategies for data collection for constructing training and evaluation data for intent classifiers include the use of crowd-sourcing to generate queries by either (1) paraphrasing input query prompts or (2) responding to scenarios with queries.\nThis prior work includes Coucke et al. (2018  ###reference_b5###); Larson et al. (2019b  ###reference_b31###); Gupta et al. (2018  ###reference_b15###); Liu et al. (2019a  ###reference_b35###); Kang et al. (2018  ###reference_b23###).\nRecently, prior work has investigated using large language models (LLMs) to generate this type of training data.\nThis work includes Rosenbaum et al. (2022  ###reference_b42###), who used AlexaTM, and Sahu et al. (2022  ###reference_b43###), who used GPT-3, and Cegin et al. (2023  ###reference_b4###), who used ChatGPT to generate paraphrases.\nOut-of-Scope and Challenging Data Collection.\nMost prior work on data collection for intent classification does not consider the production of OOS queries for evaluating a model’s ability to distinguish between in- and out-of-scope inputs.\nExceptions to this include Larson et al. (2019b  ###reference_b31###), who’s Clinc-150 dataset includes out-of-scope utterances that were generated via crowd-sourcing.\nOther work in this space includes Larson and Leach (2022a  ###reference_b27###), whose out-of-scope data is constructed by sampling from other datasets, and Zhang et al. (2022  ###reference_b50###), who constructed “in-domain, out-of-scope” splits of Clinc-150 and Banking77 where training data includes a set of intents  from the original dataset , but evaluation data includes a set of intents  that are in the same domain111 Here, a domain is a semantically meaningful group of intents like “banking”, “travel”, etc. as  but .\nSimilarly, Khosla and\nGangadharaiah (2022  ###reference_b24###) created challenging datasets for testing model robustness to “covariate shifted” data.\nIn that work, covariate shifted data means data that was generated from a different distribution with respect to some other original data distribution, but where both data distributions generate data for the same intent category.\nConsidering the weather intent from Clinc-150, covariate shifted data includes data that was originally generated for the Snips or HWU64 datasets (i.e., the get_weather intent from Snips, and HWU64’s weather_query intent).\nOther work that focuses on directly generating new challenge data includes techniques from Larson et al. (2019a  ###reference_b30###), which prompted crowd workers to paraphrase only unique queries from a dataset, and Larson et al. (2020b  ###reference_b32###), who prompted crowd workers to paraphrase seed phrases but constrained the crowd workers from using certain keywords that were found to be indicative of certain intents.\nThe techniques from both of these works can be seen as ways to generate covariate shifted in-scope data."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "2.3.   Adversarial Examples",
            "text": "Our work on generating hard-negative data has similarities to prior work on generating adversarial examples.\nMotivated by adversarial example generation work in computer vision that applies “imperceptible” perturbations to images to provoke incorrect model classification (e.g., Goodfellow et al. (2015  ###reference_b14###)), prior work in natural language processing on adversarial example generation has revolved around perturbing texts using character-level alterations (e.g., Ebrahimi et al. (2018  ###reference_b9###); Gao et al. (2018  ###reference_b11###)) and word synonym and phrase replacement (e.g., Alzantot et al. (2018  ###reference_b1###); Ren et al. (2019  ###reference_b41###); Garg and Ramakrishnan (2020  ###reference_b12###)).\nSimilar work in dialog data has been done by Peng et al. (2021  ###reference_b40###); Liu et al. (2021  ###reference_b33###); Sengupta et al. (2021  ###reference_b45###), where utterances are modified (e.g., by introducing typos, word synonyms, ASR errors, etc.) in order to test the robustness of models.\nThe method we present in this paper can be seen as way to generate adversarial examples to test the robustness of intent classification models, but differs in that we do not apply perturbations to existing samples.\n###figure_2###"
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "2.4.   Data Collection and Annotation with ChatGPT",
            "text": "In a recent study, Cegin et al. (2023  ###reference_b4###) showed that large language models such as ChatGPT can generate more lexically and syntactically diverse INS data by paraphrasing existing corpora.\nCegin et al. (2023  ###reference_b4###) also showed that ChatGPT can follow prompted restrictions and used ChatGPT in-lieu of crowd-sourcing to generate “taboo” paraphrases in the manner of Larson et al. (2020b  ###reference_b32###), where certain words are avoided in paraphrases in order to promote diversity.\nHowever, Cegin et al. (2023  ###reference_b4###) also observed several issues with open-sourced models such as Falcon-40b: duplicated outputs, erroneous outputs, and lack of instruction following.\nAnother study showed ChatGPT’s performance varies for sentiment analysis on tweets depending on the topics  Zhu et al. (2023  ###reference_b51###). For tasks such as classifying the political affiliation of Twitter users, ChatGPT outperforms human crowd-source workers Törnberg (2023  ###reference_b47###).\nChatGPT’s performance for text-annotation tasks has also been found to exceed that of crowd workers (e.g., Gilardi et al. (2023  ###reference_b13###); He et al. (2024  ###reference_b16###)).\nSahu et al. (2022  ###reference_b43###) prompted GPT-3 to generate labeled training data, and the generated data significantly improves the intent classifiers when the intents are distinct. Using ChatGPT to rephrase sentences, models trained with AugGPT outperform state-of-the-art text data augmentation methods to generate data for scarce intents in a few-shot learning setting Dai et al. (2023  ###reference_b7###)."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Methods",
            "text": "We introduce an automated method for generating hard-negative OOS utterances using ChatGPT’s API.\nIn this study, we generate 3,732 hard-negative OOS queries for five benchmark datasets.\nOur objective is to generate hard-negative OOS utterances by producing utterances that are likely to contain words that heavily influence the intent classifiers’ predictions.\nThe hard-negative OOS datasets are generated following these steps, which we discuss throughout this section.\nExample utterances produced with our approach are shown in Figure 2  ###reference_###.\nUse feature-mining to select  keywords by analyzing the most frequently appearing words for each intent for every selected dataset\nSelect a combination of  keywords  …  from the  keywords for an intent\nShow ChatGPT the name of the intent  and five in-scope utterances from\nPrompt ChatGPT to generate  questions (i.e., utterances) that must contain  … , and is not related to the intent\nPrompt ChatGPT to verify that each of the  generated questions is not related to the intent\nPrompt ChatGPT to verify that each of the  generated questions is not related to any of the intents in the entire dataset\nIn this study, we select  to be ,  to be , and  to be . When the prompts include only one keyword, we noticed that the generated data shares less similarity to the INS data compared to when  = . When prompts include three or more keywords, ChatGPT frequently struggles to include all the keywords or produce an OOS utterance. Larger  and  can be selected to generate more hard-negative OOS data."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Feature-Mining Keywords",
            "text": "To ensure that the generated OOS queries resemble INS queries for each intent, we need to identify important keywords that are likely to influence the intent classifiers’ prediction.\nAmong our five selected datasets, we collect the most frequently occurring words in the INS training samples from each intent.\nWe lemmatize all words using NLTK’s WordNetLemmatizer Bird and Loper (2004  ###reference_b2###) to prevent getting multiple versions of the same word.\nIn addition, we discard the stop words and tokens that contain less than three characters.\nWe have also explored alternative methods to identify keywords.\nFor instance, using the Python ELI5 package,222 https://github.com/eli5-org/eli5  ###reference_github.com/eli5-org/eli5### we determined the words with the highest weights after training an SVM classification model on each of the datasets, as was done in Larson et al. (2020b  ###reference_b32###).\nFor larger datasets such as Clinc-150 and HWU64, training multi-class SVM on a substantial number of intents is time consuming. We utilized the LinearSVC from Scikit-Learn Pedregosa et al. (2011  ###reference_b39###) which is implemented as One-vs-All, resulting in a model requiring  classifiers for  intents.\nAfter removing stopwords and lemmatizing the tokens, we are not able to obtain at least five keywords for many intents. For example 65 of 150 intents from Clinc-150 produced less than 5 keywords using the ELI5 method.\nTherefore, we use the original token frequency-based approach for keywords collection."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Data Generation with ChatGPT",
            "text": "Recall that we prompt ChatGPT to produce hard-negative OOS samples.\nWe use the GPT 3.5-turbo model through the chat completion API. (All experiments using ChatGPT were done June-August 2023.) For interaction with the API, we make use of three distinct “roles”: (1) The “system” role, which allows the developers to guide ChatGPT’s behavior throughout the conversation.\n(2) The “assistance” role, which grants ChatGPT’s API the access to previous conversations, enabling ChatGPT to recall previously generated hard-negative OOS utterances to avoid generating duplicates.\nChatGPT can also retain the intent information, removing the need for us to repeatedly inform ChatGPT the intent in every prompt.\n(3) The “user” role, which lets the developers to prompt questions for ChatGPT’s API to answer.\nWhen generating hard-negative OOS utterances, we first set the role to “system” and guide ChatGPT to answer with only the hard-negative sentence.\nThis approach prevents the API from padding the responses with unnecessary tokens like “Sure, I’d be happy to help.”\nNext, we set the role to “user” and show ChatGPT the name of each intent and five INS samples for that intent.\nThis enables ChatGPT to understand the semantics of the intent, especially when the intent name alone does not provide sufficient context.\nThen, we use the “assistance” role to record the dialog between the developer and ChatGPT.\nSubsequently, we prompt ChatGPT to generate an utterance that must be unrelated to the intent (i.e., OOS) and must contain a combination of two keywords\ncollected during feature-mining.333 Preliminary experiments revealed that ChatGPT will often output utterances with mostly the same tokens if prompted to generate multiple utterances at once.\nThis process allows us to guide ChatGPT to produce an utterance that contains commonly used words associated with a given intent but that is not related to that intent — that is, a hardnegative OOS sample.\nNext, we discuss how we validate each such generated utterance is in fact OOS."
        },
        {
            "section_id": "3.3",
            "parent_section_id": "3",
            "section_name": "3.3.   OOS Verification with ChatGPT",
            "text": "To ensure that the hard-negative OOS data does not contain any INS samples, we use a two-step verification method using ChatGPT.\nAfter ChatGPT generates every hard-negative OOS utterance, we immediately prompt ChatGPT to assess whether each utterance belongs to the intent that the utterance should not relate to.\nFor example, after prompting ChatGPT to generate a question containing “hello” and “french” that is not related to the translate intent, we subsequently prompt ChatGPT to determine whether the generated utterance is related to “translate”.\nIf ChatGPT determines that the utterance is related to “translate”, then it is discarded.\nIn the second step of verification, the remaining utterances are then checked to be OOS with respect to the entire dataset.\nTo implement this step, we provide ChatGPT with the name of all INS intent categories using the “system” role, and prompt ChatGPT to verify if each utterance is OOS with the ‘user’ role.\nWe note that ChatGPT occasionally mislabels a small portion of the utterances during this two-step verification process.\nHowever, since our goal is to generate hard negative OOS data, discarding such inadvertently mislabeled data is not critical.\nFinally, we manually check the hard-negative OOS datasets collected after the two-step verification stage to ensure the label accuracy.\nFor utterances that do not clearly fall into the INS or OOS categories, we compare the utterance with the INS samples and discuss amongst the research team to conclude the correct label.\nWe discard the utterances if no consensus is reached regarding label opinions."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Evaluation",
            "text": "We design experiments to assess the level of difficulty that intent classifiers have when discerning between in-scope (INS) and hard-negative out-of-scope (OOS) data.\nAs a baseline, we also measure models’ abilities to discern INS data from “general” (i.e., not hard-negative) OOS data.\nAdditionally, we evaluate the improvements in models’ OOS detection abilities after including hard-negative OOS and general OOS data in training.\nWe hypothesize that the hard negative OOS data we generate with our approach will lead to performance decreases because the model will confuse these samples as being INS.\nWe use INS data from Clinc-150 Larson et al. (2019b  ###reference_b31###), Banking77 Casanueva et al. (2020  ###reference_b3###), ATIS Hemphill et al. (1990  ###reference_b17###); Hirschman et al. (1992  ###reference_b20###, 1993  ###reference_b19###); Dahl et al. (1994  ###reference_b6###), Snips Coucke et al. (2018  ###reference_b5###), and HWU64 Liu et al. (2019a  ###reference_b35###).\nDifferent from the other four datasets, HWU64 consists of two intents General_Quirky and QA_Factoid that span a wide spectrum of semantics.\nWe excluded these two “catch-all” intents from HWU64 for training and testing to allow for sufficient samples that are considered OOS.\nWe use our method to generate 3,732 hard-negative out-of-scope samples targeting intents from the five datasets listed above. Section 5.1  ###reference_### discusses the generated data in detail.\nInstead of hard-negative OOS data, the baseline approach uses “general” OOS data.\nWe use the Clinc-150 companion OOS data as this general OOS data, which consists of 1,000 test utterances.\nWe then filtered out any utterances that belonged to any of the in-scope intents from the other four datasets.\nWe split the INS data into training and testing.\nEach selected model is trained on the training data\nand evaluated with the INS testing data, the generated hard-negative OOS data, the general OOS data from Clinc-150.\nTo examine whether hard-negative OOS data\ncan be used during training to improve the models’\nOOS detection capability, we separated both hard-negative OOS data and general OOS data into\n80% training and 20% testing splits and compared\nthe models’ confidence for the OOS datasets\nwhen we included hard-negative OOS, general\nOOS, and both OOS corpora in training."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Data",
            "text": "We use INS data from Clinc-150 Larson et al. (2019b  ###reference_b31###  ###reference_b31###), Banking77 Casanueva et al. (2020  ###reference_b3###  ###reference_b3###), ATIS Hemphill et al. (1990  ###reference_b17###  ###reference_b17###); Hirschman et al. (1992  ###reference_b20###  ###reference_b20###, 1993  ###reference_b19###  ###reference_b19###); Dahl et al. (1994  ###reference_b6###  ###reference_b6###), Snips Coucke et al. (2018  ###reference_b5###  ###reference_b5###), and HWU64 Liu et al. (2019a  ###reference_b35###  ###reference_b35###).\nDifferent from the other four datasets, HWU64 consists of two intents General_Quirky and QA_Factoid that span a wide spectrum of semantics.\nWe excluded these two “catch-all” intents from HWU64 for training and testing to allow for sufficient samples that are considered OOS.\nWe use our method to generate 3,732 hard-negative out-of-scope samples targeting intents from the five datasets listed above. Section 5.1  ###reference_###  ###reference_### discusses the generated data in detail.\nInstead of hard-negative OOS data, the baseline approach uses “general” OOS data.\nWe use the Clinc-150 companion OOS data as this general OOS data, which consists of 1,000 test utterances.\nWe then filtered out any utterances that belonged to any of the in-scope intents from the other four datasets.\nWe split the INS data into training and testing.\nEach selected model is trained on the training data\nand evaluated with the INS testing data, the generated hard-negative OOS data, the general OOS data from Clinc-150.\nTo examine whether hard-negative OOS data\ncan be used during training to improve the models’\nOOS detection capability, we separated both hard-negative OOS data and general OOS data into\n80% training and 20% testing splits and compared\nthe models’ confidence for the OOS datasets\nwhen we included hard-negative OOS, general\nOOS, and both OOS corpora in training."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Intent Classification Models",
            "text": "We use the following intent classifiers in our experiments:\nBERT, a neural network that uses a transformer model to capture the context of each word and fine-tuned on the training data for NLP tasks Devlin et al. (2019  ###reference_b8###). In this study, we use bert-base-uncased.\nRoBERTa, a variant of BERT that provides better contextual representation of text Liu et al. (2019b  ###reference_b36###).\nDistilBERT, a lightweight variant of BERT that uses fewer parameters than BERT and processes texts faster Sanh et al. (2019  ###reference_b44###).\nWe used the Hugging Face implementations of these models Wolf et al. (2020  ###reference_b48###).\nCommon approaches to dealing with OOS inputs involve the use of confidence scores to differentiate between INS and OOS inputs.\nNormally, a desirable model is one that assigns higher confidence to INS inputs, and lower confidence to OOS inputs.\nWe use two functions to produce the confidence scores when evaluating our hard-negative OOS datasets:\n(1) Softmax, where we use the highest softmax confidence score for each prediction Hendrycks and Gimpel (2016  ###reference_b18###).\n(2) Energy, where we compute the energy score Liu et al. (2020  ###reference_b34###) for each prediction using .444 We considered alternative values for  and the results are similar for different .\nThese two methods are commonly used in prior work on out-of-distribution detection (e.g., Larson et al. (2022  ###reference_b29###))."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "4.3.   Metrics",
            "text": "We consider several performance metrics to evaluate the quality of our hard-negative OOS datasets, assigning the INS predictions as the positive class and OOS predictions as the negative class:\n(1) AUROC, the Area Under the Receiver Operating Characteristic curve can be interpreted as measuring the overlap between two distributions and is commonly used for benchmarking OOD performances Fort et al. (2021  ###reference_b10###). An AUROC score of 0.5 means the model is unable to produce confidence scores that distinguish between INS and OOS inputs, and an AUROC closer to 1.0 indicates better OOS detection capability.\n(2) AUPR, the Area Under the Precision and Recall Curve. A higher AUPR indicates a more robust model.\n(3) FPR95, the false positive rate at 95% recall. A lower FPR95 indicates a more robust model.\n(4) F1 score with confidence thresholds, the F1 score for a range of confidence thresholds from 0.5 to 0.95 for softmax confidence scores. Predictions with higher confidence score than the confidence threshold are considered as positive predictions. Higher F1 captures the classifier’s ability to distinguish INS and OOS data at different confidence thresholds since most intent classifiers in deployment utilize a confidence threshold to determine whether an utterance is not understood."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   Results",
            "text": "This section discusses the results of our data generation and experiments: Section 5.1  ###reference_### discusses the results of generating hard-negative OOS with our method.\nSection 5.2  ###reference_### discusses results of experiments determining the effectiveness of hard-negative OOS data vis-à-vis general OOS data.\nSection 5.3  ###reference_### discusses results of experiments on determining the effectiveness of training with hard-negative OOS data."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "5.1.   Generation Results",
            "text": "In this study, we prompted ChatGPT to generate a total of 11,080 hard-negative OOS utterances from five different datasets.\nRoughly 74% (8,172 samples) of the generated hard-negative passed the first round of OOS verification.\nThen, 3,779 (34%) remained to be valid after the second round of OOS verification where each utterance is prompted to ChatGPT to determine whether it is related to any known in-scope intent of the dataset.\nFinally, when we manually examined the hard-negative OOS datasets after the two-step verification method, we found that 47 (1.2% of the hard-negative OOS after the two-step verification) are INS and mislabelled by ChatGPT, resulting in 3,732 valid hard-negative OOS samples.\nExamples of generated hard-negative data are shown in Table 1  ###reference_###.\nPrecise counts of verified hard-negative OOS data for each dataset is shown in Table 2  ###reference_###.\n0.968\n0.914\n0.982\n0.914\n0.121\n0.326\n0.964\n0.810\n0.959\n0.826\n0.205\n0.639\n0.964\n0.953\n0.972\n0.989\n0.179\n0.245\n0.956\n0.864\n0.982\n0.993\n0.223\n0.400\n0.921\n0.917\n0.971\n0.988\n0.392\n0.462\n###figure_3### ###figure_4### 0.968\n0.914\n0.989\n0.916\n0.981\n0.988\n0.984\n0.990\n0.964\n0.810\n0.997\n0.874\n0.989\n0.996\n0.996\n0.992\n0.964\n0.953\n0.998\n0.974\n0.996\n0.996\n1.000\n1.000\n0.956\n0.864\n0.999\n0.919\n0.968\n0.999\n0.998\n0.993\n0.921\n0.917\n0.965\n0.927\n0.924\n0.985\n0.961\n0.986"
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "5.2.   Classifier Performance",
            "text": "We evaluate our five generated hard-negative OOS datasets with BERT, RoBERTa, and DistilBERT trained on only INS data.\nTable 3  ###reference_### shows the AUROC, AUPR, and FPR95 of all datasets evaluated with BERT.\nFor Banking77 and Clinc-150, the softmax and energy confidence scores for the INS predictions are substantially closer to the hard-negative OOS predictions than the general OOS predictions for all three models.\nFor instance, when evaluated with BERT, Figure 3  ###reference_### (a) shows that the distribution of the softmax confidence scores for the hard-negative OOS is much closer to the INS data compared to the general OOS data. Figure 3  ###reference_### (b) demonstrates that the distribution of energy confidence scores for the INS data is also more similar to that of the hard-negative OOS data compared to the general OOS data.\nFigure 3  ###reference_### (c) displays the F1 score for the INS vs hard-negative OOS data is lower than that for the INS vs. general OOS data at all confidence thresholds, indicating the model is worse at distinguishing hard-negative OOS than general OOS from the INS data.\nRoBERTa and DistilBERT resulted in distributions of confidence scores comparable to BERT. Figure 4  ###reference_### displays the distribution of softmax confidence score for RoBERTa after training on the in-scope data from Clinc-150.\nDuring the evaluation for ATIS, Snips, and HWU64, all three models predict both hard-negative OOS data and general OOS data with a substantial number of high softmax confidence scores.\nThe AUROC of the softmax and energy confidence scores for our hard-negative OOS with INS are lower than those for general OOS with INS, indicating that our generated hard-negative OOS utterances has a larger overlap with the INS utterances compared to the general OOS and INS’s overlap in confidence scores.\nThe FPR95 for both softmax and energy confidence for hard-negative OOS with INS are higher than those for general OOS with INS across all models and datasets, highlighting that the confidence scores can more effectively differentiate the INS data from the general OOS data than our hard-negative OOS data.\nOur results suggest that the hard-negative OOS utterances generated with our approach are, at minimum, as challenging as the general OOS dataset and frequently result in high-confidence, incorrect predictions from intent classifiers.\nSpecifically for Clinc-150 and Banking77, the hard-negative OOS utterances are substantially more difficult to differentiate as be OOS in comparison to the general OOS utterances.\nTherefore, our proposed hard-negative OOS datasets and other hard-negative OOS datasets generated following our approach will challenge intent classifiers and scrutinize classifiers’ robustness against such data."
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "5.3.   Using Hard-Negative OOS in training",
            "text": "When we train transformer-based intent classifiers only on INS data (Section 5.2  ###reference_###), the models predicted high confidence for hard-negative OOS utterances and varying general OOS confidence across all five benchmark datasets. To determine if using hard-negative OOS in training can improve model robustness, we compare the model confidence after training BERT with (1) INS and general OOS data, (2) INS and hard-negative OOS data, (3) INS, general OOS, and hard-negative OOS data, using a 80/20 train test split for the datasets that are used in training.\nTable 4  ###reference_### presents results for the AUROC of the softmax confidence scores to be INS for hard-negative OOS and OOS data with the INS data for each model across five datasets.\nSince OOS data are included in training, we consider “oos” to be a new label.\nWe calculate the confidence score for each prediction by taking the highest softmax score for any in-scope intent.\nThis confidence score indicates how confident the classifier models are in predicting that utterance belongs to a known intent and is in-scope.\nFor Clinc-150, Banking77, and ATIS, when the intent classifiers are trained on OOS data, the confidence scores for general OOS utterances drop substantially compared to models trained only on in-scope data, but the confidence score for hard-negative OOS utterances remain high.\nIn comparison, when we add hard-negative OOS in the training corpora, the models produce low confidence predictions for both hard-negative OOS and OOS utterances, shown by the higher AUROC in Table 4  ###reference_###.\nFor Snips and HWU64, incorporating general OOS in training results in high confidence predictions for hard-negative OOS, and using hard-negative OOS in training results in high confidence predictions for the general OOS.\nIn this case, incorporating only hard-negative OOS in training in not enough to ensure model robustness.\nWhen using both hard-negative OOS and general OOS in training, the model predicts OOS utterances with low confidence to be INS.\nThis result indicates that models trained solely with INS and general OOS data are still prone to predicting hard-negative OOS data with high confidence. When the generated hard-negative OOS datasets are incorporated in the training data, the models are much less likely to produce high confidence scores for hard-negative OOS utterances and displays varying improvements for detecting general OOS utterances.\nAlthough our experiments demonstrate that training with both hard-negative OOS and general OOS greatly reduces confidence on OOS utterances, we note that there is no way to guarantee that every OOS intent can be covered.\nThat is, in deployment, we cannot guarantee that the distribution of inputs will follow the OOS data generated with our approach.\nNonetheless, our approach can be used to help improve model robustness and to improve benchmarking and data quality."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Conclusion",
            "text": "We present a new approach to\ngenerating hard-negative OOS data using ChatGPT. After manually reviewing and verifying generated data, we show our approach can generate data that are OOS data with infrequent mislabels.\nOur evaluation shows that models trained only on INS data are brittle when tested against hard-negative OOS utterances generated with out approach and often result in overconfident but incorrect predictions.\nOur results indicate that the hard-negative OOS utterances are more challenging to differentiate from the INS utterances when compared to the general OOS utterances.\nFurthermore, we show that using hard-negative OOS data in training improves model robustness against hard-negative OOS utterances substantially and general OOS utterances to varying degrees. Models trained on general OOS data still struggle with hard-negative OOS utterances to a noticeable extent across all five datasets.\nSince collecting hard-negative OOS data with ChatGPT is substantially less costly than traditional crowd-sourcing methods, we hope that our technique and analysis will lead to more robust intent classifiers.\nAll code used for generating and verifying hard-negative OOS data with ChatGPT, datasets generated and used, results, and additional figures are available at github.com/frank7li/Generating-Hard-Negative-Out-of-Scope-Data-with-ChatGPT-for-Intent-Classification  ###reference_d-Negative-Out-of-Scope-Data-with-ChatGPT-for-Intent-Classification###."
        }
    ]
}