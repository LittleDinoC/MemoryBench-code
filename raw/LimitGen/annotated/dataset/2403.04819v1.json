{
    "title": "Automating the Information Extraction from Semi-Structured Interview Transcripts",
    "abstract": "This paper explores the development and application of an automated system designed to extract information from semi-structured interview transcripts. Given the labor-intensive nature of traditional qualitative analysis methods, such as coding, there exists a significant demand for tools that can facilitate the analysis process. We present a user-friendly software prototype that enables researchers, including those without programming skills, to efficiently process and visualize the thematic structure of interview data. This tool not only facilitates the initial stages of qualitative analysis but also offers insights into the interconnectedness of themes revealed, thereby enhancing the depth of qualitative analysis.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1. Introduction",
            "text": "Qualitative methods such as interviews or focus groups with customers are an integral part of the research arsenal in a number of fields: marketing, social science, and medical studies (Avjyan, 2005  ###reference_b7###; Leeson et al., 2019  ###reference_b10###). This approach differs significantly from quantitative techniques in its ability to draw on individual experiences and delve deeper into the issue under study. However, unlike the results of quantitative surveys, in interviews, there is no ready-made information, no statistics, and no clear answers to the questions posed. The researcher unwittingly faces the problem of interpretational objectivity, and the question arises as to how to tackle it. The general analysis of collected data in interviews mainly uses open coding technology (Fig 1  ###reference_###), which involves repeatedly reading the text to identify ”codes” that are in essence important thoughts, ideas, attitudes, and subjects. Further, the axial coding procedure is applied, where the relationships between the codes and their aggregation into higher-level categories are found (Saldana, 2016  ###reference_b15###). Several other coding methods are present and all of them involve independent work with the text, consisting of re-reading and finding the key thoughts of the informant in a large number of documents. This process often takes several weeks (Alshenqeeti, 2014  ###reference_b6###). Hence, it can be seen that this procedure requires a lot of human effort to process the text by oneself. So the research issue of implementing automatization of the whole process or pre-processing of the text corpus to facilitate the subsequent analysis appears. That’s why the main goal of current research is to automate the analysis of qualitative research results and elaborate the appropriate software that will help organizations and researchers dealing with large clients’ text corpora. To begin with, it is necessary to consider the existing solutions on the market and describe how the future service will differ."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2. Current coding practices",
            "text": "Each statement or significant segment of dialogue within an interview is assigned a ’code’ that summarizes its main idea. Codes are not just words, phrases, sentences, or thoughts but represent a unit of meaning that encapsulates key aspects of the data (Miles and Huberman, 1994  ###reference_b12###). Once coded, these segments are then organized into broader categories that reflect the underlying patterns and relationships within the dataset (Glaser and Strauss, 2017  ###reference_b9###). In practice categories and codes consist of one or two words to encapsulate the main meaning of a citation. However if the main thought of a sentence can be described only in a phrase, that is also allowed.\nDescribing the process in simpler terms, first, we summarize the main idea of each citation in the interview(Ryan and Bernard, 2003  ###reference_b14###). Then, we start grouping them into bigger categories. This means looking at all the little ideas we’ve found and seeing how they fit together into larger themes. We ask questions like, ”Do these codes share something in common?” or ”Are they talking about the same bigger idea?” This helps us organize our findings better.\nThese categories serve as the pillars for constructing a conceptual framework (Lochmiller, 2021  ###reference_b11###), which researchers often visualize in the form of a graph. Such a graph, akin to a mind map, interlinks individual responses, highlighting the associations and hierarchies amongst different thematic codes. This visualization assists in better understanding the collective narrative of the participants. Thus, the coding process is a critical interpretive phase in qualitative research, helping in developing conclusions and theoretical insights."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3. Overview of methods and tools",
            "text": "In general, researchers use software to facilitate the coding of interviews as follows: the text is conveniently placed on the screen with the possibility of highlighting parts of the sentence with a color marker and tagging them with codes, the number of which then counts itself (Atl, 2024  ###reference_b3###; MAX, 2024  ###reference_b5###). These programs also make space for drawing diagrams with codes and connecting them with arrows and written relationships. Thus, the software does not replace the analysis process as such but simply puts the researcher in a comfortable environment for the same workflow.\nWhen it comes to programs aimed at replacing some of the work some softwares replace part of the work by giving analytical tools such as word statistics and word cloud (Ded, 2024  ###reference_b4###). It is worth noting that all of these programs are paid, so not all researchers are inclined to use them. For example, in one of the works already described, coding was done in MS Word and Excel (Leeson et al., 2019  ###reference_b10###). Some programs focus on text processing in general, with clustering and collocation search capabilities (Ant, 2024  ###reference_b2###). However, the format of interview analysis is very specific, as it requires the building of models based on a set of answers to one question from several informants. Therefore, it is difficult to use such general-purpose software for the analysis of transcripts.\nThus, the purpose of this work is to develop a method for analyzing transcripts of qualitative research results, as well as to write user-friendly software that can be used by researchers who do not know the skills of programming."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1. Existing softwares",
            "text": "In general, researchers use software to facilitate the coding of interviews as follows: the text is conveniently placed on the screen with the possibility of highlighting parts of the sentence with a color marker and tagging them with codes, the number of which then counts itself (Atl, 2024  ###reference_b3###  ###reference_b3###; MAX, 2024  ###reference_b5###  ###reference_b5###). These programs also make space for drawing diagrams with codes and connecting them with arrows and written relationships. Thus, the software does not replace the analysis process as such but simply puts the researcher in a comfortable environment for the same workflow.\nWhen it comes to programs aimed at replacing some of the work some softwares replace part of the work by giving analytical tools such as word statistics and word cloud (Ded, 2024  ###reference_b4###  ###reference_b4###). It is worth noting that all of these programs are paid, so not all researchers are inclined to use them. For example, in one of the works already described, coding was done in MS Word and Excel (Leeson et al., 2019  ###reference_b10###  ###reference_b10###). Some programs focus on text processing in general, with clustering and collocation search capabilities (Ant, 2024  ###reference_b2###  ###reference_b2###). However, the format of interview analysis is very specific, as it requires the building of models based on a set of answers to one question from several informants. Therefore, it is difficult to use such general-purpose software for the analysis of transcripts.\nThus, the purpose of this work is to develop a method for analyzing transcripts of qualitative research results, as well as to write user-friendly software that can be used by researchers who do not know the skills of programming."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4. Research design",
            "text": "In this paper, several methods will be applied and compared with each other, and finally, the most appropriate method for analyzing qualitative research transcripts will be chosen. To achieve the goal, it is necessary to perform the following tasks: Create a framework for visualizing selected keywords from transcripts Write a frontend understandable to researchers.\n\nThe paper will compare various methods to find the most suitable one for analyzing interview transcripts. Semi-structured interviews present a unique challenge as they include characteristics of both: they are short like tweets but can contain rich narratives similar to longer documents.\n\nBefore proceeding with analysis, the necessary preprocessing of the natural text is done. First, the sentences were tokenized and lemmatized. Stop words, which are included by default, were also removed. However, a complementary set of stop words was created, compiled independently after building the frequency tables of the tokens. Many undesirable words occurring in interviews could skew the analysis. Such words as \"probably, it turns out, in general, supposedly, like\" were removed, as well as some verbs that refer to the process of reflection \"think, suppose\"."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1. Analysis of interview transcript data",
            "text": "This paper will compare various methods to find the most suitable one for analyzing interview transcripts. Semi-structured interviews present a unique challenge as they include characteristics of both short and rich narratives, making some standard analytical approaches less effective.\n\nBefore analysis, necessary preprocessing of the natural text is done. First, the sentences were tokenized and lemmatized. Stop words, which are included by default, were also removed. However, in addition to this, a complementary set of stop words was created, which was compiled independently after building the frequency tables of the tokens. Words such as \"probably,\" \"it turns out,\" \"in general,\" \"supposedly,\" \"like,\" were removed, as well as some verbs that refer to the process of reflection \"think,\" \"suppose.\"\n\nUsing the transcripts and combining them into larger formats for analysis was tested and found to give unsatisfactory results when based on individual questions, as it resulted in similar outputs. Therefore, it was decided to abandon this method and focus on the aggregate of all documents for future model development."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5. Experiments",
            "text": "Initial language for interview texts is Russian, and the Russian language BERT model from Deep Pavlov and an autoencoder for dimensionality reduction were used. For the English version of interviews, the BERT base uncased model was used. Clustering was done using K-means, resulting in challenges with clarity.\n\nThe BERT+UMAP+HDBSCAN algorithm was selected as the most suitable for semi-structured interviews, despite its longer processing time. BERT embeddings and UMAP for dimensionality reduction were found to be beneficial for interpretability. Across various sets of interviews, the BERT+HDBSCAN model consistently showed better results. However, for the prototype, model tuning was omitted in the frontend due to efficiency and time considerations."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6. The prototype",
            "text": "The prototype was based on completed objectives. Firstly, the researcher uploads a\ndocument with all the interviews to the website. Then he has a choice to either save or dismiss the Interviewer’s phrases. This heavily depends on the researcher’s perspective and type of interview. Then he has to press the lemmatize button and preprocess. Shortly after that, the program will give him the most frequently used words in the text, which he can load into the file ”additional stop words” if he wishes and add to the website again111https://github.com/Likich/TM_graph  ###reference_###.\nNext, he can choose several suggested methods for analyzing the interview. LDA is the classic method and is fast, while BERT gives higher-quality results but takes more time. Based on these results, we can already hypothesize about the influence of indicators on others and prepare the methodology for the quantitative phase of the study."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7. Empirical perspective",
            "text": "Automating the coding process in qualitative research can be an advantage for various fields such as market research, customer feedback analysis, and clinical data analysis. These areas often deal with vast amounts of unstructured data like interviews, focus groups, and open-ended survey responses, where traditional manual coding is time-consuming and subject to human biases.\nIn market research automated coding can analyze customer interviews and group discussions faster, helping businesses find new trends and customer preferences more quickly. As for customer feedback analysis, automated coding can process customer feedback from various channels (social media, customer surveys, etc.) in real-time, enabling companies to respond promptly to customer needs and complaints. Analyzing qualitative feedback at scale allows for more personalized marketing strategies based on nuanced customer preferences and experiences. Creating a concept network from qualitative feedback can help in creating detailed customer journey maps, identifying pain points, and enhancing customer experience.\nIn healthcare, automated coding of patient interviews and feedback can provide insights into patient experiences, leading to improved care and treatment strategies reducing the time for data analysis, and accelerating research outcomes. Analysis of patient narratives and feedback can reveal insights into the efficacy of treatments and patient feedback, aiding in the improvement of therapeutic approaches."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8. Conclusion",
            "text": "The purpose of this study was to automate the analysis of semi-structured interviews, which is currently very time-consuming for individual researchers. It was also intended to write an application that would allow qualitative researchers with no knowledge of programming skills to use automatic text-processing methods. To achieve the goal, this paper considered methods of coding texts.\n\nThe theoretical significance of this work consists of testing more advanced methods of interview analysis. The main practical contribution is that researchers in qualitative studies now will have access to automatic analysis of their work, or a convenient basis for subsequent analysis. It cannot be argued that such work completely replaces the individual researcher, who can analyze the truthfulness of the answers. However, automated analysis frees the researcher from his or her subjectivity and can help avoid judgmental attitudes."
        }
    ]
}