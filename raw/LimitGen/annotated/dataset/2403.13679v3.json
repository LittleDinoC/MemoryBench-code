{
    "title": "RoleInteract: Evaluating the Social Interaction of Role-Playing Agents",
    "abstract": "Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing conversational agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge, and stylistic attributes of these agents, there has been a noticeable gap in assessing their social intelligence. In this paper, we introduce RoleInteract, the first benchmark designed to systematically evaluate the sociality of role-playing conversational agents at both individual and group levels of social interactions. The benchmark is constructed from a variety of sources and covers a wide range of 500 characters and over 6,000 question prompts and 30,800 multi-turn role-playing utterances. We conduct comprehensive evaluations on this benchmark using mainstream open-source and closed-source LLMs.\n\nWe find that agents excelling in individual level does not imply their proficiency in group level. Moreover, the behavior of individuals may drift as a result of the influence exerted by other agents within the group.\n\nThe benchmark is publicly accessible at https://github.com/X-PLUG/RoleInteract.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Recently, role-playing applications powered by LLMs, such as Character.AI, have gained significant attention. A growing number of research efforts have been dedicated to developing LLM-based role-playing conversational agents, aiming to mimic diverse characters and human behavior. As an emerging and rapidly developing area, the evaluation of role-playing conversational agents is becoming increasingly important. While previous works mainly focus on evaluating the agent’s individual abilities to imitate the character’s role-specific knowledge or speaking style, this study aims to explore and measure the social interaction of role-playing conversational agents, another pivotal dimension for assessing how role-playing agents perceive and behave in a social interaction environment.\n\nTherefore, we introduce RoleInteract, the first evaluation benchmark designed to systematically assess the social interaction of role-playing conversational agents. As introduced in previous studies, the agent society represents a complex system comprising individual and group social activities. Following this definition, RoleInteract assesses the sociality metrics at both the individual and group levels. At the individual level, the agent should possess basic social intelligence, such as self-awareness on role description, emotional perception on environment, and long-term conversation memory. Each of these aspects contributes to a nuanced understanding of how the agents manifest their individual social behaviors. Moreover, we further examine the social intelligence of the role-playing agents within group social interactions, which require the agents to possess certain social preferences towards group dynamics.\n\nRoleInteract is carefully constructed from diverse English and Chinese books, movies, and novels, covering a wide range of 500 characters and 6,000 questions, and 30,800 multi-turn role-playing utterances. Specifically, we design a three-step construction pipeline for RoleInteract. Firstly, we collect diverse role profiles from common web sources. Secondly, GPT-4 is employed to extract dialogue scenes, individual and group-level social conversations, as well as multi-choice questions. Thirdly, we conduct a series of pre-processing and manual labeling to ensure the quality of the benchmark. We conduct comprehensive evaluations on RoleInteract using mainstream open-source and closed-source LLMs to inspire future research."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "Role-Playing Agents",
            "text": "Leveraging the powerful capabilities of open-source foundational models, numerous efforts have emerged to develop models specifically tailored for role-playing tasks. These approaches can be categorized based on training paradigms: 2) Integration of offline reinforcement learning. Shea and Yu (2023) combined role-playing model training with importance sampling strategies. 3) Incorporation of retrieval-enhanced methods. Salemi et al. (2023) combined role-playing model training with retrieved information to enhance the capabilities of agents in role-playing. Shao et al. (2023) introduced an experience upload method to test the model’s effectiveness on memorizing the character knowledge, values, and personality."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Role-Playing Benchmarks",
            "text": "With the rapid development of role-playing agents, there has been a corresponding increase in evaluation datasets. Current evaluation datasets mostly focus on the alignment of role-playing agents with regards to role style and role knowledge. In terms of role style, Tu et al. (2024) and Wang et al. (2023c) investigate whether models can generate responses consistent with the style of the given role. Agents need to grasp different speaking styles for different roles. Regarding role knowledge, Shen et al. (2023) particularly focuses on the role knowledge of role-playing models, including the characters’ experiences and social relationships. Tu et al. (2024) and Wang et al. (2023c) also address aspects of role knowledge, such as role knowledge illusions. Additionally, Wang et al. (2023a) and Tu et al. (2024) introduce psychological theories like the Big Five and MBTI to evaluate role-playing agents."
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Agent Society",
            "text": "Previous benchmarks have primarily focused on single-agent scenarios, leaving the more complex multi-agent scenarios underexplored. Similar to humans, agents are capable of engaging in intricate social interactions, resulting in the formation of an agent society (da Rocha Costa, 2019). Recently, LLM-based agents demonstrate complex social behaviors, where cooperation and competition coexist (Xu et al., 2023). These sophisticated behaviors intertwine to shape social interactions (Gao et al., 2023). \n\nRoleInteract follows the framework defined by Nigel Gilbert and Troitzsch (1997); Leng et al. (2023), where behaviors in agent societies are divided into individual and group-level activities, to study the social intelligence of role-playing agents within social interactions."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Sociality of Role-Playing Agent",
            "text": "The role-playing agent is designed to engage in conversations with users by imitating predefined characters. Given the character profile and social context, the sociality of role-playing agents focuses on imitating typical human social interactions from individual level to group level."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Individual Level",
            "text": "At the individual level, the role-playing social agents manifest through various capabilities, which collectively contribute to their ability to interact within a social context. These capabilities form the foundation of the agent’s social behavior.\nSelf-Awareness on Role Description involves understanding not only the role’s knowledge (Shen et al., 2023  ###reference_b21###), but also the role’s distinct behavioral style (Zhou et al., 2023  ###reference_b33###; Wang et al., 2023b  ###reference_b28###). This self-awareness enables the agent to maintain consistency with its designated role.\nEmotional Perception on Environment enables agents to acquire high-level feeling perception for effective social interactions (Hsu et al., 2018  ###reference_b10###). Agents endowed with sophisticated emotional intelligence, such as situation understanding and emotion detection, can perceive and respond to the emotions of others, facilitating smoother communication and relationship-building.\nLong-Term Conversation Memory is crucial for conversational agents (Shao et al., 2023  ###reference_b19###; Zhong et al., 2023  ###reference_b32###). By memorizing previous dialogue content and aligning with their statements accordingly, role-playing agents demonstrate reliability, enhancing the quality of their social engagements."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Group Level",
            "text": "Individuals within group conversation may be influenced by the group member interactions, thus demonstrate more sophisticated social behaviors towards group dynamics. It represents a higher calling for the sociality of role-playing agent.\nSocial Preference towards Group Dynamics. As a group member, it is natural to navigate diverse group conversation scenarios: acting as a leader to control the pace of conversation, serving as a mediator when conflicts arise among the group, or considering others’ perspectives during discussion, which shows its internal social preference (Leng et al., 2023  ###reference_b13###) towards group dynamics. Furthermore, within society, not all behaviors are inherently positive for the group, and some may be neutral or even negative (Xi et al., 2023  ###reference_b30###). Social agents need to exhibit and keep their pre-designed social preference or group identity when confronted with diverse and more sophisticated group conversations."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "RoleInteract",
            "text": "In this section, we introduce the construction process of RoleInteract, as illustrated in Figure 2  ###reference_###."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Profile Collection",
            "text": "A role profile defines the character style, knowledge, emotions, and social preference of a role-playing agent.\nWe gather profiles for role-playing agents from various sources including novels, scripts, online platforms such as CharacterAI222https://beta.character.ai and Fandom333https://www.fandom.com, and automatic generation via GPT-4-Turbo prompting.\nTo ensure diversity, we construct profiles based on various character types and personality traits by combining the existing categorizations in online platforms and research work (Shen et al., 2023  ###reference_b21###; Gunkel, 1998  ###reference_b8###).\nFigure 3  ###reference_### illustrates the distribution of personality traits for roles within RoleInteract. It demonstrates our approach of ensuring both category diversity and balanced proportions across all categories.\nThe details regarding profile collection in RoleInteract can be found in Appendix D.1  ###reference_###.\n\n###figure_2### \n###figure_3###"
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Dialogue Construction",
            "text": "The dialogue construction adheres to two principles: dialogue fluency, which ensures natural and coherent conversations; and character fidelity, meaning all characters in the dialogue must adhere to their respective personas.\nWe employ four dialogue construction methods:\n1) Extracting from novels and scripts: We gather novels and scripts and extract high-quality dialogue data.\n2) Collecting from online role-playing platforms: We collect authentic user dialogue data from online role-playing platforms.\n3) Conducting role-playing tasks between users and general LLMs: We prompt general LLMs like GPT-4-Turbo to role-play characters and engage users to generate dialogue data.\n4) Fully automatic self-dialogue generation with general LLMs: We task general LLMs like GPT-4-Turbo to role-play and engage in self-dialogue for data collection.\nPrompts for extracting dialogues can be found in Appendix B.1  ###reference_###."
        },
        {
            "section_id": "4.3",
            "parent_section_id": "4",
            "section_name": "Question Design",
            "text": "Based on the constructed dialogues, we employ different methods for designing questions tailored to different dimensions within RoleInteract.\nFor Self-Awareness: This includes two subcategories: self-awareness on role style (SA Style) and self-awareness on role knowledge (SA Know.). Utterances from the original dialogue are selected as correct answers because they have been manually verified to conform to the corresponding role style and role knowledge. For SA Style, we choose styles contradicting the character as negative options, such as rephrasing the original sentence using a different tone. For SA Know., we alter correct answers to be inconsistent with the facts mentioned in the original sentence (e.g., time, location) as negative options.\nFor Emotional Perception: We construct questions related to situational understanding (EP Situ.) and emotion detection (EP Emo.) based on professional exam questions and relevant open-source datasets (Chen et al., 2022  ###reference_b2###; Hsu et al., 2018  ###reference_b10###; Garbowicz, 2021  ###reference_b5###). For EP Situ., we design questions that require agents to analyze the psychological state of the speaker and identify the causes of this state. In this dimension, we design multiple-choice questions with multiple correct answers. For EP Emo., we design questions that require agents to analyze the current speaker’s emotions, such as happiness or sadness, with the correct emotion serving as the correct answer and incorrect emotions as negative options.\nWe further use expert annotations or existing labels to create correct answers, while negative options are constructed through manual collection and generation by GPT-4-Turbo.\nFor Conversation Memory: This category includes two subcategories: short-term conversation memory (CM Short) and long-term conversation memory (CM Long).\nIn a dialogue, the user initially poses a question to the agent. After several rounds of conversation, the user repeats the same question, expecting the agent to provide a consistent response. We employ keyword matching, where the agent is required to include the previously mentioned keywords in their subsequent response.\nFor CM Short, we prompt the agent to recall keywords discussed within 40 utterances, while for CM Long, we prompt the agent to recall keywords discussed over 40 utterances.\nWe evaluate how many of these keywords are recalled.\nFor Social Preference: We design questions for three social behavior preferences: positive (Pos.), neutral (Neu.), and negative (Neg.). Group dialogues typically consist of social interactions involving 2 to 10 characters.\nWe analyze the social preference of an agent and identify behaviors aligning with its preference in the dialogues as correct answers. For instance, behaviors like cooperation and coordination are deemed consistent with the preferences of an agent inclined towards positive social interactions, and thus, are designated as correct answers. Behaviors contradicting its social preference serve as negative options, such as behaviors reflecting a negative social preference, including refusal to cooperate or engage in competition.\nOther agents in group dialogues also have their own social behavior preferences, which are reflected in their profiles or demonstrated through their social interactions."
        },
        {
            "section_id": "4.4",
            "parent_section_id": "4",
            "section_name": "Dataset Validation",
            "text": "The validation stage includes two parts: dataset pre-validation and post-validation. Throughout this process, we undergo multiple iterations of rigorous manual screening, annotation, and refinement."
        },
        {
            "section_id": "4.4.1",
            "parent_section_id": "4.4",
            "section_name": "4.4.1 Dataset Pre-Validation",
            "text": "Profile Verification: After profile collection, we assess personality contradictions and knowledge hallucinations in profiles to ensure character accuracy. We manually review and modify any erroneous descriptions in profiles, while also ensuring the exclusion of specific personal information such as phone numbers and home addresses.\nDialogue Verification: Our focus is on ensuring dialogues adhere to principles of dialogue fluency and character fidelity. For fluency, we manually inspect dialogues for contextual coherence and natural expression. For fidelity, we analyze the speaker’s profile to verify if the utterance aligns with the character’s speaking style and behavior. Dialogues that do not meet requirements undergo manual correction.\nQuestion Verification: For multiple-choice questions, we invite three different annotators to label each question. If all three annotators deem the question valid and agree on the answer, it is considered valid. For open-domain generation questions, we verify the correctness and validity of keywords provided. Invalid questions are either modified by experts or discarded."
        },
        {
            "section_id": "4.4.2",
            "parent_section_id": "4.4",
            "section_name": "4.4.2 Dataset Post-Validation",
            "text": "We undergo the post-validation process\nafter completing each round of dataset. Different dimensions require different validation strategies.\nValidation for Self-Awareness: We focus on examining knowledge-related errors in the questions and options, particularly those generated by LLMs that may give rise to knowledge hallucinations. We remove questions that do not meet the requirements, while options that do not meet the requirements will be flagged for correction in the subsequent iteration.\nValidation for Emotional Perception: Some of the questions we collect are sourced from professional psychology exams, which may include highly specialized content not conducive to assessing the basic abilities of role-playing agents. Therefore, we filter out samples that are too focused on psychology-specific knowledge, retaining those that are more general and fundamental for role-playing agents.\nValidation for Conversation Memory: In this dimension, we’ve observed that questions containing pronouns (such as \"him,\" \"it,\" \"she\") often result in unclear or ambiguous references to preceding context. Therefore, we remove questions containing pronouns to prevent ambiguity. Additionally, we assess the validity of extracted keywords to ensure they are proper nouns, thereby avoiding mismatches caused by different verb tenses.\nValidation for Social Preference: We find that the options within this dimension may exhibit similarities, making it difficult to distinguish the correct option from the negative ones. To reduce difficulty, we manually examine the similarity between options for each sample. For options with excessively high similarity, we increase the differentiation between negative options and the correct answer. For instance, if the correct option has a positive social preference, we select negative social preference content with significantly different characteristics as negative options.\nIndividual Level\nGroup Level\n\nSA Style\nSA Know.\nEP Situ.\nEP Emo.\nCM Short\nCM Long\nPos.\nNeu.\nNeg.\n\nMetrics\n\n\n\n\n\n\n\n\n\n\n#Questions\n1,063\n1,408\n193\n1,016\n773\n1,348\n586\n724\n606\n\nAvg Utterances\n17.9\n9.4\n1.0\n6.4\n23.9\n76.7\n15.6\n16.1\n16.0\n\nAvg Tokens per Utterance\n32.6\n66.7\n286.3\n23.0\n37.6\n41.2\n38.8\n38.7\n42.0\n\nAvg Characters per Question\n2\n2\nN/A\nN/A\n2\n2\n6.3\n6.5\n6.7"
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Experiment Settings",
            "text": "In this section, we show the statistic of RoleInteract. Then we introduce the metrics along with the evaluation LLMs."
        },
        {
            "section_id": "5.1",
            "parent_section_id": "5",
            "section_name": "Dataset Statistic",
            "text": "We show the statistic of RoleInteract in Table 1  ###reference_### and the distribution of dialogue tokens length in Figure 4  ###reference_###. RoleInteract encompasses individual level and group level. There are six subcategories in individual level: self-awareness on role style (SA Style), self-awareness on role knowledge (SA Know), situational understanding (EP Situ.), emotion detection (EP Emo.), short-term conversation memory (CM Short), and long-term conversation memory (CM Long). Group level consists of three social preference categories: positive (Pos.), neutral (Neu.), and negative (Neg.). There are a total of 500 roles, comprising 6,000 questions and 30,800 utterances in RoleInteract."
        },
        {
            "section_id": "5.2",
            "parent_section_id": "5",
            "section_name": "Evaluation Metrics",
            "text": "Most of the previous methods (Wang et al., 2023c  ###reference_b29###; Shao et al., 2023  ###reference_b19###) for role-playing applications rely on GPT-3.5 or GPT-4 for evaluation, which may suffer from questionable accuracy on the role-playing scenario and costly API usage. We follow the popular benchmark MMLU Hendrycks et al. (2020  ###reference_b9###) and C-Eval Huang et al. (2023  ###reference_b11###), and prompt for automatic and fast evaluation free from LLMs.\nRoleInteract utilizes fully automatic evaluation metrics, employing both multiple-choice and open-domain generation questions.\nFor single-answer questions, we calculate the accuracy () using the following formula:\nFor multiple-answer questions, we calculate the accuracy () using the following formula:\nwhere  is the total number of multiple-answer questions.  is the score obtained for the th question, considering both correct and partially correct options chosen.  is the maximum achievable score for the th question. For detailed information on metrics related to multiple-answer questions, please refer to Appendix C  ###reference_###.\nFor open-domain question, we calculate the keyword coverage rate (). RoleInteract provides a keyword set . Given the keywords set mentioned in the response , we compute:\nwhere  quantifies the proportion of keywords mentioned in the response  relative to the keywords identified in the .\nThe metrics utilized for different dimensions in RoleInteract are listed in Table 1  ###reference_###.\n\n###figure_4### Models (Max Length)\nIndividual Level\nGroup Level\nAvg\n\nSA Style\nSA Know.\nEP Situ.\nEP Emo.\nCM Short\nCM Long\nPos.\nNeu.\nNeg.\n\nOpen-Source Models\n\nLLaMA-2-7B-Chat (4k)\n48.76\n51.23\n31.23\n28.91\n25.38\n21.89\n44.98\n24.19\n27.67\n33.80\n\nLLaMA-2-13B-Chat (4k)\n57.62\n65.51\n37.12\n32.56\n30.43\n29.82\n66.38\n42.25\n26.27\n43.11\n\nLLaMA-2-70B-Chat (4k)\n67.61\n70.78\n35.74\n38.47\n45.57\n26.74\n69.87\n45.29\n39.37\n48.83\n\nMistral-7B (8k)\n50.12\n61.17\n36.48\n31.72\n31.78\n25.42\n65.67\n46.34\n28.96\n41.96\n\nQwen-7B-Chat (32k)\n66.44\n71.16\n41.68\n40.68\n67.45\n53.45\n75.61\n52.78\n43.11\n56.93\n\nQwen-14B-Chat (32k)\n77.06\n86.15\n45.71\n43.78\n65.32\n51.37\n78.32\n58.25\n59.21\n62.80\n\nQwen-72B-Chat (32k)\n83.87\n90.64\n53.10\n52.89\n83.29\n73.15\n91.53\n73.44\n63.82\n73.97\n\nClosed-Source Models\n\nGPT-4-Turbo (128k)\n84.57\n93.11\n56.48\n53.05\n81.39\n80.11\n89.73\n81.69\n75.10\n77.25\n\nGPT-3.5-Turbo (16k)\n73.17\n73.82\n52.44\n45.49\n73.03\n59.72\n81.59\n76.79\n54.16\n65.58\n\nQwen-Max (8k)\n82.04\n93.34\n61.14\n52.36\n76.45\n72.65\n87.22\n72.14\n52.19\n72.17\n\nXingchen-Plus (8k)\n85.43\n91.6\n55.44\n60.73\n82.43\n80.69\n94.27\n86.69\n77.26\n79.39\n\nBaichuan-NPC-Turbo (unknown)\n53.69\n61.67\n52.14\n43.34\n76.47\n22.40\n62.09\n48.91\n34.59\n50.59\n\nBaichuan-2-Turbo (unknown)\n77.75\n83.35\n55.7\n47.38\n80.11\n78.91\n87.37\n74.71\n68.50\n72.64\n\nCharGLM-3 (unknown)\n74.70\n79.41\n26.23\n41.27\n81.16\n68.29\n84.40\n70.45\n36.36\n62.47\n\nGLM-3-Turbo (128k)\n77.85\n84.62\n35.58\n53.05\n74.64\n71.68\n84.41\n67.47\n54.55\n67.09\n\nMinimax-abab5.5s-chat (8k)\n36.09\n42.11\n28.15\n47.97\n29.55\n19.30\n44.59\n41.04\n22.45\n34.58\n\nMinimax-abab6-chat (32k)\n82.92\n87.45\n35.90\n51.38\n83.60\n80.26\n89.12\n79.55\n74.65\n73.87"
        },
        {
            "section_id": "5.3",
            "parent_section_id": "5",
            "section_name": "Models",
            "text": "We conduct evaluation on the current mainstream open-source and closed-source LLMs.\nFor evaluation of open-source LLMs, we select chat version of LLaMA-2-7B/13B/70B (Touvron et al., 2023  ###reference_b23###), instruction version of Mistral-7B (Instruct-V0.2) (Jiang et al., 2023  ###reference_b12###), and chat versions of Qwen-7B/14B/72B (Bai et al., 2023  ###reference_b1###).\nFor evaluation of closed-source LLMs, we choose Minimax (abab5.5s-chat and abab6-chat) 444https://api.minimax.chat/, GLM (CharGLM-3 and GLM-3-Turbo) (Zhou et al., 2023  ###reference_b33###), Baichuan (Baichuan-NPC-Turbo and Baichuan-2-Turbo) 555https://npc.baichuan-ai.com/index, Qwen-Max 666https://help.aliyun.com/zh/dashscope/developer-reference/api-details, GPT-4-Turbo (OpenAI, 2023  ###reference_b17###), GPT-3.5-Turbo (OpenAI, 2022  ###reference_b16###), and Xingchen-Plus 777https://xingchen.aliyun.com/.\n\n###figure_5### \n###figure_6###"
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Results and Analysis",
            "text": "In this section, we evaluate mainstream open-source and closed-source LLMs, while also analyzing the experimental results."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "Overall Results",
            "text": "As presented in Table 2  ###reference_###, the performance of closed-source models tends to surpass open-source models. Moreover, models specifically designed for role-playing, such as Xingchen-Plus, outperform others. While the general model GPT-4-Turbo also demonstrates impressive performance.\nHowever, role-playing agents, like Baichuan-NPC-Turbo, CharGLM-3 and Minimax-abab5.5s, tend to underperform compared to their general counterparts, such as Baichuan-2-Turbo, GLM-3-Turbo and Minimax-abab6-chat. We find that they are biased towards character-based dialogues, leading to poorer understanding and compliance with instructions. It’s essential for role-playing agents to maintain character-based dialogue abilities and general instruction-following capabilities.\nAt the individual level, dimensions such as SA Style, SA Know., and CM Short are well-performed by most models. However, some models tend to exhibit poor performance in EP Situ., EP Emo., and CM Long.\nAt the group level, most models perform poorly due to the complexity of group dynamics. While models generally align well with tendencies towards positive social preference, there is a notable absence of necessary abilities to embody neutral and negative social preferences, which are also important for role-playing agents."
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "Conversation Memory for Role-Playing",
            "text": "Conversation memory capability is crucial for role-playing agents. We investigate the memory capacity of role-playing agents across different conversation lengths, measured by the number of utterances in the dialogue. We analyze the distribution of utterance counts in the conversation memory dimension of RoleInteract. As illustrated in Figure 5  ###reference_###, there is a declining trend in memory capability for some models, such as GPT-3.5-Turbo and CharGLM-3, as conversation length increases. When the number of utterances in the dialogue exceeds 80 rounds, most role-playing agents exhibit a noticeable performance decline. This finding showcases the limitations of current role-playing agents in handling extremely long-term memory and highlights potential areas for improvement."
        },
        {
            "section_id": "6.3",
            "parent_section_id": "6",
            "section_name": "Impact of Group Dynamics Complexity",
            "text": "We measure complexity of group dynamics by the number of group members, where a greater number denotes more intricate group dynamics. We analyze the distribution of the number of participating roles in group-level questions. As shown in Figure 6  ###reference_###, with increasing complexity of group dynamics, the performance of all role-playing agents shows a downward trend.\nThis can be interpreted as the interactions among a greater number of participants forming more complex group dynamics.\nWe find that excelling in simple group dynamics does not necessarily imply their proficiency in more complex group dynamics.\nFor example, models like GLM-3-Turbo and GPT-4-Turbo perform well in simple group dynamics, but this doesn’t guarantee strong performance in complex group dynamics. However, models like Xingchen-Plus and Minimax-abab6-chat, which are specially designed and trained with multi-turn role-playing data, could also demonstrate proficiency in handling complex group dynamics."
        },
        {
            "section_id": "6.4",
            "parent_section_id": "6",
            "section_name": "Impact of Group Dynamics Polarity",
            "text": "It is important for role-playing agents to maintain designed social preferences under the influence of varying group dynamics.\nThe group dynamics polarity is defined as the majority social preference of group members. For instance, positive group dynamics imply that the majority of members exhibit positive social preference. For an individual with a specific social preference, different polarities of group dynamics may have various impacts.\nWe study the performance of individuals under different polarities of group dynamics, by analyzing a subset of group data in RoleInteract. As shown in Figure 7  ###reference_###, we find that individuals with neutral and negative social preferences perform optimally within their corresponding group polarities (i.e., neutral and negative group polarities). However, they are susceptible to the influence of group dynamics with different polarities and undergo a phenomenon termed as preference drift, leading to deviation from their original designed behaviors, as indicated by the decline of performance.\nNevertheless, individuals with positive social preference appear to be more resilient to the preference drift, performing better across all group polarities. Especially, they excel in negative group polarity.\nThis phenomenon can be termed as social facilitation (Guerin, 2010  ###reference_b7###) in sociology. We hypothesize that negative group further motivates individuals to engage in behaviors advantageous to the group.\n\n###figure_7###"
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In this paper, we introduce RoleInteract, the first evaluation benchmark designed to systematically assess the social intelligence of role-playing conversational agents at both individual and group levels. We construct diverse question prompts on a wide range of characters covering comprehensive dimensions, including self-awareness on role description, emotional perception on environment, long-term conversation memory, and social preference towards group dynamics. Moreover, rigorous human verification ensures questions’ difficulty and validity. We evaluate over 10 mainstream LLMs on RoleInteract and provide in-depth analysis. While role-playing agents demonstrate satisfactory performance at the individual level, we find that their social interaction capabilities at the group level remain deficient. We hope this finding may inspire future research in this field."
        }
    ]
}