{
    "title": "Generalization Measures for Zero-Shot Cross-Lingual Transfer",
    "abstract": "A model’s capacity to generalize its knowledge to interpret unseen inputs with different characteristics is crucial to build robust and reliable machine learning systems. Language model evaluation tasks lack information metrics about model generalization and their applicability in a new setting is measured using task and language-specific downstream performance, which is often lacking in many languages and tasks. In this paper, we explore a set of efficient and reliable measures that could aid in computing more information related to the generalization capability of language models in cross-lingual zero-shot settings. In addition to traditional measures such as variance in parameters after training and distance from initialization, we also measure the effectiveness of sharpness in loss landscape in capturing the success in cross-lingual transfer and propose a novel and stable algorithm to reliably compute the sharpness of a model optimum that correlates to generalization. 111Code: https://anonymous.4open.science/r/strikegen-7288",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "Generalization enables models to use prior knowledge to reasonably respond to previously unseen stimuli. Although traditional machine learning evaluation is performed based on a preselected set of prediction or generation tasks, accuracy on many public benchmarks may often not be sufficient to extensively assess the ability to perform well in new settings. Therefore, a majority of researchers have found it worthwhile to investigate measures that could evaluate the generalization capability of models with properties, such as VC dimension Vapnik & Chervonenkis (1971), cross-entropy Shannon (1948), complexity Mohri et al. (2012), or variation in parameters during training Nagarajan & Kolter (2019).\n\nAmong these, recent findings support the smoothness in the loss curvature to correlate best with generalization capability Chaudhari et al. (2019); Petzka et al. (2021); Kaddour et al. (2022), motivating the development of learning methods that induce smoothness in the learning trajectory such that the model becomes more robust; either through data perturbation Jiang et al. (2020a); Aghajanyan et al. (2021); Liang et al. (2021); Hua et al. (2021); Park et al. (2022); Zheng et al. (2021); Wang et al. (2021); Huang et al. (2021) or by integrating the measure directly to the optimization objective Izmailov et al. (2018); Jastrzebski et al. (2021); Cha et al. (2021); Foret et al. (2021); Hu et al. (2022); Zaken et al. (2022); Stickland & Murray (2021). However, it might often not be straightforward to compute such measures in high-dimensional feature space in a stable fashion Nachum et al. (2024).\n\nAs models get larger and cover more languages, the possibility of improving the applicability of NLP systems in many under-resourced languages gets more promising. An essential requirement in studying the dynamics of cross-lingual knowledge transfer is to have an evaluation methodology that can reliably measure the model’s capability in generalization of knowledge under different scenarios. There is a common hypothesis that states that a model demonstrating an extended flat optimum area of low loss value surrounding the minimized loss is indicative of better generalization capability. \n\nWe pick prominent measures that were previously shown to correlate well with generalization performance Jiang et al. (2020b), such as the Frobenius distance of the learned parameters after training Nagarajan & Kolter (2019), the margin between model predictions and true labels Wei et al. (2018), and sharpness in loss minima to test applicability to zero-shot cross-lingual generalization measurement Keskar et al. (2017); Foret et al. (2021).\n\nWe also extend the formulation of state-of-the-art sharpness computation methods Keskar et al. (2017); Foret et al. (2021) to provide a sharpness prediction algorithm such that the optimization of the parameters can converge in a more stable fashion."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Related work",
            "text": "Loss-landscape Minima One of the most promising indicators of generalization capability to date seems to be related to the form of the loss landscape, in particular, the sharpness in the loss curvature. A potential reason for this fallback is traced to stochastic gradient descent (SGD) Bottou (2012  ###reference_b2###) methods which often fall into sharp minima of the loss surface Keskar et al. (2017  ###reference_b20###); Chaudhari et al. (2019  ###reference_b4###); Wang et al. (2021  ###reference_b34###).\nAlthough clear conclusions on the relationship between sharpness and generalization performance, such as whether sharper Dinh et al. (2017  ###reference_b8###) vs. flatter Li et al. (2018  ###reference_b21###); Keskar et al. (2017  ###reference_b20###) minima would generally yield better generalization, are still due.\nThe main idea behind these methods is that their objective is to explicitly find flat minima, often using stochastic averaging methods Polyak & Juditsky (1992  ###reference_b30###); Izmailov et al. (2018  ###reference_b15###), mini-max or sharpness-aware minimization methods, which can be computed by direct formulation based on the Hessian matrix of the loss function Chaudhari et al. (2019  ###reference_b4###); Petzka et al. (2021  ###reference_b29###) or Monte-Carlo approximations of the minimizer’s neighborhood Foret et al. (2021  ###reference_b11###); Cha et al. (2021  ###reference_b3###).\nAdversarial optimization Comparison of two approaches finds that for NLP tasks, mini-max methods are more competitive over averaging-based optimization Kaddour et al. (2022  ###reference_b19###). Jastrzebski et al. (2021  ###reference_b16###) hypothesize that regularizing the trace of the Fisher information matrix amplifies the implicit bias of SGD, which prevents memorization. The Fisher information Fisher (1925  ###reference_b10###) measures local curvature, so a smaller trace implies a flatter minimum, which gives the model more freedom to reach an optimum. Instead of explicitly minimizing the values of parameters, Foret et al. (2021  ###reference_b11###) propose minimizing both loss and sharpness while optimizing the parameters such that they lie in neighborhoods with low loss values. Perturbation is an auxiliary objective that encourages the model predictions to be similar in the vicinity of the observed training samples Englesson & Azizpour (2021  ###reference_b9###), usually by penalizing the KL-divergence between the probability distribution of the perturbed and normal model.\nPerturbations can be adversarial inputs Jiang et al. (2020a  ###reference_b17###) or inputs with Gaussian or uniform noise Aghajanyan et al. (2021  ###reference_b1###). To improve cross-lingual generalization, translations of the input generated by machine translation systems were used as perturbed input Wang et al. (2021  ###reference_b34###); Zheng et al. (2021  ###reference_b40###). Other work also has found the benefit of enforcing consistency for perturbations within the model in addition to the input distribution Liang et al. (2021  ###reference_b22###); Hua et al. (2021  ###reference_b13###)."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Methodology",
            "text": "In this study, we undertake the development of a methodology that could benefit an accurate assessment of the generalization capability of models for the purpose of cross-lingual knowledge transfer into under-resourced languages. This section first presents approaches to improving generalization performance and the selected measures that provide stable results for measuring zero-shot cross-lingual transfer performance."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "Sharpness-based Optimization",
            "text": "We chose the following objective functions as fine-tuning methods for a given pre-trained model as a means of comparison since their main purpose is to enhance the generalization and robustness of models. Following the work of Stickland & Murray (2021  ###reference_b32###), as the two most prominent approaches to mini-max optimization, we include Sharpness-Aware Minimization (SAM) Foret et al. (2021  ###reference_b11###) and regularization with Fisher Information Matrix (FIM) Jastrzebski et al. (2021  ###reference_b16###) in our evaluation study on cross-lingual generalization.We also include Multi-view Subword Regularization (MVR) as a perturbation-based optimization method Wang et al. (2021  ###reference_b34###) which induces stochasticity into the shared subword vocabulary across languages for easing cross-lingual transfer.\nSAM Foret et al. (2021  ###reference_b11###) works on the principle of a mini-max objective function: , which essentially means the optimizing function tries to minimize the maximum loss value in a given radius in loss landscape. Therefore, SAM states that it tries to seek ”parameters lying in uniformly low-loss neighborhoods”.\nFisher Penalty is defined as explicitly penalizing the trace of the Fisher information matrix (FIM). Jastrzebski et al. (2021  ###reference_b16###), Stickland & Murray (2021  ###reference_b32###) observed penalizing FIM during training correlates to better generalization performance. It can be written mathematically as  where  is the loss at the data point .\nMVR Wang et al. (2021  ###reference_b34###) function on the concept of consistency regularization where the divergence between the model predictions on deterministic and probabilistic segmentation inputs is minimized. The objective function is formulated as\nwhere the first term is the model loss on deterministic segmentation of the  data sample (most probable segmentation), the second term is the model loss on probabilistic segmentation of the  data sample (random segmentation) and the third term is the KL divergence between these two output predictions. This technique influences the model to be consistent on the predictions of different input types which successively motivates the model to be more adversarially robust."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Generalization Measures",
            "text": "Our study aims to investigate which type and characteristics of methods would best correlate with better performance in generalization, in this case, zero-shot cross-lingual transfer. We are especially interested in confirming the applicability of the flatness hypothesis for cross-lingual generalization. In order to assess whether a flat optimum loss-scape region corresponds to generalization, we essentially break down the experiment to measure two things, flatness, and generalization, such that their correlation can be measured.\nJiang et al. (2020b  ###reference_b18###) conducted an extensive study on image classification tasks using generalization measures such as flatness-based measures (sharpness metrics), margin and norm-based metrics (based on parameter norms and distance from initial weights) to find correlations between measures and model performance which supported the usability of measures. These measures can be useful to explore the capabilities of language models to transfer knowledge from high-resource languages to low-resource ones."
        },
        {
            "section_id": "3.2.x",
            "parent_section_id": "3.2",
            "section_name": "Margin",
            "text": "Higher certainty in predicting the correct label leads to a model that is robust to perturbations and unseen examples. Margin is the distinction between model prediction for ground truth label and the next highest prediction probability. We use an average based margin formula defined by Wei et al. (2018  ###reference_b35###) to calculate margin values on the entire test set. Jiang et al. (2020b  ###reference_b18###) observed that the margin was directly proportional to better generalization in the image classification tasks. Margin is\nwhere  is the  input to model,  is the ground truth label,  is the model function. A larger value of the margin of a model on a given dataset would mean higher confidence in the model to predict the correct label - including unseen examples (from languages not included in fine-tuning)."
        },
        {
            "section_id": "3.2.x",
            "parent_section_id": "3.2",
            "section_name": "Sharpness of optimum",
            "text": "In simpler terms, we can define sharpness as the change in the model loss value at two neighboring points in the model weights plane. It can also be loosely interpreted as the inverse of the maximum radius the loss function can sustain a low loss value at the optimum. Sharpness-based measures resulted in the highest correlation with generalization in Jiang et al. (2020b  ###reference_b18###).\nJiang et al. (2020b  ###reference_b18###) formulates the sharpness to be\nsuch that , where  is the maximum radius in the model’s loss landscape possible,  and  are the models finetuned weights and model initial weights respectively,  is the number of parameters,  is the total number of observations,  is the standard deviation of Gaussian noise added. In this work, as we are comparing models with the same architecture (considering mBERT only), on the same dataset, we can remove the constants, and simplify the equation further for comparative analysis.\nIntuitively, if the radius of the low-loss region in the loss-landscape () is small, that means the model has a higher loss value near the optimum, which would mean the landscape of the optimum is not flat. We can relate this to resulting in an unstable prediction when having perturbations in either the data or model weights. Jiang et al.  ###reference_b18###’s formula didn’t result in stable results for our experimental set-up which might be because the ascent steps taken to optimize the  value resulted in either having a large or a very small final . The values of  occurred at extreme points because the algorithm was using a binary search method and whenever optimal  was not found, the search algorithm stopped with the final  value at either of the extreme points. The correlation results of the above sharpness method are shown in Table 3  ###reference_###.\nWe present an alternative definition (inclined with sharpness measure mentioned in the works of Keskar et al.  ###reference_b20###, and Foret et al.  ###reference_b11###),  that removes the need to optimize  by calculating the difference between loss values at two points in the optimum region, formulated as\nwhere  is  ( being Gaussian noise) and  is the optimum weight parameters. The details of our definition are in Algorithm 1  ###reference_### and performs calculation at about roughly 5-10 times faster than Jiang et al.  ###reference_b18###’s algorithm for a given batch size of 8."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Experiments",
            "text": "For comparison, we implement each Sharpness-based optimization as a fine-tuning objective on the multilingual mBERT base variant (bert-base-multilingual-cased from huggingface) Devlin et al. (2019) in addition to mT5 model (google/mt5-small) Xue et al. (2021). We use a linear classification layer of size 768x3 where the output dimension is equal to the number of labels. We adopt a two-step training approach in our experiments."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Data, Model details, and Settings",
            "text": "We fine-tune pretrained mBERT models for 15 epochs each with a batch size of 32, with a learning rate of , and select best checkpoint on validation. The objective function we use for the baseline model with the classification layer is the AdamW optimizer Loshchilov & Hutter (2019) with cross-entropy loss, the mBERT+FIM model has an additional loss as Fisher Penalty, the mBERT+SAM model uses the SAM optimizer and mBERT+MVR uses the MVR algorithm for fine-tuning. We use the hyperparameters and code presented in XTREME222https://github.com/google-research/xtreme and MVR codebase333https://github.com/cindyxinyiwang/multiview-subword-regularization. We run the models with 8 random seeds and present the average performance of these models. In Algorithm 1, the amount of Gaussian noise we add to model weights during calculating sharpness is controlled using a scale that we empirically find (among [0.001, 0.005, 0.01, 0.02]) for each model, with equal to 0.05.\n\nAdditional experiments were run on PAWS-X dataset Yang et al. (2019) which has 7 languages: German \"de\", English \"en\", Spanish \"es\", French \"fr\", Japanese \"ja\", Korean \"ko\", Chinese \"zh\". We use similar experimentation of fine-tuning on English and doing a zero-shot transfer on 6 other languages as defined above for this dataset. We used Huggingface’s models: mBERT (bert-base-multilingual-cased), RoBERTa (roberta-base), and XLM (xlm-mlm-en-2048) using Adam optimizers."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "Enabling cross-lingual knowledge transfer is an important step towards extending the applicability of NLP models to more languages. Despite recent efforts to develop better optimization methods for improving the generalization of language models in new languages or domains; these techniques try different types of methods to achieve higher performance such as sharpness-based minimizations, reducing gradient of loss functions, or consistency regularization. Evaluating these techniques thoroughly without a standardized methodology remains a difficult task. This work aims to uncover insights into how to measure cross-lingual generalization by exploring suitable measures that work well under different settings. Our experiments studying model loss landscape and parameter properties find strong relationships between the margin, sharpness in the loss minima neighborhood, and zero-shot cross-lingual downstream task performance, both on validation and test sets, supporting strong applicability to evaluate models before deploying them in new languages."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Limitations",
            "text": "The algorithm presented in our paper, the difference-based sharpness measure, is a great novelty for more robust sharpness computation, however, we would like to acknowledge that a few variables in the algorithm still require tuning heuristically, including the noise scale and the multiplication coefficient required to compute the projected radius. Secondly, the mean-based margin distance is only applicable to classification tasks. Due to the limited scope of this project, we leave the development of generalization measures more suitable for generative tasks to future work."
        }
    ]
}