{
    "title": "Uncovering Customer Issues through Topological Natural Language Analysis",
    "abstract": "E-commerce companies deal with a high volume of customer service requests daily. While a simple annotation system is often used to summarize the topics of customer contacts, thoroughly exploring each specific issue can be challenging. This presents a critical concern, especially during an emerging outbreak where companies must quickly identify and address specific issues. To tackle this challenge, we propose a novel machine learning algorithm that leverages natural language techniques and topological data analysis to monitor emerging and trending customer issues. Our approach involves an end-to-end deep learning framework that simultaneously tags the primary question sentence of each customer’s transcript and generates sentence embedding vectors. We then whiten the embedding vectors and use them to construct an undirected graph. From there, we define trending and emerging issues based on the topological properties of each transcript. We have validated our results through various methods and found that they are highly consistent with news sources.",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "Introduction",
            "text": "E-commerce websites handle a vast number of online customer service requests daily. During a typical online customer service interaction, customers first interact with a chatbot which asks them questions to identify their intent. This intent is usually classified based on the product or service that the customer needs assistance with. For instance, an online consumer electronics retailer might use its chatbot to classify requests as relating to cell phones, computers, or home appliances, among others. The chatbot then routes the customer to an agent who specializes in the requested product or service to assist. While the actual business practices among companies may differ, the interaction process between customers and agents is generally similar. Agents usually begin with a greeting and ask for details about the customer’s questions. They then engage in diagnosis and finally conclude with some closing remarks.\nGenerally, processing customer requests can take several minutes, making it one of the most time-consuming aspects of e-commerce business. Therefore, developing a standardized process to handle specific issues is critical to help customers save considerable time and optimize the available resources of agents. This is especially important during emerging events or sudden surges in customer inquiries. By anticipating common issues and developing standardized procedures for agents, businesses can improve their response times, reduce customer frustration, and ultimately enhance customer satisfaction.\nWe present a novel machine learning framework, as illustrated in Fig.1, that can detect emerging and trending issues without predefined lists. The terms ”trending” and ”emerging” refer to the topics that are most frequently discussed within the current time window and the topics that show the most rapid increase in discussion compared to the previous time window. Our approach comprises three distinct components. Firstly, a deep learning model is employed, which utilizes an attention mechanism to automatically tag the primary question sentence in each customer’s transcript and generates sentence-level embedding vectors. To improve the performance of cosine similarity, we decouple the covariance matrix to whiten the embedding vectors, bringing the coordinates of the feature space close to an orthonormal basis. We then construct an undirected graph based on cosine similarity. Finally, we analyze the topology of the graph by calculating the centrality of each customer’s question. This enables us to quantify both trending and emerging issues.\n###figure_1### Related Works Our work relates to several areas in the literature, including sentence-level attention, sentence tagging, and graph-based clustering. Works related to sentence attention include (Yang et al.,, 2016  ###reference_b16###), (Nallapati et al.,, 2016  ###reference_b6###), and (Lin et al.,, 2016  ###reference_b4###), which apply the idea to document classification, summarization, and text noise reduction, respectively. Regarding sentence tagging, (Collobert and Weston,, 2008  ###reference_b1###) and (Santos and Zadrozny,, 2014  ###reference_b11###) are works that perform sentence tagging from token-level representation, and have also influenced our approach. Additionally, we reference several works in graph-based clustering, including (Wang et al.,, 2019  ###reference_b15###) and (Novák et al.,, 2010  ###reference_b7###), which use this technique to handle repetitive sequences and multiview data. These works have inspired our research in the application of topological data analysis to natural language processing."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "Question Tagging and Sentence Attention Model",
            "text": "We present a deep learning model that can automatically tag the primary question in a contact transcript. This model is a crucial component for detecting both trending and emerging issues, as the identified questions will be utilized in later sections."
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "The Dataset",
            "text": "There has been a lack of publicly available datasets related to customer service transcripts. To address this gap, we partnered with customer service team to initiate this research, using a dataset from an online chat system that enables customers to communicate with customer service agents. We collected over 500,000 contact transcripts during 2022, recording conversations between customers and agents. Each contact also comes with a unique label of the product or service that the customer and agents discussed. It’s worth noting that the dataset only contains customer text data, with all confidential information, such as names and account details, anonymized to protect privacy before being shared with researchers. Although the dataset is from a specific database, the methodology presented in this article can be applied to other use cases as well."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "Sentence Embedding",
            "text": "Our goal is to identify the primary question sentence in a customer-agent contact transcript. We propose two hypotheses: (1) the primary question sentence typically appears in the first few sentences of the customer’s interaction with the agent, and (2) it contains the most relevant information about the product or service being discussed. If these hypotheses hold, we can treat the problem as a machine learning task: identifying the customer sentences near the agent’s initial response that are most useful in predicting the product or service of the contact for a machine learning classifier. To achieve this, we need information on attention weights at the sentence level.\nWe propose a deep learning model, as shown in Fig. 2, to achieve our goal. Unlike traditional text classification models that represent an article as a 2D tensor , where  is the number of tokens in the article and  is the dimension of the word embedding, our approach represents each article as a 3D tensor . Here,  is the number of sentences in the article, and  is the number of tokens per sentence. To accommodate varying numbers of sentences and tokens per sentence in each transcript, we use zero-padding to ensure a consistent tensor shape for subsequent processing.\nTo obtain sentence-level embeddings, we treat each sentence as a temporal slice and apply a time-distributed wrapper to a sequence model , such as BERT or LSTM. This ensures that the model receives only one sentence per time step, allowing us to embed each sentence. The resulting output tensor, , contains  sentence vectors, each with  dimensions.\nOur ”bag of sentences” model currently does not consider sentence positions, but we have observed that customer questions tend to appear in early sentences during interactions with agents. This suggests that sentence positions can impact attention weights, so we incorporate sentence position information into the model.\nTo do this, we adapt the idea of position embedding used in many language models for tokens, but apply it to sentences. We assign each sentence an index, ranging from - to +, representing the number of sentences between the current sentence and the agent’s first response. For instance, an index of -5 indicates that the sentence is five steps before the agent’s first sentence, while +5 indicates five steps after. We shift the indices by , resulting in an allowed index range of 0 to +, with the sentence having an index of  being the agent’s first sentence to avoid negative indices. For a sentence with index , the -th component of the position embedding vector  is given by  and :\nwhere  is the dimension of embedding vector. By adding  and , we get the final sentence embedding vector .\n###figure_2###"
        },
        {
            "section_id": "2.3",
            "parent_section_id": "2",
            "section_name": "Sentention Attention",
            "text": "We define sentence level attention(Vaswani et al.,, 2017  ###reference_b14###):\n, where  is a query tensor (i.e. the sentence embedding),  is a key vector and  is a value tensor. We can generally define  without any impact on model performance. As a result, the attention value  is a vector and the sum of its elements must equal 1, due to the application of the softmax function.\nOur model’s attention vector  has a simple interpretation. As shown in Fig. 2, each sentence in a transcript is represented as a vector  (the -th row of the 2D tensor ). The attention vector  is a linear combination of all sentences, computed as , subject to the constraint that . We then pass  through a fully connected layer with a softmax activation function to predict the product or service associated with the transcript. The attention weights  reflect the importance of each sentence in determining the product or service, with higher weights assigned to sentences containing more critical information."
        },
        {
            "section_id": "2.4",
            "parent_section_id": "2",
            "section_name": "Experiments",
            "text": "Our model was trained on 500,000 transcripts with 152 classes to predict the product or service discussed in each contact. We used DistilBERT (Sanh et al.,, 2020  ###reference_b10###) as the embedding model , with an output dimension of 768. To prepare the transcripts for training, we padded each one with zeros to create 64 sentences, each with 128 words.\nAfter training, we calculated attention weights  for each customer sentence in a transcript. To identify the primary question, we assumed that it is the sentence with the highest attention weight that is  steps before or after the agent’s first sentence. In testing on 4,000 human-annotated transcripts, we found that  (i.e.,  steps) yielded the best results, correctly identifying the primary question sentence in 84.3% of the total transcripts. Fig. 1 in the Appendix illustrates an example of how our sentence attention model tags the primary question sentence.\nTo evaluate the impact of sentence position embedding on performance, we compared the model with and without this feature. Although the difference in accuracy was minimal (83.4%), we observed that sentence position embedding resulted in higher attention weights on the primary question sentence. Further investigation is needed to explore the effects of position embedding."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "Topological Natural Language Analysis",
            "text": "Our objective is to identify both emerging and trending topics among the questions gathered by the model presented in Sec. 2. However, conventional clustering methods face several challenges in achieving this goal, including sensitivity to hyperparameters, scalability issues with large numbers of classes and samples, and lack of flexibility in defining distances.\nMoreover, identifying emerging topics involves changes in the volume of a topic between time windows, and conventional clustering methods cannot determine whether two clusters in different datasets are related to the same topics. It is even possible for an emerging topic to be present in the current time window without appearing in the previous time window. Additionally, conventional clustering methods may treat emerging topics as noise due to their much smaller volume than trending topics.\nTo overcome these challenges, we propose a topological-analysis-based method robust to hyperparameter selection and can quantitatively detect both emerging and trending topics between different time windows."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "Undirected Representation Graph and Centrality",
            "text": "Let us assume that we have gathered primary customer questions and their corresponding sentence embeddings, , over two time periods,  and . Each sentence can be represented as a node in an undirected graph, with edges connecting nodes whose cosine similarity surpasses a specified threshold, . It is important to note that this graph is constructed using data from both time periods,  and . In this graph, a node with a higher number of neighbors indicates a greater number of similar questions.\nCentrality is a significant topological property of a node, which describes its importance within a graph. Various types of centrality exist, each applicable to different scenarios. In this case, we define two new types of centrality that modify the decay centrality. Assuming we have an undirected graph represented by an adjacency matrix , where  if nodes , the decay centrality of a node  in a graph  is defined as(van Steen,, 2010  ###reference_b13###):\nHere,  refers to the set of nodes in the graph, and  is the total number of nodes in the graph. This normalization factor ensures that the centrality  is independent of the graph’s size. The attenuation factor  is typically selected such that . The topological distance  between nodes  and  is the graph distance, not the Euclidean distance . The numerator is given by an exponent , which results in  when nodes  and  are directly connected. A question with higher decay centrality means the graph has more similar questions.\nGiven that time is an additional property of each node, we modify the definition above and propose two new types of centrality:\nmatched decay centrality:\nmismatched decay centrality:\nIn these equations, the brackets  represent Iverson brackets, yielding 1 if the statement inside is true and 0 if false.  refers to the time window that node  belongs to.  considers contributions only when two nodes belong to the same time window, while  accounts for contributions from different windows, decaying exponentially as the distance increases. It is important to note that node  can reach node  through intermediate nodes in either the same or different time windows. Furthermore, we have . This definition splits the decay centrality into two terms based on the time window. We can effectively identify trending and emerging issues by utilizing matched and mismatched decay centrality.\n###figure_3###"
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "Trending and emerging Issues",
            "text": ""
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "Topological Perspective",
            "text": "We are only interested in the nodes in the current time window, so we define trending and emerging issues from a topological perspective as follows: 1). Trending issues are identified as the customer’s primary questions with a large trending score:  2). Emerging issues are identified as the customer’s primary questions with a large emerging score: .\nThe definitions for the trending and emerging scores are simple to understand. The trending score, denoted by , counts the number of similar questions in the graph that exist in the current time window. On the other hand, the emerging score, given by , represents the difference in centrality contributed from the previous time window and the current time window. It’s important to note that . As a result, the emerging score lies between -1 and +1, where -1 and +1 correspond to the centrality entirely coming from the previous and current time window respectively, while 0 indicates equal contributions from both time windows. To avoid identifying small-size clusters that may not be significant for a business that receives a large volume of customer contacts, we introduce an additional filtering factor, , where  is a parameter that controls the strength of the filter. This factor applies a weight to the emerging score, such that  drops to 0 when , and saturates to 1 when ."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "Experiment",
            "text": "We constructed a graph using the MessageUs transcript data by applying a cosine similarity threshold of , an attenuation factor of , and a filter factor of , where  is the total number of nodes. This filter factor was set to 10% of the maximum number of  values, and it helped to exclude small clusters that were unlikely to be significant. We used topological data analysis to identify the most prominent clusters, and we found that the topics of these clusters were highly consistent, even though the exact values of  and  were sensitive to the chosen hyperparameters. Varying the hyperparameters affected only the sizes of the clusters and did not significantly alter the topics we discovered, which demonstrates the robustness of the topology analysis approach.\nFig. 3 shows the distribution of , , and  for Tablet-related transcripts, using Jan 2023 and Feb 2023 as the previous and current time windows, respectively (around 100K data points). We compare the distributions for a cosine similarity threshold of  (panels (a)-(c)) and  (panels (d)-(f)). Decreasing  results in a more compact graph and a more Gaussian-like distribution of centrality. We observe that the emerging score distribution can be separated into two parts: a Gaussian-like distribution around zero due to the filter factor applied to nodes with , and a long-tail region due to nodes with . The filter factor helps to focus on the outliers, and the nodes in the long-tail region are generally similar, with high-score nodes unlikely to become low-score nodes due to changes in hyperparameters.\nIt is important to note that similar sentences tend to form clusters. As a result, the neighbors of a high centrality node also tend to have high centrality, as shown in Fig. 3(g). To avoid locating the same cluster multiple times, it is necessary to ensure that two centers are sufficiently far apart. To achieve this, we first designate the node with the largest  (for trending) or  (for emerging) as the cluster center and its surrounding neighbors with graph distance  as the cluster members. Next, we search for the node with the next-largest score at least a graph distance of 4 away from any known clusters as the next cluster center. We repeat this procedure until we have obtained the desired number of clusters.\nTable.1 of the appendix provides examples of sentences from the top-1 trending and emerging clusters of Tablet in February 2023. As one can see, all the customer’s questions within each cluster are very similar, demonstrating the effectiveness of our approach in cosine similarity and topology-based topic detection."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "Result and Discussion",
            "text": "We have successfully developed a machine learning model capable of extracting trending and emerging issues from extensive transcripts. However, directly validating the precision rate of our model presents a challenge. To address this challenge, we have proposed a human-annotation-based method for validation.\nOur data collection spanned from November 2022 to February 2023 and involved more than 10 different products, including Kindle, Echo, Music, eBook, and Prime Video. During this period, our focus was on identifying the top-3 trending and emerging issues. We took care to exclude issues that appeared unreasonable due to quality of data or instances of fraud or policy abuse attacks. As a result of this process, we successfully identified 84 trending issues and 64 emerging issues.\nTo assess trending issues, each annotator is asked to select three keywords that best represent each issue. We then count the number of transcripts containing these keywords simultaneously. Remarkably, we discovered that all 84 issues, representing 100% of the total, constitute a large portion, at least 10%, of the overall volume of each product line. Furthermore, the volume remains consistently stable from month to month. Although it’s challenging to determine if these are the largest issues, it’s noteworthy that a significant portion of them pertains to return or refund-related matters, aligning closely with our business experiences.\nRegarding emerging issues, we employ three methods to identify them. Firstly, we select the three most representative keywords for each issue and monitor changes in volume within transcripts containing these keywords. Additionally, we investigate whether the issue surfaces in the Amazon Digital and Device Forum for that month, where customers discuss Amazon’s services, with a minimum of 10 replies ( not necessary in a single thread ). Lastly, we conduct a Google search to determine if these issues are covered in news media.\nOur surveys revealed some insightful findings: approximately 90% of emerging issues exhibit volume changes exceeding 30% between two months, around 60% of the issues are discussed in the Amazon Digital and Device Forum for that month, and roughly 15% of the issues are covered in news media, typically related to live events or new product launches. The surveys support our model indeed captures the emerging issues very well. In Table 2 of the appendix, we provide a few examples of emerging topics found in Feb 2023 and our validation results, and most of the topics align well with the news sources."
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "Conclusion",
            "text": "In summary, we have presented a unique machine learning framework for extracting customers’ trending and emerging issues. Our work starts with an attention-based deep learning model that tags customers’ primary questions and generates corresponding sentence embeddings simultaneously. We then transform the sentence embeddings into an isotropic coordinate system using whitening techniques to improve the cosine similarity performance. Finally, we apply topological natural language analysis methods to analyze the centrality of each question, enabling us to identify trending and emerging issues.\nOur work makes a significant contribution by demonstrating the application of a sentence-level attention mechanism in conversational transcripts, an area that has been understudied. We combine this mechanism with topological data analysis to extract useful information for a real-world problem."
        }
    ]
}