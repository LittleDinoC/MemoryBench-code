{
    "title": "Willkommens-Merkel, Chaos-Johnson, and Tore-Klose: Modeling the Evaluative Meaning of German Personal Name Compounds",
    "abstract": "We present a comprehensive computational study of the under-investigated phenomenon of personal name compounds (PNCs) in German such as Willkommens-Merkel (‘Welcome-Merkel’). Prevalent in news, social media, and political discourse, PNCs are hypothesized to exhibit an evaluative function that is reflected in a more positive or negative perception as compared to the respective personal full name (such as Angela Merkel).\nWe model 321 PNCs and their corresponding full names at discourse level, and show that PNCs bear an evaluative nature that can be captured through a variety of computational methods. Specifically, we assess through valence information whether a PNC is more positively or negatively evaluative than the person’s name, by applying and comparing two approaches using (i) valence norms and (ii) pretrained language models (PLMs). We further enrich our data with personal, domain-specific, and extra-linguistic information and perform a range of regression analyses revealing that factors including compound and modifier valence, domain, and political party membership influence how a PNC is evaluated. \n\n\n\n\nKeywords: Multiword Expressions & Collocations, Semantics, Statistical and Machine Learning Models",
    "sections": [
        {
            "section_id": "1",
            "parent_section_id": null,
            "section_name": "1.   Introduction",
            "text": "Personal name compounds (PNCs) such as Willkommens-Merkel (‘Welcome-Merkel’), Chaos-Johnson (‘Chaos-Johnson’) and Tore-Klose (‘Goal-Klose’) are nominal compounds that consist of a modifier such as Willkommen (‘Welcome’) and a personal name such as Merkel. PNCs are compositions that refer to a person, in our example the former German chancellor Angela Merkel. With few exceptions Wildgen (1981  ###reference_b36###); Kürschner (2020  ###reference_b19###), PNCs have not received much attention from the theoretical or computational perspectives, but recent work suggests that they represent a rather frequent phenomenon\nand carry an evaluative function with regard to the reference person Belosevic and Arndt-Lappe (2021  ###reference_b4###); Belosevic (2022  ###reference_b3###). That is, for a specific PNC in its discourse we hypothesize that the PNC is perceived as either more positively or as more negatively than the corresponding full name.\nFor understanding and generating texts from and for domains where real-world people are talked about (such as the news, social media, and any kind of political discourse, as well as for related tasks including sentiment and emotion analysis) it is thus particularly relevant to explore the evaluative nature and discourse effects of PNCs.\nThis paper performs such an investigation:\nwe leverage and extend an existing dataset consisting of German PNCs and their corresponding full names from the domains politics, sports, show business, and others Belosevic and Arndt-Lappe (2021  ###reference_b4###). To assess PNCs in their contexts, we build a corpus drawing on data from social media (Twitter)\nand German news (Deutscher Wortschatz).\nWe then draw on the notion of valence from psycholinguistics that determines the pleasantness of a stimulus. Valence is considered one of the principal dimensions of affect and cognitive heuristics that shape human bias and attitude Harmon-Jones et al. (2013  ###reference_b14###). It determines the affective quality referring to the intrinsic pleasantness or unpleasantness of a stimulus (e.g., joy vs. toothache) Osgood et al. (1957  ###reference_b26###); Frijda (1986  ###reference_b10###).\nWe hypothesize that PNCs with a higher or lower valence relative to their respective full name bear an evaluative character. To assess valence at context level, we develop two computational approaches.\nFirst, we explore valence norms to efficiently compute and compare whether a PNC’s contexts are more negative or positive than the contexts of the respective name. Second, we present an approach to interpret and evaluate the PNCs by leveraging a range of suitable pretrained language models (PLMs) that have been fine-tuned and evaluated for the conceptually related task of sentiment analysis\nBarbieri et al. (2022  ###reference_b2###); Antypas et al. (2023  ###reference_b1###); Guhr et al. (2020  ###reference_b13###); Lüdke et al. (2022  ###reference_b22###). We use sentiment predictions as a proxy for valence and investigate whether PNCs for which more positive or negative sentiment is predicted relative to their respective full name bear an evaluative character. To this end, we compare results from four models varying regarding underlying architectures (RoBERTa, BERT) and training data.\nSince PNC meaning is heavily dependent on modifier meaning, we also examine to which extent modifier valence influences the evaluation of the whole compound.\nLastly, we explore whether personal background information such as age, domain-specific knowledge\nand extra-linguistics information\nimpact the PNC evaluation.\nTo explore which factors are influential at a statistically significant level, we\nfit a range of regression models.\nOur results show that PNCs are both positively and negatively evaluative in comparison to their full name with a tendency towards a negative evaluative nature, underlining previous findings from Belosevic and Arndt-Lappe (2021  ###reference_b4###); Belosevic (2022  ###reference_b3###). We find domain-specific differences with public figures from the domain politics bearing a more negative meaning, while the opposite is true for PNCs from the domain sports and show business.\nModeling modifiers reveals corresponding valence scores to be more extreme than valence scores obtained for the compound as a whole with a tendency towards lower valence. Our findings also highlight cases where modifier meaning is either interpreted non-literally or smoothed down when evaluated as PNC constituent. Furthermore, comparing results across approaches shows that valence assessments using PLMs lead to up to 37% more negatively evaluated PNCs as compared to results based on valence norms.\nFinally, while personal and domain-specific information impact the evaluative nature of a PNC, regression models including extra-linguistic information such as compound valence are more informative. Our best model thus combines information from all variables except name valence, with factors such as compound valence, domain, and political party membership playing an important role."
        },
        {
            "section_id": "2",
            "parent_section_id": null,
            "section_name": "2.   Background and Related Work",
            "text": ""
        },
        {
            "section_id": "2.1",
            "parent_section_id": "2",
            "section_name": "2.1.   Personal Name Compounds (PNCs)",
            "text": "PNCs such as Tore-Klose (‘Goal-Klose’) are nominal compounds that consist of a modifier which is usually realized in form of appellative or onymic constituents (e.g., Tore) and a head constituent that is filled with a first, last, or nick name (Klose) Belosevic (2022  ###reference_b3###).\nPNCs are formed based on regular patterns within a context that both evaluates and evokes knowledge regarding the name bearer Belosevic and Arndt-Lappe (2021  ###reference_b4###). For example, the PNC Tore-Klose (’Goal Klose’) refers to the former German soccer player Miroslav Klose who is the all-time top scorer for Germany with 16 goals scored during the Men’s FIFA World Cup. The example also illustrates the importance of the compound modifier contributing information regarding the name bearer or events in which the name bearer was involved. In other words, the meaning of the modifier is the reason or at least related to the reason why this compound was formed. In our example, goal hints towards a positive evaluation of the PNC as such an event is usually connected with particular athletic performance and special occasions, as well as concrete events such as scored goals during the soccer world cup in 2014."
        },
        {
            "section_id": "2.2",
            "parent_section_id": "2",
            "section_name": "2.2.   Approaches to Modelling PNCs",
            "text": "German PNCs are under-investigated from both a theoretical and computational point of view. Early work is limited to very small scale studies based on a few names Wildgen (1981  ###reference_b36###) or focus on other phenomena and touch on this composition type only in passing Kürschner (2020  ###reference_b19###); Ortner and Ortner (1984  ###reference_b24###); Ortner and Müller-Bollhagen (1991  ###reference_b25###); Schlücker (2017  ###reference_b30###, 2020  ###reference_b31###). An exception is recent work by Belosevic and Arndt-Lappe (2021  ###reference_b4###) who present a systematic analysis of ~1.2K PNCs to test three hypotheses on personal name composition that prevail in word formation (irregularity or unpredictability, low frequency, evaluative function). They compile a small Twitter and newspaper corpus, manually infer a paraphrase of the PNC in form of a relative clause, and assign a corresponding German FrameNet  ###reference_gsw.phil.hhu.de/### Ziem (2014  ###reference_b39###) relation. Their corpus analysis shows that not only are PNCs formed based on regular patterns but also bear an evaluative and a knowledge-evoking function.\nWhile this analysis constitutes an important contribution to name-based composition and evaluation, it is, however, limited by size and a manual approach.\nFrom a NLP perspective, PNCs have not received much attention yet. Related tasks such as noun compound interpretation where a noun compound is classified into a predefined label or expressed in a paraphrase Lauer (1995  ###reference_b20###); Kim and Baldwin (2005  ###reference_b16###); Shwartz and Dagan (2018  ###reference_b34###); Coil and Shwartz (2023  ###reference_b6###) and noun compound conceptualization exploring rare or novel interpretation through paraphrasing Dhar et al. (2019  ###reference_b7###); Li et al. (2022  ###reference_b21###) neither include PNCs nor approaches to assess the evaluative function of such compounds.\nAnother relevant line of work concentrates on sentiment analysis (SA), i.e., predicting the sentiment, attitude or opinion of text or speech on different units using e.g., the categories positive, neutral and negative Mohammad (2012  ###reference_b23###).\nWillkommens-Merkel\n(‘Welcome-Merkel’)\n#Lanz This political constellation should never have come about in the first place, says Merz. Another declaration of war on Welcome-Merkel\nVillen-Spahn\n(‘Villas-Spahn’)\nI’m so fed up with jet-setting, fizzy brew-drinking politicians who flaunt their swagger. Where do they get all the money from? I would like to see more transparency in the revenues of Villas-Spahn and Jet-Merz, for example.\nGedächtnislücken-Scholz\n(‘Memory-Lapse-Scholz’)\nDo I understand correctly that the same Memory-Lapse-Scholz, who seems to have lost all decency in connection with the huge tax fraud Cum-Ex, is now hypocritically demanding – morality? Morality? Scholz? Really?\nVollgas-Vettel\n(‘Pedal-to-the-Metal-Vettel’)\nExcellent! - “Pedal-to-the-Metal-Vettel” saves World Cup lead #Vettel\nGold-Rosi\n(‘Gold-Rosi’)\nSki legend Rosi Mittermaier has died at the age of 72. “Gold-Rosi” became the “pop star” of winter sports at the 1976 Winter Olympics. #rosimittermaier\nWhile an increasing amount of researchers have explored the sentiment of news text and tweets in many languages including German Cieliebak et al. (2017  ###reference_b5###); Fehle et al. (2021  ###reference_b8###); Grimminger and Klinger (2021  ###reference_b12###); Schmidt et al. (2022  ###reference_b33###); Zielinski et al. (2023  ###reference_b38###),\nPNCs have not been investigated yet. We address this gap by developing two computational approaches drawing on valence norms and PLMs fine-tuned for SA to examine the evaluative nature of PNCs at discourse level."
        },
        {
            "section_id": "3",
            "parent_section_id": null,
            "section_name": "3.   Data",
            "text": "We start out with 770 eventive PNCs provided by Belosevic (2022  ###reference_b3###). As described in detail in her work, the PNCs were collected manually by searching for the string *name or -name as well as regular expressions in the DWDS (Goldhahn et al., 2012  ###reference_b11###) WebXL interface. Additional targets were collected via the Twitter Extended Search option.\nWe filter the corpus for PNCs with a common or proper noun modifier followed by a personal name such as Willkommens-Merkel or Gold-Rosi, and only keep PNCs for which we find a context instance (cf. §3.2  ###reference_###).\nThis leads to final lists of 321 and 217 instances of PNCs with at least one and five contexts that are used for modeling, respectively. To maximize recall w.r.t our corpora, PNCs are modified at character level using heuristics such as eszett replacement: ß  ss, e.g., Spaß-Guido  Spass-Guido (’fun-Guido).111See App. A  ###reference_### for the full list of heuristics.\nThe PNCs can be categorized into the domains politics including politicians such as Angela Merkel and Boris Johnson (87%), sports referring to athletes who are mostly soccer players but also include e.g., the Formula 1 driver Sebastian Vettel (9%), show business encompassing e.g., the actress Angelina Jolie (1%), and others including public figures such as lobbyist Karlheinz Schreiber or the climate activist Greta Thunberg (3%). We list example PNCs\nwithin a context in Table 1  ###reference_### and make the full list of examined PNCs publicly available.222The full list is available here: https://github.com/AnneroseEichel/LREC-COLING2024  ###reference_ING2024###\nWe manually map each PNC to the corresponding full name (first name, last name), yielding 131 and 113 names for which at least one or five PNC instances are in the used corpora.\nWe download tweets containing PNCs or full names using the Twitter333We downloaded the data before the re-naming.\nAcademic API (closed in spring 2023) using missing  ###reference_test/twarc2_en_us/###twarc. Modifiers and names are required to be perfect matches while characters in between are not restricted to hyphens or whitespace but may also be e.g., hashtags. The maximum context is defined as one tweet and added to the corresponding subcorpus whenever a PNC or name is found. For full names, we download 100 tweets per match and remove retweets based on URLs.\nThis yields a number of 9,145 and 24,688 tweets containing a PNC or full name, respectively.\n###figure_1### We further leverage the Leipzig Corpora Collection providing large numbers of German news data in the context of the ongoing project Deutscher Wortschatz (DW) (Klein and Geyken, 2010  ###reference_b17###; Goldhahn et al., 2012  ###reference_b11###). We leverage the full DW data inventory of ~27 million sentences. We define a context as a sentence that we only add whenever they contain a PNC or a name.\nThis yields a total number of 170 and 233,477 sentences containing a PNC or full name, respectively."
        },
        {
            "section_id": "3.1",
            "parent_section_id": "3",
            "section_name": "3.1.   Targets",
            "text": "We start out with 770 eventive PNCs provided by Belosevic (2022  ###reference_b3###  ###reference_b3###). As described in detail in her work, the PNCs were collected manually by searching for the string *name or -name as well as regular expressions in the DWDS (Goldhahn et al., 2012  ###reference_b11###  ###reference_b11###) WebXL interface. Additional targets were collected via the Twitter Extended Search option.\n\nThe PNCs can be categorized into the domains politics including politicians such as Angela Merkel and Boris Johnson (87%), sports referring to athletes who are mostly soccer players but also include e.g., the Formula 1 driver Sebastian Vettel (9%), show business encompassing e.g., the actress Angelina Jolie (1%), and others including public figures such as lobbyist Karlheinz Schreiber or the climate activist Greta Thunberg (3%). We list example PNCs within a context in Table 1  ###reference_###  ###reference_### and make the full list of examined PNCs publicly available.222The full list is available here: https://github.com/AnneroseEichel/LREC-COLING2024  ###reference_ING2024###  ###reference_ING2024### We manually map each PNC to the corresponding full name (first name, last name), yielding 131 and 113 names for which at least one or five PNC instances are in the used corpora."
        },
        {
            "section_id": "3.2",
            "parent_section_id": "3",
            "section_name": "3.2.   Context Corpora",
            "text": "For our models, we build two corpora based on Twitter and Deutscher Wortschatz. Each corpus consists of two subcorpora containing contexts for full target names or PNCs.\nWe download tweets containing PNCs or full names using the Twitter333We downloaded the data before the re-naming.\nAcademic API (closed in spring 2023) using missing  ###reference_test/twarc2_en_us/###  ###reference_test/twarc2_en_us/###twarc. Modifiers and names are required to be perfect matches while characters in between are not restricted to hyphens or whitespace but may also be e.g., hashtags. The maximum context is defined as one tweet and added to the corresponding subcorpus whenever a PNC or name is found. For full names, we download 100 tweets per match and remove retweets based on URLs.\nThis yields a number of 9,145 and 24,688 tweets containing a PNC or full name, respectively.\n###figure_2### We further leverage the Leipzig Corpora Collection providing large numbers of German news data in the context of the ongoing project Deutscher Wortschatz (DW) (Klein and Geyken, 2010  ###reference_b17###  ###reference_b17###; Goldhahn et al., 2012  ###reference_b11###  ###reference_b11###). We leverage the full DW data inventory of ~27 million sentences. We define a context as a sentence that we only add whenever they contain a PNC or a name.\nThis yields a total number of 170 and 233,477 sentences containing a PNC or full name, respectively."
        },
        {
            "section_id": "4",
            "parent_section_id": null,
            "section_name": "4.   Evaluating PNCs via Valence",
            "text": "As a first step, we explore the evaluative nature of PNCs from a range of domains drawing on the notion of valence from psycholinguistics, determining the pleasantness of a stimulus (joy vs. toothache).\nWe hypothesize that PNCs with higher or lower valence relative to their respective full name bear an evaluative character. For this, PNC and full name valence are assessed and compared at context level both cross and within domains. We further determine PNC modifier valence and explore the relationship between PNC and modifier evaluation.\nWe use the automatically generated valence norms by Köper and Schulte im Walde (2016  ###reference_b18###) who provide ratings on a scale from 0 to 10 with 0 and 10 referring to low and high valence, respectively. Provided norm types are lower-cased and provided in their inflected forms.\nWe apply part-of-speech (PoS) tagging444We use the TreeTagger Schmid (1999  ###reference_b32###) which we find to produce better results for the task and text at hand than more recent libraries, e.g., spaCy. including lemmatization to all context words of a given target. We only keep context lemmas which belong to the word classes noun, adjective, or verb.555See App. A  ###reference_### for the full list of PoS tags.\nThen, each lemma is assigned a valence score using the valence norms by Köper and Schulte im Walde (2016  ###reference_b18###), iff available.\nSpecifically, the valence of a target  is defined by the normalized mean valence of the corresponding sum of context lemmas :\nWe compare PNC and name valence by means of the valence delta  both across and within the domains politics, sports, and others, and determine statistical significance by calculating the Pearson correlation coefficient.\nOur findings are visualized in Fig. 1  ###reference_### including PNC frequency illustrated by increasing dot size. PNCs are sorted by name valence with the lowest valence score determined for the German businessman, arms dealer, and lobbyist Karlheinz Schreiber,\nand the highest valence score calculated for the former German soccer player Bastian Schweinsteiger. We note that PNC valence moves more towards the name valence line in case of higher frequencies, while outlier PNC scores tend to be more distanced.\nAcross domains, we find PNCs bearing a slightly more negative nature than full names with PNC valence distributed over a greater score range. More specifically, 56% of PNCs are shown to be more negatively evaluative than the corresponding full names.\nThe Spearman correlation coefficient reveals a moderately positive correlation of statistical significance (, ).\nTo gain qualitative insights, we inspect the sample name-PNC pairs with the largest positive and negative relative differences  and examine the most frequent context words.\nThe greatest positive  0.9 comes from the PNC Tore-Klose (‘Goal-Klose’) which refers to the former German soccer player Miroslav Klose. While name valence is around average (4.99), the PNC is evaluated very positively (5.89). Frequent context words of both PNC and name are on average positive since Klose was a very successful athlete, known for his fair play, and well-received in the public sphere. However, considering that the PNC Tore-Klose refers to the specific positive event of scoring many goals, the PNC is evaluated even more positively, with frequent context words such as feiern (‘celebrate’), herrlich (‘wonderful’), and gold (‘gold’) pointing at this finding.\nWhen looking at the pair with the greatest negative difference, we find the PNC Knast-Hoeneß (‘Prison-Hoeneß’) with a  of -0.89.\nWhile Ulrich Hoeneß is also a successful former German soccer player, he is now mainly known for the fact that he was found guilty for serious cases of tax evasion. However, frequent context words are mixed, including the modifier Knast (‘prison’), sagen (‘to say’), and Jahr (‘year’).\nAn explanation for this might be that the public credits Hoeneß for accepting the guilty verdict without appeal.\nWe further compare results within domains. As shown in Fig. 2  ###reference_###, PNC valence scores extend both below and above name valence for the domains politics and sports, while exceeding name valence only for others. Both PNC and name valence scores are lowest for public figures from politics, followed by the slightly more positively evaluated domain others. Athletes, in contrast, are generally evaluated more positively, surpassing the mean value of 5 for both PNC and name valence.\nWe find modifier valence to be spread across a substantially wider range than PNC valence, with minimum modifier valence as low as 0.89 (folter: Folter-Bush (‘Torture Bush’)) and maximum modifier valence going up to 7.9 (willkommen: Willkommens-Merkel (‘Welcome-Merkel’)). In comparison, PNC valence values range between 3.95 (Folter-Bush (‘Torture-Bush’)) and 5.89 (Tore-Klose (‘Goal-Klose’)), with average PNC valence at 4.81 and average modifier valence at 4.22. The majority of modifiers is located below PNC valence with modifier valence increasing only slightly with higher PNC valence (Spearman’s , ).\nFor more fine-grained insights, we examine the modifier-PNC pairs with the largest positive and negative difference . Investigating the largest positive  leads us to the PNC Willkommens-Merkel (‘Welcome-Merkel’), with peak modifier valence (7.9) and below-average PNC valence (4.42). Inspecting frequent context words such as Abschiebung (‘deportation’), verheerend (‘devastating’), and Kritik (‘criticism’) reveals quite negative discourses. This might indicate potentially ironic use of the modifier welcome as the context words convey the opposite meaning or a negative stance towards corresponding political actions of the name bearer.\nThe modifier-PNC pair Enteignungs-Kühnert (‘Expropriation-Kühnert’) is the PNC with the largest negative . Here, modifier valence is extremely low (1.51), while PNC valence is around average (4.9). Context words are very mixed w.r.t. valence, including mentions of Partei (‘political party’), Wahl (‘election’), and Wohnung (‘apartment’). Thus, the extreme value of the modifier is not reflected by the context words and, consequently, PNC valence."
        },
        {
            "section_id": "4.1",
            "parent_section_id": "4",
            "section_name": "4.1.   Assessing Context-Level Valence",
            "text": "We use the automatically generated valence norms by Köper and Schulte im Walde (2016  ###reference_b18###  ###reference_b18###) who provide ratings on a scale from 0 to 10 with 0 and 10 referring to low and high valence, respectively. Provided norm types are lower-cased and provided in their inflected forms.\nWe apply part-of-speech (PoS) tagging444We use the TreeTagger Schmid (1999  ###reference_b32###  ###reference_b32###) which we find to produce better results for the task and text at hand than more recent libraries, e.g., spaCy. including lemmatization to all context words of a given target. We only keep context lemmas which belong to the word classes noun, adjective, or verb.555See App. A  ###reference_###  ###reference_### for the full list of PoS tags.\nThen, each lemma is assigned a valence score using the valence norms by Köper and Schulte im Walde (2016  ###reference_b18###  ###reference_b18###), iff available.\nSpecifically, the valence of a target  is defined by the normalized mean valence of the corresponding sum of context lemmas :\nWe compare PNC and name valence by means of the valence delta  both across and within the domains politics, sports, and others, and determine statistical significance by calculating the Pearson correlation coefficient.\nOur findings are visualized in Fig. 1  ###reference_###  ###reference_### including PNC frequency illustrated by increasing dot size. PNCs are sorted by name valence with the lowest valence score determined for the German businessman, arms dealer, and lobbyist Karlheinz Schreiber,\nand the highest valence score calculated for the former German soccer player Bastian Schweinsteiger. We note that PNC valence moves more towards the name valence line in case of higher frequencies, while outlier PNC scores tend to be more distanced.\nAcross domains, we find PNCs bearing a slightly more negative nature than full names with PNC valence distributed over a greater score range. More specifically, 56% of PNCs are shown to be more negatively evaluative than the corresponding full names.\nThe Spearman correlation coefficient reveals a moderately positive correlation of statistical significance (, ).\nTo gain qualitative insights, we inspect the sample name-PNC pairs with the largest positive and negative relative differences  and examine the most frequent context words.\nThe greatest positive  0.9 comes from the PNC Tore-Klose (‘Goal-Klose’) which refers to the former German soccer player Miroslav Klose. While name valence is around average (4.99), the PNC is evaluated very positively (5.89). Frequent context words of both PNC and name are on average positive since Klose was a very successful athlete, known for his fair play, and well-received in the public sphere. However, considering that the PNC Tore-Klose refers to the specific positive event of scoring many goals, the PNC is evaluated even more positively, with frequent context words such as feiern (‘celebrate’), herrlich (‘wonderful’), and gold (‘gold’) pointing at this finding.\nWhen looking at the pair with the greatest negative difference, we find the PNC Knast-Hoeneß (‘Prison-Hoeneß’) with a  of -0.89.\nWhile Ulrich Hoeneß is also a successful former German soccer player, he is now mainly known for the fact that he was found guilty for serious cases of tax evasion. However, frequent context words are mixed, including the modifier Knast (‘prison’), sagen (‘to say’), and Jahr (‘year’).\nAn explanation for this might be that the public credits Hoeneß for accepting the guilty verdict without appeal.\nWe further compare results within domains. As shown in Fig. 2  ###reference_###  ###reference_###, PNC valence scores extend both below and above name valence for the domains politics and sports, while exceeding name valence only for others. Both PNC and name valence scores are lowest for public figures from politics, followed by the slightly more positively evaluated domain others. Athletes, in contrast, are generally evaluated more positively, surpassing the mean value of 5 for both PNC and name valence."
        },
        {
            "section_id": "4.2",
            "parent_section_id": "4",
            "section_name": "4.2.   Assessing Modifier Valence",
            "text": "PNCs constitute determinative compounds where a modifier such as a noun modifies the compound head, in our case, a name. As modifier meaning has a large share in human compound interpretation, we would assume that modifier meaning influences the way the whole compound is evaluated.\nWe thus hypothesize that modifier meaning can be used as a proxy for compound evaluation. For this, we examine the connection between PNC and modifier valence.\nWe manually666Results using libraries such as TreeTagger or spaCy yield very inaccurate results which could not be used for further investigations. determine modifier lemmas and automatically assign a valence score Köper and Schulte im Walde (2016  ###reference_b18###) whenever possible. 777In the rare case of double entries, we choose among the available scores at random.\nWe calculate the relative difference  between the 203 PNC and name valence scores and determine statistical significance using Spearman’s .\n###figure_3### We find modifier valence to be spread across a substantially wider range than PNC valence, with minimum modifier valence as low as 0.89 (folter: Folter-Bush (‘Torture Bush’)) and maximum modifier valence going up to 7.9 (willkommen: Willkommens-Merkel (‘Welcome-Merkel’)). In comparison, PNC valence values range between 3.95 (Folter-Bush (‘Torture-Bush’)) and 5.89 (Tore-Klose (‘Goal-Klose’)), with average PNC valence at 4.81 and average modifier valence at 4.22. The majority of modifiers is located below PNC valence with modifier valence increasing only slightly with higher PNC valence (Spearman’s , ).\nFor more fine-grained insights, we examine the modifier-PNC pairs with the largest positive and negative difference . Investigating the largest positive  leads us to the PNC Willkommens-Merkel (‘Welcome-Merkel’), with peak modifier valence (7.9) and below-average PNC valence (4.42). Inspecting frequent context words such as Abschiebung (‘deportation’), verheerend (‘devastating’), and Kritik (‘criticism’) reveals quite negative discourses. This might indicate potentially ironic use of the modifier welcome as the context words convey the opposite meaning or a negative stance towards corresponding political actions of the name bearer.\nThe modifier-PNC pair Enteignungs-Kühnert (‘Expropriation-Kühnert’) is the PNC with the largest negative . Here, modifier valence is extremely low (1.51), while PNC valence is around average (4.9). Context words are very mixed w.r.t. valence, including mentions of Partei (‘political party’), Wahl (‘election’), and Wohnung (‘apartment’). Thus, the extreme value of the modifier is not reflected by the context words and, consequently, PNC valence."
        },
        {
            "section_id": "5",
            "parent_section_id": null,
            "section_name": "5.   PLMs for Evaluating PNCs",
            "text": "We further explore the evaluative function of PNCs leveraging a range of suitable pretrained language models (PLMs) that have been fine-tuned and evaluated for the task of sentiment analysis (SA).\nWe propose to use sentiment predictions as a proxy for valence and hypothesize that PNCs for which more positive or negative sentiment relative to their respective full name is predicted to bear an evaluative character. For this, we formulate the task of predicting the evaluative nature of a PNC in context as a text classification problem at the document level. We feed the context including a PNC or name to a model and obtain top-1 predictions. The multi-class output is then mapped onto a valence scale to calculate relative differences between PNC and name valence that are leveraged as a proxy for the evaluative nature of a PNC. Results are compared across different models with varying underlying architectures and training data as well as findings from experiments based on valence norms (§4  ###reference_###).\nBarbieri et al. (2022  ###reference_b2###) devise a multilingual XLM-RoBERTa model (XLM-Twitter  ###reference_rta-base-sentiment###) trained on  198M tweets and fine-tuned on SA for 8 languages including German. Antypas et al. (2023  ###reference_b1###) harness this model and provide a version that is further fine-tuned on sentiment by politician’s tweets, focusing on MPs from the UK, Spain, and Greece (XLM-Politics  ###reference_tics-sentiment###). Although no explicit fine-tuning has been performed for German, we hypothesize that parameter changes may still yield interesting changes for PNCs referring to politicians. We further test a model specifically focusing on German Guhr et al. (2020  ###reference_b13###) which is based on the German BERT architecture and trained on 1.834M German language samples from domains such as Twitter, Facebook, and reviews (GBERT-Sentiment  ###reference_-bert###). We also explore a model extending Guhr et al. (2020  ###reference_b13###)’s model by additional fine-tuning on German news texts about migration Lüdke et al. (2022  ###reference_b22###) (GBERT-Migration  ###reference_-bert###).\nWe feed the context including a PNC or name to a model and obtain top-1 predictions with a label  where  {negative, neutral, positive}, respectively.888All experiments are performed with one NVIDIA RTX A6000 GPU with inference runtime per model at max. 4 minutes.\nTo map the obtained labels onto our valence scale, we compute a weighted valence score for each target  (PNC or name) with\nwhere  and  denote positive and neutral labels obtained for , and  refers to the sum of labels observed for . In principle, valence could also be defined as (i) the sum of all positive labels only, or (ii)  sum of all negative labels, normalized by the sum of all labels. However, (i) does not include the overall label distribution,\nand (ii) sums all positive and neutral labels as positive labels. In contrast, our approach incorporates whether the remaining labels are mainly neutral or negative, while weighing contributions of positive and neutral differently.\nResults from our PLM experiments suggest that PNCs carry a clearly more negative evaluative function than full names across all tested models with up to 93.55% PNCs labeled as more negatively evaluative than the corresponding name (cf. Table 2  ###reference_###). We find low positive correlations of statistical significance between name and PNC valence for the XLM-RoBERTa-based models and no significant correlation for the BERT-based models focusing on German data.\nWhen comparing results to our valence experiments (§4  ###reference_###), the largest difference can be seen in cases where PLMs predict a PNC to be more negatively evaluative than the full name (XLM-Twitter: 36%, XLM-Politics: 31%, GBERT-Sentiment: 39%, GBERT-Migration: 35%, cf. Table 3  ###reference_###).\n###table_1### ###table_2### ###table_3### Further zooming in on examples (cf. Table 4  ###reference_###), we find all models but GBERT-Sentiment predicting the PNC Tore-Klose (‘Goal-Klose’) more positively evaluative than the name Miroslav Klose. The same is true for Knast-Hoeneß (‘Prison-Hoeneß’) where all but XLM-Politics predict the PNC to be more negatively evaluative than the name Ulrich Hoeneß. Inspecting PNCs with very high and low modifier valence, we observe that all models agree on the PNC Willkommens-Merkel (‘Welcome-Merkel’) carrying a more negative meaning than the full name which is line with our valence norms experiment. Similarly, for the PNC Enteignungs-Kühnert (‘Expropriation-Kühnert’) with very low modifier valence, model predictions match regarding a more negatively evaluative PNC compared to the name Kevin Kühnert.\nWe perform a human evaluation of sentiment predictions to assess task difficulty and compare model predictions to humans’ opinions.\nFor this, we evaluate 30 PNCs (10% of targets) for which (i) all PLMs and valence norms predict the same label (negative only), (ii) PLMs agree among themselves but disagree with valence norm prediction, and (iii) PLMs disagree among themselves and/or disagree with valence norms prediction. For feasibility reasons, we focus on PNCs occurring within max. 30 contexts (avg. # contexts: 12.7). Provided a PNC in context, five annotators are asked to annotate sentiment choosing between the labels {positive, negative, neutral}.\nThe evaluation task is carried out online in a remote setting using Google Forms and Google Tables. We collect unique and complete answer sets from six annotators.999For further details on the annotators and the annotation setup and, we refer to Sec. Ethics Statement  ###reference_###. Pairwise inter-annotator agreement101010We exclude submissions from one annotator due to poor inter-annotator agreement. () indicates reasonable consensus. Self-reported task difficulty reveals that annotators assess the annotation as difficult in at least 40-60% of the cases noting that they needed time to choose a label and expressing uncertainty in some cases.\nUsing the obtained annotations, we determine valence as described in Eq. 2  ###reference_###.\nA visualization of PNC valence scores determined by human annotations compared to computational approaches (valence norms, PLMs) is shown in Fig. 3  ###reference_###. While human evaluation suggests a substantially more negative meaning of most PNCs as compared to all computational approaches, domain-specific differences are underlined with all PNCs from the domain sports evaluated more positively than PNCs from the domain politics.\nFurthermore, while PLM predictions have high variance which seems to be connected to modifier meaning, both our valence norms-based approach and human evaluation shows less variance which hints towards stronger incorporation of the whole discourse. These observations point towards the need of further investigation, for example, focusing on predicting sentiment towards a specific target Pei et al. (2019  ###reference_b27###) or increasing model attention on the discourse as a whole.\nFurthermore, human evaluation seems to be less influenced by modifier meaning in contrast to PLM predictions, e.g., ratings for Folter-Bush (‘Torture-Bush’) and Bienen-Söder (‘Bee-Söder’) are assigned almost equal ratings by humans, while PLM and valence predictions differ quite significantly.\nBased on these observations, we confirm that sentiment predictions obtained from PLMs fine-tuned for SA can serve as a proxy for assessing whether PNCs are more negatively or positively evaluative than corresponding personal names. However, we find model-specific differences including (i) PLMs providing stronger valence assessments than our valence-based approach with a tendency towards more negative predictions and (ii) XLM-based models suggesting a more positive interpretation of PNCs than models using German BERT as their backbone.\nA comparison of models with human evaluation of PNCs however hints towards a more negatively evaluated meaning of PNCs compared to both computational approaches with PNCs from the domain sports evaluated more positively than from the domain politics.\n###figure_4###"
        },
        {
            "section_id": "6",
            "parent_section_id": null,
            "section_name": "6.   Regression Modelling",
            "text": "Given that every PNC refers to a real-world person, e.g., Tore-Klose (‘Goal-Klose’)  Miroslav Klose, we hypothesize that personal background information potentially influence the evaluative meaning of a PNC. Furthermore, evaluating PNCs via valence (cf. §4  ###reference_###) and PLMs (cf. §5  ###reference_###) showed that information such as modifier valence impacts whether a PNC is more positively or negatively evaluated than a full name. To explore which factors are in fact influential at a statistically significant level, we first enrich each name and PNC with\npersonal (age, gender, nationality, place of birth), domain-specific (domain, political party membership), and extra-linguistic information (name, PNC, and modifier valence scores, event frame). In a next step, we fit a range of linear regression models to see which relationships are directed and explore options for variable selection.\nFor each target, we manually collect and assign relevant personal background information based on publicly accessible information111111We use Wikipedia through Google to collect data.. We further model the relationship between the modifier and the compound head as frame elements of the event frame in which the name bearer participated, using German FrameNet:\nDomain (politics: 87%, sports: 9%, show business: 1%, others: 3%)\nCurrent age in full years (if deceased: age at time of death)\nCurrent nationality (Argentina, Austria, France, Turkey: <1%, Germany: 88% Russia, Sweden, UK: 1%, US: 7%)\nPlace of birth (for feasibility restricted to West Germany: 77%, East Germany: 16%, outside of Germany: 7%)\nGender (female: 22%, male: 78%)121212No target identified as non-binary according to publicly available information.\nPolitical party membership (Austria: Team HC Strache: <1%, Germany: AfD: 5%, CDU/CSU: 25/10%, FDP: 12%, The Greens: 12%, The Left: 1%, SPD: 18%, Centre: <1%; Russia: United Russia: 1%; UK: Conservatives: <1%; USA: Democrats: 3%, Republicans: 2%; non-party politicians are assigned the label independent; people who are neither politicians nor party members are assigned no party)\nParticipation in events (20 German FrameNet  ###reference_gsw.phil.hhu.de### frames; PNCs not representing an event corresponding to a frame or an unknown event are labeled not eventive or unknown, respectively)\nWe first fit a linear model to predict  using each of our ten independent variables131313Reference categories for factor variables are determined by lowest value.\nand find significant results for the variables PNC valence, modifier valence, age, political party, and birthplace (cf. App. B.1  ###reference_###, Table 5  ###reference_###),\nno significant difference in means based on the Tukey post-hoc test).\nThe results indicate PNC valence as highly significant predictor explaining ~88% of variance. Modifier valence also has a positive linear relationship, explaining around 10% of variance, while age comes with an significant inverse relationship, i.e., increasing age seems to be reflected in a PNC that is more negative than the name of a person itself. If a person is a member of the far right party AfD (Alternative for Germany), a negative  is more likely, while being a member of any other larger party is positively related to  as compared to the AfD. In particular, members of The Greens party are likely to be assigned a positive . Moreover, different birth places might be connected to differences in the evaluative nature of a corresponding PNC.\nTo further verify which predictors are relevant, we fit a linear regression model using elastic net regularization leveraging all variables excluding either name valence or PNC valence or both variables. Further details are reported in App. B.2  ###reference_###.\nExcluding PNC valence leads to increased importance of modifier valence as well as personal and domain-specific information such as age, while name valence is of low relevance. In general, the fitted model only explains a limited amount of variance (). Excluding both name and PNC valence increases the importance of modifier valence and variables focusing more on geographic information such as place of birth. Similarly to the previous model, this model only explains a limited percentage of variance (). Excluding name valence places maximum importance on PNC valence as well as domain categories followed by personal information, while modifier valence only bears little relevance. The fitted model clearly outperforms the other models, explaining a high percentage of variance ().\nAs a next step, we fit a range of multivariate regression models based on theoretical background, including models based on (i) personal information including age, gender or age, gender, nationality, origin, (ii) and domain-specific information such as domain and political party membership, as well as (iii) semantic knowledge and extra-linguistic information regarding the PNC encompassing modifier valence, FrameNet (and PNC) valence. 141414As  is calculated based on name and PNC valence, including both would yield a model of perfect fit, which does, however not reveal potentially interesting results. We thus only consider scenarios where either one or both variables are excluded.\nAdditionally, (iv) three models including all but either name or PNC valence or neither of both variables are fitted.\nResults (cf. App. B  ###reference_###, Table 6  ###reference_###) reveal that only models based on (i) personal, or (ii) domain-specific information are significant but cannot explain the variance in the data very well (best model delta~party + domain yields ). Models based on (iii) extra-linguistic information regarding the compound, on the other hand, are more successful with adding PNC valence significantly boosting performance ().\n(iv) Including all variables except either name or PNC valence or neither of both yields models of mixed performance with PNC valence excluded leading to significantly less variance explained (PNC excluded: , name and PNC valence excluded: ). The best model includes all variables except name valence ().\nOverall, we observe a highly significant positive relationship for PNC valence.\nInterestingly, we find the domain sports connected to a slightly inverse relationship with top valence scores for athlete’s names and not the PNC. An example is the PNC Gold-Rosi (‘Gold-Rosi’) where top valence scores are related to the full name Rosi Mittermaier and PNC valence scores placed slightly below. In this case, the reason is hidden in many of the contexts who are – very positive, but nevertheless – obituaries of the famous skier (cf. Table 1  ###reference_###, Fig. 1  ###reference_###)\nIf a person identifies as male or comes from the U.S., the PNC is slightly more likely to be more positively or negatively evaluative, respectively. Political party membership has an inverse relationship in cases of the CDU, CSU, FDP, The Greens, and the SPD, while Democrats and Republicans come with a positive relationship (reference level: AfD)."
        },
        {
            "section_id": "6.1",
            "parent_section_id": "6",
            "section_name": "6.1.   Data",
            "text": "As valence scores calculated with valence norms (cf. §4  ###reference_###) show a moderately positive correlation between name and valence (as compared to PLM-based valence), we draw on corresponding valence scores for this analysis. We use all 289 targets for which a valence score for both the full name and the PNC could be calculated. Then, we determine the corresponding  where positive values refer to cases where compounds are more positive than the name and negative values represent target pairs where the compound is more negative than the name. For each PNC, we also compute the corresponding modifier valence scores and filter out cases where no score could be determined.\nFor each target, we manually collect and assign relevant personal background information based on publicly accessible information111111We use Wikipedia through Google to collect data.. We further model the relationship between the modifier and the compound head as frame elements of the event frame in which the name bearer participated, using German FrameNet:\nDomain (politics: 87%, sports: 9%, show business: 1%, others: 3%)\nCurrent age in full years (if deceased: age at time of death)\nCurrent nationality (Argentina, Austria, France, Turkey: <1%, Germany: 88% Russia, Sweden, UK: 1%, US: 7%)\nPlace of birth (for feasibility restricted to West Germany: 77%, East Germany: 16%, outside of Germany: 7%)\nGender (female: 22%, male: 78%)121212No target identified as non-binary according to publicly available information.\nPolitical party membership (Austria: Team HC Strache: <1%, Germany: AfD: 5%, CDU/CSU: 25/10%, FDP: 12%, The Greens: 12%, The Left: 1%, SPD: 18%, Centre: <1%; Russia: United Russia: 1%; UK: Conservatives: <1%; USA: Democrats: 3%, Republicans: 2%; non-party politicians are assigned the label independent; people who are neither politicians nor party members are assigned no party)\nParticipation in events (20 German FrameNet  ###reference_gsw.phil.hhu.de###  ###reference_gsw.phil.hhu.de### frames; PNCs not representing an event corresponding to a frame or an unknown event are labeled not eventive or unknown, respectively)"
        },
        {
            "section_id": "6.2",
            "parent_section_id": "6",
            "section_name": "6.2.   Linear Regression Modelling",
            "text": "We first fit a linear model to predict  using each of our ten independent variables131313Reference categories for factor variables are determined by lowest value.\nand find significant results for the variables PNC valence, modifier valence, age, political party, and birthplace (cf. App. B.1  ###reference_###  ###reference_###, Table 5  ###reference_###  ###reference_###),\nno significant difference in means based on the Tukey post-hoc test).\nThe results indicate PNC valence as highly significant predictor explaining ~88% of variance. Modifier valence also has a positive linear relationship, explaining around 10% of variance, while age comes with an significant inverse relationship, i.e., increasing age seems to be reflected in a PNC that is more negative than the name of a person itself. If a person is a member of the far right party AfD (Alternative for Germany), a negative  is more likely, while being a member of any other larger party is positively related to  as compared to the AfD. In particular, members of The Greens party are likely to be assigned a positive . Moreover, different birth places might be connected to differences in the evaluative nature of a corresponding PNC.\nTo further verify which predictors are relevant, we fit a linear regression model using elastic net regularization leveraging all variables excluding either name valence or PNC valence or both variables. Further details are reported in App. B.2  ###reference_###  ###reference_###.\nExcluding PNC valence leads to increased importance of modifier valence as well as personal and domain-specific information such as age, while name valence is of low relevance. In general, the fitted model only explains a limited amount of variance (). Excluding both name and PNC valence increases the importance of modifier valence and variables focusing more on geographic information such as place of birth. Similarly to the previous model, this model only explains a limited percentage of variance (). Excluding name valence places maximum importance on PNC valence as well as domain categories followed by personal information, while modifier valence only bears little relevance. The fitted model clearly outperforms the other models, explaining a high percentage of variance ().\nAs a next step, we fit a range of multivariate regression models based on theoretical background, including models based on (i) personal information including age, gender or age, gender, nationality, origin, (ii) and domain-specific information such as domain and political party membership, as well as (iii) semantic knowledge and extra-linguistic information regarding the PNC encompassing modifier valence, FrameNet (and PNC) valence. 141414As  is calculated based on name and PNC valence, including both would yield a model of perfect fit, which does, however not reveal potentially interesting results. We thus only consider scenarios where either one or both variables are excluded.\nAdditionally, (iv) three models including all but either name or PNC valence or neither of both variables are fitted.\nResults (cf. App. B  ###reference_###  ###reference_###, Table 6  ###reference_###  ###reference_###) reveal that only models based on (i) personal, or (ii) domain-specific information are significant but cannot explain the variance in the data very well (best model delta~party + domain yields ). Models based on (iii) extra-linguistic information regarding the compound, on the other hand, are more successful with adding PNC valence significantly boosting performance ().\n(iv) Including all variables except either name or PNC valence or neither of both yields models of mixed performance with PNC valence excluded leading to significantly less variance explained (PNC excluded: , name and PNC valence excluded: ). The best model includes all variables except name valence ().\nOverall, we observe a highly significant positive relationship for PNC valence.\nInterestingly, we find the domain sports connected to a slightly inverse relationship with top valence scores for athlete’s names and not the PNC. An example is the PNC Gold-Rosi (‘Gold-Rosi’) where top valence scores are related to the full name Rosi Mittermaier and PNC valence scores placed slightly below. In this case, the reason is hidden in many of the contexts who are – very positive, but nevertheless – obituaries of the famous skier (cf. Table 1  ###reference_###  ###reference_###, Fig. 1  ###reference_###  ###reference_###)\nIf a person identifies as male or comes from the U.S., the PNC is slightly more likely to be more positively or negatively evaluative, respectively. Political party membership has an inverse relationship in cases of the CDU, CSU, FDP, The Greens, and the SPD, while Democrats and Republicans come with a positive relationship (reference level: AfD)."
        },
        {
            "section_id": "7",
            "parent_section_id": null,
            "section_name": "7.   Conclusion",
            "text": "We tackled the under-studied task of modeling the meaning of PNCs such as Willkommens-Merkel (’Welcome-Merkel’), and presented a comprehensive computational exploration revealing that PNCs are both positively and negatively evaluative at discourse level. We examined 321 German PNCs from domains such as politics and sports and their respective full names, e.g., Angela Merkel. We developed two computational approaches based on (i) valence norms and (ii) PLMs and compared results to human annotation, uncovering domain-specific differences where athletes are generally evaluated more positively than politicians. To explore PNC connections to the respective real-world persons, we enriched our data with personal background information and employed regression analyses to demonstrate which factors influence PNC valence."
        },
        {
            "section_id": "8",
            "parent_section_id": null,
            "section_name": "8.   Bibliographical References",
            "text": ""
        }
    ]
}